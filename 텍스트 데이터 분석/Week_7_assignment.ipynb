{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IOyrZmof7meJ"
      },
      "source": [
        "**7주차 과제 - 문서 분류**\n",
        "\n",
        "- 과제: 아래 코드를 실행하고 실행화면을 캡쳐하여 반드시 **pdf** 파일로 변환하여 제출하시오.\n",
        "- 유의사항: 본 과제의 목적은 학생들께서 아래 코드를 이용하여 문서 분류를 경험해 보는 것입니다. 이 코드를 그대로 실행하여 제출해도 되지만 7주차 실습파일을 참고로 하여 전처리 방법과 알고리즘 등을 변경해 가면 실습하기를 추천합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "asfTKOYK7meO"
      },
      "source": [
        "# 1. 20 뉴스그룹 데이터 준비\n",
        "\n",
        "- 데이터셋 설명: http://qwone.com/~jason/20Newsgroups/\n",
        "- scikit-learn 라이브러리: http://scikit-learn.org/0.19/datasets/twenty_newsgroups.html"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "# 20 뉴스그룹 데이터의 20개 주제 중 2개만을 선택\n",
        "categories = ['comp.graphics', 'sci.space']\n",
        "\n",
        "# 20 newsgroups 데이터셋에서 training data를 가져옴\n",
        "# 본문을 제외한 텍스트의 특정 부분('headers', 'footers', 'quotes')을 제거\n",
        "newsgroups_train = fetch_20newsgroups(subset='train',\n",
        "                                      remove=('headers', 'footers', 'quotes'),\n",
        "                                      categories=categories)\n",
        "\n",
        "# 20 newsgroups 데이터셋에서 test data를 가져옴\n",
        "newsgroups_test = fetch_20newsgroups(subset='test',\n",
        "                                     remove=('headers', 'footers', 'quotes'),\n",
        "                                     categories=categories)\n",
        "\n",
        "# training data와 test data 크기\n",
        "print('# Training data sample size:', len(newsgroups_train.data))\n",
        "print('# Test data sample size:', len(newsgroups_test.data))"
      ],
      "metadata": {
        "id": "HnkeYKvoKKvv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. TF-IDF 기반 특성 추출"
      ],
      "metadata": {
        "id": "Lp1tsW5sKRyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "X_train = newsgroups_train.data\n",
        "y_train = newsgroups_train.target\n",
        "\n",
        "X_test = newsgroups_test.data\n",
        "y_test = newsgroups_test.target\n",
        "\n",
        "# max_features=2000: 최대로 사용할 단어 특성의 수\n",
        "# min_df=5: 단어가 적어도 5개의 문서에 나와야 함\n",
        "# max_df=0.5: 단어가 전체 문서의 50% 이상에 나오지 않아야 함\n",
        "tfidf = TfidfVectorizer(max_features=2000, min_df=5, max_df=0.5)\n",
        "\n",
        "# training/test data를 feature 벡터로 변환\n",
        "X_train_tfidf = tfidf.fit_transform(X_train)\n",
        "X_test_tfidf = tfidf.transform(X_test)"
      ],
      "metadata": {
        "id": "kI1r_ciUShfn"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOLvpqS77meX"
      },
      "source": [
        "# **3. 로지스틱 회귀를 이용한 문서 분류**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# TF-IDF 기반 feature 벡터를 이용한 로지스틱 회귀 적합\n",
        "LR_clf_tfidf = LogisticRegression(max_iter=1000, random_state=3002)\n",
        "LR_clf_tfidf.fit(X_train_tfidf, y_train)\n",
        "\n",
        "print('# Training accuracy: {:.3f}'.format(LR_clf_tfidf.score(X_train_tfidf, y_train)))\n",
        "print('# Test accuracy: {:.3f}'.format(LR_clf_tfidf.score(X_test_tfidf, y_test)))"
      ],
      "metadata": {
        "id": "aiAPtAfmRKUb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pred = LR_clf_tfidf.predict(X_test_tfidf[:2])\n",
        "\n",
        "print('# Predicted labels:', pred)\n",
        "print('# Predicted categories:', newsgroups_train.target_names[pred[0]], newsgroups_train.target_names[pred[1]])"
      ],
      "metadata": {
        "id": "OvygrB3tUAav"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": true
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}