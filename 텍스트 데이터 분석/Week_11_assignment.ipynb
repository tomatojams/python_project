{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLUyz_8u86eM"
      },
      "source": [
        "**11주차 과제 - 워드 클라우드**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "PORT7MdbVA-Z"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "from textblob import TextBlob\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHGnhkP5VwFA"
      },
      "outputs": [],
      "source": [
        "# 영화 리뷰 로드\n",
        "nltk.download(\"movie_reviews\")\n",
        "\n",
        "# 긍정/부정 리뷰를 리스트로 각각 저장\n",
        "positive_reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids('pos')]\n",
        "negative_reviews = [movie_reviews.raw(fileid) for fileid in movie_reviews.fileids('neg')]\n",
        "\n",
        "# 긍정/부정 리뷰를 하나의 DataFrame으로 저장\n",
        "df = pd.concat([pd.DataFrame(positive_reviews), pd.DataFrame(negative_reviews)])\n",
        "\n",
        "# 컬럼명을 'review'로 변경\n",
        "df = df.rename(columns={0: \"review\"})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1VkbVuin_2zO"
      },
      "outputs": [],
      "source": [
        "df\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 많이 등장하는 n-gram을 추출하는 함수\n",
        "def get_top_ngrams(corpus, ngram_range, stop_words=None, n=None):\n",
        "    vec = CountVectorizer(stop_words=stop_words, ngram_range=ngram_range).fit(corpus)\n",
        "    bag_of_words = vec.transform(corpus)\n",
        "\n",
        "    sum_words = bag_of_words.sum(axis=0)\n",
        "\n",
        "    words_freq = [(word, sum_words[0, idx]) for word, idx in vec.vocabulary_.items()]\n",
        "    words_freq = sorted(words_freq, key=lambda x: x[1], reverse=True)\n",
        "\n",
        "    common_words = words_freq[:n]\n",
        "    words = []\n",
        "    freqs = []\n",
        "    for word, freq in common_words:\n",
        "        words.append(word)\n",
        "        freqs.append(freq)\n",
        "\n",
        "    df = pd.DataFrame({'Word': words, 'Freq': freqs})\n",
        "    return df"
      ],
      "metadata": {
        "id": "T6XScYhTwX35"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 가장 많이 등장하는 n-gram\n",
        "stop_words = 'english'\n",
        "n = 20\n",
        "unigrams_st = get_top_ngrams(df['review'], (1, 1), stop_words, n)"
      ],
      "metadata": {
        "id": "39CuidsHwZrR"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "G4-kv01686ei"
      },
      "outputs": [],
      "source": [
        "from wordcloud import WordCloud\n",
        "\n",
        "# 워드 클라우드 함수를 사용하기 위해 빈도 DataFrame을 dictionary로 변환\n",
        "unigrams_st_dict = {word: freq for word, freq in zip(unigrams_st['Word'], unigrams_st['Freq'])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWAUQSBqGU6A"
      },
      "outputs": [],
      "source": [
        "unigrams_st_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GK9PSPghEcpO"
      },
      "outputs": [],
      "source": [
        "# background_color: 배경색, colormap: 글자색\n",
        "wordcloud_uni = WordCloud(background_color=\"white\",\n",
        "                          colormap=\"twilight_shifted\").generate_from_frequencies(unigrams_st_dict)\n",
        "\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.imshow(wordcloud_uni, interpolation='bilinear')\n",
        "plt.axis(\"off\")\n",
        "plt.title(\"Word Cloud Example\")\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": true,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "165px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}