{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXSgl_cSZWI8"
   },
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4230,
     "status": "ok",
     "timestamp": 1684113717923,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     },
     "user_tz": -540
    },
    "id": "nJCye9i4Z4Dc",
    "outputId": "c811aa63-e78c-4fa3-b35c-26901459c7e6",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:17:45.061755Z",
     "start_time": "2024-01-16T02:17:39.560273Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: konlpy in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (0.6.0)\r\n",
      "Collecting preprocess\r\n",
      "  Downloading preprocess-2.0.0-py3-none-any.whl (12 kB)\r\n",
      "Requirement already satisfied: JPype1>=0.7.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from konlpy) (1.4.1)\r\n",
      "Requirement already satisfied: lxml>=4.1.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from konlpy) (4.9.2)\r\n",
      "Requirement already satisfied: numpy>=1.6 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from konlpy) (1.23.2)\r\n",
      "Collecting future (from preprocess)\r\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\r\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m840.9/840.9 kB\u001B[0m \u001B[31m581.7 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25hRequirement already satisfied: packaging in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from JPype1>=0.7.0->konlpy) (23.1)\r\n",
      "Building wheels for collected packages: future\r\n",
      "  Building wheel for future (setup.py) ... \u001B[?25ldone\r\n",
      "\u001B[?25h  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492025 sha256=06171940178fb3c7e2faa1b135e65f88634d51d49d75d0cc74e39aeaa03eff8e\r\n",
      "  Stored in directory: /Users/soma/Library/Caches/pip/wheels/bf/5d/6a/2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\r\n",
      "Successfully built future\r\n",
      "Installing collected packages: future, preprocess\r\n",
      "Successfully installed future-0.18.3 preprocess-2.0.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip install konlpy preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AV-FvWgQZWI9",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:17:48.957289Z",
     "start_time": "2024-01-16T02:17:45.061476Z"
    }
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "from konlpy.tag import Twitter\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import enum\n",
    "import os\n",
    "import re\n",
    "import json\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from preprocess import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0XO9m6U-ZWI-"
   },
   "source": [
    "# 시각화 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "m8evqZv8ZWI-",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:17:48.957910Z",
     "start_time": "2024-01-16T02:17:48.954676Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "    plt.plot(history.history[string])\n",
    "    plt.plot(history.history['val_'+string], '')\n",
    "    plt.xlabel(\"Epochs\")\n",
    "    plt.ylabel(string)\n",
    "    plt.legend([string, 'val_'+string])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UqbwnZiYZWI-"
   },
   "source": [
    "# 학습 데이터 경로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "WWCNR1e4ZWI-",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:18:28.306535Z",
     "start_time": "2024-01-16T02:18:28.276463Z"
    }
   },
   "outputs": [],
   "source": [
    "DATA_IN_PATH = 'data/'\n",
    "DATA_OUT_PATH = 'data/'\n",
    "TRAIN_INPUTS = 'train_inputs.npy'\n",
    "TRAIN_OUTPUTS = 'train_outputs.npy'\n",
    "TRAIN_TARGETS = 'train_targets.npy'\n",
    "DATA_CONFIGS = 'data_configs.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MjCalv0_ZWI-"
   },
   "source": [
    "# 랜덤 시드 고정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "kQi7CygwZWI-",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:18:29.740383Z",
     "start_time": "2024-01-16T02:18:29.718855Z"
    }
   },
   "outputs": [],
   "source": [
    "SEED_NUM = 1234\n",
    "tf.random.set_seed(SEED_NUM)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Jru07IHzZWI-"
   },
   "source": [
    "# 파일 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "997yZTfoZWI-",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:18:30.828930Z",
     "start_time": "2024-01-16T02:18:30.755984Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'data/train_inputs.npy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mFileNotFoundError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[9], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m index_inputs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28;43mopen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mDATA_IN_PATH\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m+\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mTRAIN_INPUTS\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mrb\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)\n\u001B[1;32m      2\u001B[0m index_outputs \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(DATA_IN_PATH \u001B[38;5;241m+\u001B[39m TRAIN_OUTPUTS , \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m))\n\u001B[1;32m      3\u001B[0m index_targets \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mload(\u001B[38;5;28mopen\u001B[39m(DATA_IN_PATH \u001B[38;5;241m+\u001B[39m TRAIN_TARGETS , \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mrb\u001B[39m\u001B[38;5;124m'\u001B[39m))\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/IPython/core/interactiveshell.py:284\u001B[0m, in \u001B[0;36m_modified_open\u001B[0;34m(file, *args, **kwargs)\u001B[0m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m file \u001B[38;5;129;01min\u001B[39;00m {\u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m}:\n\u001B[1;32m    278\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    279\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIPython won\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mt let you open fd=\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mfile\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m by default \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    280\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    281\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124myou can use builtins\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m open.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    282\u001B[0m     )\n\u001B[0;32m--> 284\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mio_open\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfile\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mFileNotFoundError\u001B[0m: [Errno 2] No such file or directory: 'data/train_inputs.npy'"
     ]
    }
   ],
   "source": [
    "index_inputs = np.load(open(DATA_IN_PATH + TRAIN_INPUTS, 'rb'))\n",
    "index_outputs = np.load(open(DATA_IN_PATH + TRAIN_OUTPUTS , 'rb'))\n",
    "index_targets = np.load(open(DATA_IN_PATH + TRAIN_TARGETS , 'rb'))\n",
    "prepro_configs = json.load(open(DATA_IN_PATH + DATA_CONFIGS, 'r'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XcteVkO4ZWI-"
   },
   "source": [
    "# 모델 하이퍼파라메터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1MSFZpYYZWI-",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:17:49.384723Z",
     "start_time": "2024-01-16T02:17:49.383350Z"
    }
   },
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "end_index = prepro_configs['end_symbol']\n",
    "model_name = 'transformer'\n",
    "vocab_size = prepro_configs['vocab_size']\n",
    "BATCH_SIZE = 2\n",
    "MAX_SEQUENCE = 25\n",
    "EPOCHS = 30\n",
    "VALID_SPLIT = 0.1\n",
    "\n",
    "kargs = {'model_name': model_name,\n",
    "         'num_layers': 2, # 인코더 디코더가 몇개인지\n",
    "         'd_model': 512, # 인코더 디코더의 내부 사이즈 모델의 차원수\n",
    "         'num_heads': 8, # 멀티헤드 어텐션에서 헤드가 몇개인지\n",
    "         'dff': 2048, # 포인트 와이즈 피드포워드 네트워크 (Dense) Feed Forward Network\n",
    "         'input_vocab_size': vocab_size, # 다중분류 위해\n",
    "         'target_vocab_size': vocab_size,\n",
    "         'maximum_position_encoding': MAX_SEQUENCE,\n",
    "         'end_token_idx': char2idx[end_index],\n",
    "         'rate': 0.1 # 드롭아웃 레이트\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mD27pcHiZWI_"
   },
   "source": [
    "# 모델 선언 및 컴파일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KFsPWvr2ZWI_"
   },
   "source": [
    "## 패딩 및 포워드 마스킹 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZRUx6Ym_ZWI_",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:17:49.421744Z",
     "start_time": "2024-01-16T02:17:49.385137Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_padding_mask(seq):\n",
    "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32)\n",
    "\n",
    "    # add extra dimensions to add the padding\n",
    "    # to the attention logits.\n",
    "    return seq[:, tf.newaxis, tf.newaxis, :]  # (batch_size, 1, 1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mFiIASeDZWI_",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.386523Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_look_ahead_mask(size):\n",
    "    mask = 1 - tf.linalg.band_part(tf.ones((size, size)), -1, 0)\n",
    "    return mask  # (seq_len, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ffRIUXCZZWI_",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.387848Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_masks(inp, tar):\n",
    "    # Encoder padding mask\n",
    "    enc_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 2nd attention block in the decoder.\n",
    "    # This padding mask is used to mask the encoder outputs.\n",
    "    dec_padding_mask = create_padding_mask(inp)\n",
    "\n",
    "    # Used in the 1st attention block in the decoder.\n",
    "    # It is used to pad and mask future tokens in the input received by \n",
    "    # the decoder.\n",
    "    look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1])\n",
    "    dec_target_padding_mask = create_padding_mask(tar)\n",
    "    combined_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask)\n",
    "\n",
    "    return enc_padding_mask, combined_mask, dec_padding_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C_5iQE2xZWI_",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.389202Z"
    }
   },
   "outputs": [],
   "source": [
    "enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(index_inputs, index_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PzS7j3hVZWI_"
   },
   "source": [
    "## 포지셔널 인코딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n5VjDvPPZWI_",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.390752Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_angles(pos, i, d_model):\n",
    "    angle_rates = 1 / np.power(10000, (2 * i//2) / np.float32(d_model))\n",
    "    return pos * angle_rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VkgIxaaEZWI_",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.392317Z"
    }
   },
   "outputs": [],
   "source": [
    "def positional_encoding(position, d_model):\n",
    "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
    "                          np.arange(d_model)[np.newaxis, :],\n",
    "                          d_model)\n",
    "\n",
    "    # apply sin to even indices in the array; 2i\n",
    "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
    "\n",
    "    # apply cos to odd indices in the array; 2i+1\n",
    "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
    "\n",
    "    pos_encoding = angle_rads[np.newaxis, ...]\n",
    "\n",
    "    return tf.cast(pos_encoding, dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "executionInfo": {
     "elapsed": 1386,
     "status": "ok",
     "timestamp": 1684113725906,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     },
     "user_tz": -540
    },
    "id": "Ep07BljJZWI_",
    "outputId": "7db36854-9c5f-40a2-cac8-4575c456f1d8",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.393485Z"
    }
   },
   "outputs": [],
   "source": [
    "pos_encoding = positional_encoding(50, 512)\n",
    "print (pos_encoding.shape)\n",
    "\n",
    "plt.pcolormesh(pos_encoding[0], cmap='RdBu')\n",
    "plt.xlabel('Depth')\n",
    "plt.xlim((0, 512))\n",
    "plt.ylabel('Position')\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "As2YOkrpZWJA"
   },
   "source": [
    "## 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ABJhxHPqZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.395153Z"
    }
   },
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, v, mask):\n",
    "    \"\"\"Calculate the attention weights.\n",
    "    q, k, v must have matching leading dimensions.\n",
    "    k, v must have matching penultimate dimension, i.e.: seq_len_k = seq_len_v.\n",
    "    The mask has different shapes depending on its type(padding or look ahead) \n",
    "    but it must be broadcastable for addition.\n",
    "\n",
    "    Args:\n",
    "    q: query shape == (..., seq_len_q, depth)\n",
    "    k: key shape == (..., seq_len_k, depth)\n",
    "    v: value shape == (..., seq_len_v, depth_v)\n",
    "    mask: Float tensor with shape broadcastable \n",
    "          to (..., seq_len_q, seq_len_k). Defaults to None.\n",
    "\n",
    "    Returns:\n",
    "    output, attention_weights\n",
    "    \"\"\"\n",
    "\n",
    "    matmul_qk = tf.matmul(q, k, transpose_b=True)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    # scale matmul_qk\n",
    "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
    "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
    "\n",
    "    # add the mask to the scaled tensor.\n",
    "    if mask is not None:\n",
    "        scaled_attention_logits += (mask * -1e9)  \n",
    "\n",
    "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
    "    # add up to 1.\n",
    "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1)  # (..., seq_len_q, seq_len_k)\n",
    "\n",
    "    output = tf.matmul(attention_weights, v)  # (..., seq_len_q, depth_v)\n",
    "\n",
    "    return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lH4eSFg6ZWJA"
   },
   "source": [
    "## 멀티헤드 어텐션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "stO8FNWjZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.396584Z"
    }
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttention(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(MultiHeadAttention, self).__init__()\n",
    "        self.num_heads = kargs['num_heads']\n",
    "        self.d_model = kargs['d_model'] # 사이즈 조절 인풋이랑 아웃풋이 사이즈가 같다. 따라서 누적연산 가능\n",
    "\n",
    "        assert self.d_model % self.num_heads == 0\n",
    "\n",
    "        self.depth = self.d_model // self.num_heads\n",
    "\n",
    "        self.wq = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wk = tf.keras.layers.Dense(kargs['d_model'])\n",
    "        self.wv = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "        self.dense = tf.keras.layers.Dense(kargs['d_model'])\n",
    "\n",
    "    def split_heads(self, x, batch_size):\n",
    "        \"\"\"Split the last dimension into (num_heads, depth).\n",
    "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
    "        \"\"\"\n",
    "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth))\n",
    "        return tf.transpose(x, perm=[0, 2, 1, 3])\n",
    "\n",
    "    def call(self, v, k, q, mask):\n",
    "        batch_size = tf.shape(q)[0]\n",
    "\n",
    "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
    "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
    "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
    "\n",
    "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
    "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
    "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
    "\n",
    "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
    "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
    "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
    "            q, k, v, mask)\n",
    "\n",
    "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
    "\n",
    "        concat_attention = tf.reshape(scaled_attention, \n",
    "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
    "\n",
    "        return output, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0DnrE-trZWJA"
   },
   "source": [
    "## 포인트 와이즈 피드포워드 네트워크 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4liXE0IwZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.398059Z"
    }
   },
   "outputs": [],
   "source": [
    "def point_wise_feed_forward_network(**kargs):\n",
    "    return tf.keras.Sequential([\n",
    "      tf.keras.layers.Dense(kargs['dff'], activation='relu'),  # (batch_size, seq_len, dff)\n",
    "      tf.keras.layers.Dense(kargs['d_model'])  # (batch_size, seq_len, d_model)\n",
    "    ])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sDRs3baoZWJA"
   },
   "source": [
    "## 인코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0H35AS-4ZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.399467Z"
    }
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(EncoderLayer, self).__init__()\n",
    "\n",
    "        self.mha = MultiHeadAttention(**kargs)\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn_output, _ = self.mha(x, x, x, mask)  # (batch_size, input_seq_len, d_model)\n",
    "        attn_output = self.dropout1(attn_output)\n",
    "        out1 = self.layernorm1(x + attn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out1)  # (batch_size, input_seq_len, d_model)\n",
    "        ffn_output = self.dropout2(ffn_output)\n",
    "        out2 = self.layernorm2(out1 + ffn_output)  # (batch_size, input_seq_len, d_model)\n",
    "\n",
    "        return out2, attn_output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U2ftyB31ZWJA"
   },
   "source": [
    "## 디코더 레이어"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8V3y8UH9ZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.400563Z"
    }
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(DecoderLayer, self).__init__()\n",
    "\n",
    "        self.mha1 = MultiHeadAttention(**kargs)\n",
    "        self.mha2 = MultiHeadAttention(**kargs)\n",
    "\n",
    "        self.ffn = point_wise_feed_forward_network(**kargs)\n",
    "\n",
    "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
    "\n",
    "        self.dropout1 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout2 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "        self.dropout3 = tf.keras.layers.Dropout(kargs['rate'])\n",
    "    \n",
    "    \n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
    "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn1 = self.dropout1(attn1)\n",
    "        out1 = self.layernorm1(attn1 + x)\n",
    "\n",
    "        attn2, attn_weights_block2 = self.mha2(\n",
    "            enc_output, enc_output, out1, padding_mask)  # (batch_size, target_seq_len, d_model)\n",
    "        attn2 = self.dropout2(attn2)\n",
    "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
    "        ffn_output = self.dropout3(ffn_output)\n",
    "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
    "\n",
    "        return out3, attn_weights_block1, attn_weights_block2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IDLpHnrPZWJA"
   },
   "source": [
    "## 인코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pggdtrTTZWJA",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.401765Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Encoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['input_vocab_size'], self.d_model)\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], \n",
    "                                                self.d_model)\n",
    "\n",
    "\n",
    "        self.enc_layers = [EncoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, mask):\n",
    "        attn = None\n",
    "        seq_len = tf.shape(x)[1]\n",
    "\n",
    "        # adding embedding and position encoding.\n",
    "        x = self.embedding(x)  # (batch_size, input_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :]\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, attn = self.enc_layers[i](x, mask)\n",
    "\n",
    "        return x, attn  # (batch_size, input_seq_len, d_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Uq5dKPjRZWJB"
   },
   "source": [
    "## 디코더"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t8VCazl2ZWJB",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.402528Z"
    }
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.layers.Layer):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Decoder, self).__init__()\n",
    "\n",
    "        self.d_model = kargs['d_model']\n",
    "        self.num_layers = kargs['num_layers']\n",
    "\n",
    "        self.embedding = tf.keras.layers.Embedding(kargs['target_vocab_size'], self.d_model) #\n",
    "        self.pos_encoding = positional_encoding(kargs['maximum_position_encoding'], self.d_model)\n",
    "\n",
    "        self.dec_layers = [DecoderLayer(**kargs) \n",
    "                           for _ in range(self.num_layers)]\n",
    "        self.dropout = tf.keras.layers.Dropout(kargs['rate'])\n",
    "\n",
    "    def call(self, x, enc_output, look_ahead_mask, padding_mask):\n",
    "        seq_len = tf.shape(x)[1]\n",
    "        attention_weights = {}\n",
    "\n",
    "        x = self.embedding(x)  # (batch_size, target_seq_len, d_model)\n",
    "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
    "        x += self.pos_encoding[:, :seq_len, :] # 포지셔널 인코딩 시퀀스만큼만\n",
    "\n",
    "        x = self.dropout(x)\n",
    "        # 인코딩단에 추가 가능\n",
    "\n",
    "        for i in range(self.num_layers):\n",
    "            x, block1, block2 = self.dec_layers[i](x, enc_output, look_ahead_mask, padding_mask)\n",
    "\n",
    "            attention_weights['decoder_layer{}_block1'.format(i+1)] = block1\n",
    "            attention_weights['decoder_layer{}_block2'.format(i+1)] = block2\n",
    "\n",
    "        # x.shape == (batch_size, target_seq_len, d_model)\n",
    "        return x, attention_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1oj1qUTVZWJB"
   },
   "source": [
    "## 트렌스포머 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "in6TKTeMZWJB",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.403583Z"
    }
   },
   "outputs": [],
   "source": [
    "class Transformer(tf.keras.Model):\n",
    "    def __init__(self, **kargs):\n",
    "        super(Transformer, self).__init__(name=kargs['model_name'])\n",
    "        self.end_token_idx = kargs['end_token_idx']\n",
    "        \n",
    "        self.encoder = Encoder(**kargs)\n",
    "        self.decoder = Decoder(**kargs)\n",
    "\n",
    "        self.final_layer = tf.keras.layers.Dense(kargs['target_vocab_size'])\n",
    "\n",
    "    def call(self, x):\n",
    "        inp, tar = x\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "        enc_output, attn = self.encoder(inp, enc_padding_mask)  # (batch_size, inp_seq_len, d_model)\n",
    "\n",
    "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
    "        dec_output, attn = self.decoder(\n",
    "            tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "\n",
    "        final_output = self.final_layer(dec_output)  # (batch_size, tar_seq_len, target_vocab_size)\n",
    "\n",
    "        return final_output, attn\n",
    "    \n",
    "    def inference(self, x):\n",
    "        inp = x\n",
    "        tar = tf.expand_dims([STD_INDEX], 0)\n",
    "\n",
    "        enc_padding_mask, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)        \n",
    "        enc_output = self.encoder(inp, enc_padding_mask)\n",
    "        \n",
    "        predict_tokens = list()\n",
    "        for t in range(0, MAX_SEQUENCE):\n",
    "            dec_output, _ = self.decoder(tar, enc_output, look_ahead_mask, dec_padding_mask)\n",
    "            final_output = self.final_layer(dec_output)\n",
    "            outputs = tf.argmax(final_output, -1).numpy()\n",
    "            pred_token = outputs[0][-1]\n",
    "            if pred_token == self.end_token_idx:\n",
    "                break\n",
    "            predict_tokens.append(pred_token)\n",
    "            tar = tf.expand_dims([STD_INDEX] + predict_tokens, 0)\n",
    "            _, look_ahead_mask, dec_padding_mask = create_masks(inp, tar)\n",
    "            \n",
    "        return predict_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "25Ra5MueZWJB"
   },
   "source": [
    "## 모델 로스 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Yx6GkkzJZWJB",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.404221Z"
    }
   },
   "outputs": [],
   "source": [
    "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
    "    from_logits=True, reduction='none')\n",
    "\n",
    "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='accuracy')\n",
    "\n",
    "def loss(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    loss_ = loss_object(real, pred)\n",
    "\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ *= mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "def accuracy(real, pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
    "    mask = tf.expand_dims(tf.cast(mask, dtype=pred.dtype), axis=-1)\n",
    "    pred *= mask    \n",
    "    acc = train_accuracy(real, pred)\n",
    "    return tf.reduce_mean(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_abxNtXwZWJB",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.404977Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Transformer(**kargs)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=loss,\n",
    "              metrics=[accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wE51PZOZWJB"
   },
   "source": [
    "# Callback 선언"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1684113725907,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     },
     "user_tz": -540
    },
    "id": "_p0kZqRZZWJB",
    "outputId": "b6463da8-3077-43e1-a630-6b01f54e4394",
    "scrolled": false,
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.405783Z"
    }
   },
   "outputs": [],
   "source": [
    "# overfitting을 막기 위한 ealrystop 추가\n",
    "earlystop_callback = EarlyStopping(monitor='val_accuracy', min_delta=0.0001, patience=10)\n",
    "# min_delta: the threshold that triggers the termination (acc should at least improve 0.0001)\n",
    "# patience: no improvment epochs (patience = 1, 1번 이상 상승이 없으면 종료)\n",
    "\n",
    "checkpoint_path = DATA_OUT_PATH + model_name + '/weights.h5'\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "# Create path if exists\n",
    "if os.path.exists(checkpoint_dir):\n",
    "    print(\"{} -- Folder already exists \\n\".format(checkpoint_dir))\n",
    "else:\n",
    "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "    print(\"{} -- Folder create complete \\n\".format(checkpoint_dir))\n",
    "    \n",
    "\n",
    "cp_callback = ModelCheckpoint(\n",
    "    checkpoint_path, monitor='val_accuracy', verbose=1, save_best_only=True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOblTqf5ZWJB"
   },
   "source": [
    "# 모델 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "9706tiVSZWJB",
    "outputId": "4c265964-2d43-4b81-a53f-61bd6fd52396",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.406433Z"
    }
   },
   "outputs": [],
   "source": [
    "history = model.fit([index_inputs, index_outputs], index_targets, \n",
    "                    batch_size=BATCH_SIZE, epochs=EPOCHS,\n",
    "                    validation_split=VALID_SPLIT, callbacks=[earlystop_callback, cp_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B71JzuDyZWJB"
   },
   "source": [
    "# 결과 플롯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "h16igFzAZWJB",
    "outputId": "08e1778b-09c3-46f0-cdb9-16523888ccb4",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.407191Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "SgVaFXeIZWJC",
    "outputId": "3e554e54-feeb-4e2c-aa0b-8a6d64413407",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.408135Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6hncNLJZWJC"
   },
   "source": [
    "# 베스트 모델 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "CjtnWULyZWJC",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.408740Z"
    }
   },
   "outputs": [],
   "source": [
    "SAVE_FILE_NM = 'weights.h5'\n",
    "\n",
    "model.load_weights(os.path.join(DATA_OUT_PATH, model_name, SAVE_FILE_NM))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMI7AV_CZWJC"
   },
   "source": [
    "# 모델 결과 출력하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "Po88hl9lZWJC",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.409312Z"
    }
   },
   "outputs": [],
   "source": [
    "char2idx = prepro_configs['char2idx']\n",
    "idx2char = prepro_configs['idx2char']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "ubwBzYMMZWJC",
    "outputId": "358ddcd4-989e-46e1-a27a-a49cd3a2b10b",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.409955Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"남자친구 승진 선물로 뭐가 좋을까?\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vX8Xu3FvZWJC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1684116171460,
     "user_tz": -540,
     "elapsed": 762,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "7918c3be-e7e3-444b-cb12-37b2a6168013",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.410603Z"
    }
   },
   "outputs": [],
   "source": [
    "text = \"아 배고프다.\"\n",
    "test_index_inputs, _ = enc_processing([text], char2idx)\n",
    "outputs = model.inference(test_index_inputs)\n",
    "\n",
    "print(' '.join([idx2char[str(o)] for o in outputs]))"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "n1t-C_yRJWVs",
    "ExecuteTime": {
     "start_time": "2024-01-16T02:17:49.411291Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
