{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jG82MsD9YPEn",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:44:08.794297Z",
     "start_time": "2024-01-16T02:43:39.630286Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\r\n",
      "  Obtaining dependency information for transformers from https://files.pythonhosted.org/packages/20/0a/739426a81f7635b422fbe6cb8d1d99d1235579a6ac8024c13d743efa6847/transformers-4.36.2-py3-none-any.whl.metadata\r\n",
      "  Downloading transformers-4.36.2-py3-none-any.whl.metadata (126 kB)\r\n",
      "\u001B[2K     \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m126.8/126.8 kB\u001B[0m \u001B[31m708.0 kB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hCollecting datasets\r\n",
      "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/ec/93/454ada0d1b289a0f4a86ac88dbdeab54921becabac45da3da787d136628f/datasets-2.16.1-py3-none-any.whl.metadata\r\n",
      "  Downloading datasets-2.16.1-py3-none-any.whl.metadata (20 kB)\r\n",
      "Requirement already satisfied: filelock in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (3.13.1)\r\n",
      "Collecting huggingface-hub<1.0,>=0.19.3 (from transformers)\r\n",
      "  Obtaining dependency information for huggingface-hub<1.0,>=0.19.3 from https://files.pythonhosted.org/packages/3d/0a/aed3253a9ce63d9c90829b1d36bc44ad966499ff4f5827309099c8c9184b/huggingface_hub-0.20.2-py3-none-any.whl.metadata\r\n",
      "  Downloading huggingface_hub-0.20.2-py3-none-any.whl.metadata (12 kB)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (1.23.2)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (23.1)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (2023.10.3)\r\n",
      "Requirement already satisfied: requests in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (2.31.0)\r\n",
      "Collecting tokenizers<0.19,>=0.14 (from transformers)\r\n",
      "  Obtaining dependency information for tokenizers<0.19,>=0.14 from https://files.pythonhosted.org/packages/9e/2d/35a9f9378962fd954cd097efc0d3b7beee86c12d4e61cf6199bdef58e091/tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl.metadata (6.7 kB)\r\n",
      "Collecting safetensors>=0.3.1 (from transformers)\r\n",
      "  Obtaining dependency information for safetensors>=0.3.1 from https://files.pythonhosted.org/packages/ea/7c/a4a49a22fc082279d36c416f0fe2d89ca558fd214ab9e9afd889dfb8180f/safetensors-0.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading safetensors-0.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.8 kB)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from transformers) (4.66.1)\r\n",
      "Collecting pyarrow>=8.0.0 (from datasets)\r\n",
      "  Obtaining dependency information for pyarrow>=8.0.0 from https://files.pythonhosted.org/packages/4a/11/1c2d07b7e14bf3501b8946691e3df26302b71adb40fd24cc4056f78d3bcb/pyarrow-14.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading pyarrow-14.0.2-cp39-cp39-macosx_11_0_arm64.whl.metadata (3.0 kB)\r\n",
      "Collecting pyarrow-hotfix (from datasets)\r\n",
      "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\r\n",
      "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\r\n",
      "Collecting dill<0.3.8,>=0.3.0 (from datasets)\r\n",
      "  Obtaining dependency information for dill<0.3.8,>=0.3.0 from https://files.pythonhosted.org/packages/f5/3a/74a29b11cf2cdfcd6ba89c0cecd70b37cd1ba7b77978ce611eb7a146a832/dill-0.3.7-py3-none-any.whl.metadata\r\n",
      "  Downloading dill-0.3.7-py3-none-any.whl.metadata (9.9 kB)\r\n",
      "Requirement already satisfied: pandas in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from datasets) (2.1.1)\r\n",
      "Collecting xxhash (from datasets)\r\n",
      "  Obtaining dependency information for xxhash from https://files.pythonhosted.org/packages/a4/24/8092b5db6d459cb9e62409edfebb0253b3760d9ab7e4c52e5493c3b026b1/xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting multiprocess (from datasets)\r\n",
      "  Obtaining dependency information for multiprocess from https://files.pythonhosted.org/packages/c6/c9/820b5ab056f4ada76fbe05bd481a948f287957d6cbfd59e2dd2618b408c1/multiprocess-0.70.15-py39-none-any.whl.metadata\r\n",
      "  Downloading multiprocess-0.70.15-py39-none-any.whl.metadata (7.2 kB)\r\n",
      "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\r\n",
      "  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\r\n",
      "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\r\n",
      "Collecting aiohttp (from datasets)\r\n",
      "  Obtaining dependency information for aiohttp from https://files.pythonhosted.org/packages/69/73/bda9aba49fa741c5390368e91a9a36012041f48d542772af097c43dd0963/aiohttp-3.9.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading aiohttp-3.9.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (7.4 kB)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp->datasets) (22.1.0)\r\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp->datasets)\r\n",
      "  Downloading multidict-6.0.4-cp39-cp39-macosx_11_0_arm64.whl (29 kB)\r\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp->datasets)\r\n",
      "  Obtaining dependency information for yarl<2.0,>=1.0 from https://files.pythonhosted.org/packages/f9/b0/c213007560d001c9908649ff4b1dd11d1ff388235e773828e19d4637f502/yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl.metadata (31 kB)\r\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp->datasets)\r\n",
      "  Obtaining dependency information for frozenlist>=1.1.1 from https://files.pythonhosted.org/packages/8b/c9/a81e9af48291954a883d35686f32308238dc968043143133b8ac9e2772af/frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata\r\n",
      "  Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl.metadata (12 kB)\r\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp->datasets)\r\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\r\n",
      "Collecting async-timeout<5.0,>=4.0 (from aiohttp->datasets)\r\n",
      "  Obtaining dependency information for async-timeout<5.0,>=4.0 from https://files.pythonhosted.org/packages/a7/fa/e01228c2938de91d47b307831c62ab9e4001e747789d0b05baf779a6488c/async_timeout-4.0.3-py3-none-any.whl.metadata\r\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.7.1)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests->transformers) (1.26.16)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pandas->datasets) (2.8.2)\r\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pandas->datasets) (2022.7)\r\n",
      "Requirement already satisfied: tzdata>=2022.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pandas->datasets) (2023.3)\r\n",
      "Requirement already satisfied: six>=1.5 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.15.0)\r\n",
      "Downloading transformers-4.36.2-py3-none-any.whl (8.2 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m8.2/8.2 MB\u001B[0m \u001B[31m1.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading datasets-2.16.1-py3-none-any.whl (507 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m507.1/507.1 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading dill-0.3.7-py3-none-any.whl (115 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m115.3/115.3 kB\u001B[0m \u001B[31m3.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading aiohttp-3.9.1-cp39-cp39-macosx_11_0_arm64.whl (387 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m387.3/387.3 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading huggingface_hub-0.20.2-py3-none-any.whl (330 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m330.3/330.3 kB\u001B[0m \u001B[31m2.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow-14.0.2-cp39-cp39-macosx_11_0_arm64.whl (24.0 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m24.0/24.0 MB\u001B[0m \u001B[31m2.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading safetensors-0.4.1-cp39-cp39-macosx_11_0_arm64.whl (426 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m426.1/426.1 kB\u001B[0m \u001B[31m3.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0mm\r\n",
      "\u001B[?25hDownloading tokenizers-0.15.0-cp39-cp39-macosx_11_0_arm64.whl (2.5 MB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m2.5/2.5 MB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading multiprocess-0.70.15-py39-none-any.whl (133 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m133.3/133.3 kB\u001B[0m \u001B[31m8.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\r\n",
      "Downloading xxhash-3.4.1-cp39-cp39-macosx_11_0_arm64.whl (30 kB)\r\n",
      "Downloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\r\n",
      "Downloading frozenlist-1.4.1-cp39-cp39-macosx_11_0_arm64.whl (53 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m53.7/53.7 kB\u001B[0m \u001B[31m6.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hDownloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m166.4/166.4 kB\u001B[0m \u001B[31m2.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m0:01\u001B[0m\r\n",
      "\u001B[?25hDownloading yarl-1.9.4-cp39-cp39-macosx_11_0_arm64.whl (81 kB)\r\n",
      "\u001B[2K   \u001B[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001B[0m \u001B[32m81.8/81.8 kB\u001B[0m \u001B[31m3.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: xxhash, safetensors, pyarrow-hotfix, pyarrow, multidict, fsspec, frozenlist, dill, async-timeout, yarl, multiprocess, huggingface-hub, aiosignal, tokenizers, aiohttp, transformers, datasets\r\n",
      "Successfully installed aiohttp-3.9.1 aiosignal-1.3.1 async-timeout-4.0.3 datasets-2.16.1 dill-0.3.7 frozenlist-1.4.1 fsspec-2023.10.0 huggingface-hub-0.20.2 multidict-6.0.4 multiprocess-0.70.15 pyarrow-14.0.2 pyarrow-hotfix-0.6 safetensors-0.4.1 tokenizers-0.15.0 transformers-4.36.2 xxhash-3.4.1 yarl-1.9.4\r\n"
     ]
    }
   ],
   "source": [
    "# Transformers installation\n",
    "! pip install transformers datasets\n",
    "# To install from source instead of the last release, comment the command above and uncomment the following one.\n",
    "# ! pip install git+https://github.com/huggingface/transformers.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bWIi6sDrYPEo"
   },
   "source": [
    "# Fine-tune a pretrained model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pt768tyUYPEp"
   },
   "source": [
    "ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ë©´ ìƒë‹¹í•œ ì´ì ì´ ìˆìŠµë‹ˆë‹¤. ê³„ì‚° ë¹„ìš©ê³¼ íƒ„ì†Œ ë°°ì¶œëŸ‰ì„ ì¤„ì´ê³  ì²˜ìŒë¶€í„° í›ˆë ¨í•˜ì§€ ì•Šê³ ë„ ìµœì‹  ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ğŸ¤— TransformersëŠ” ë‹¤ì–‘í•œ ì‘ì—…ì„ ìœ„í•´ ìˆ˜ì²œ ê°œì˜ ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì— ëŒ€í•œ ì•¡ì„¸ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ì‚¬ìš©í•˜ëŠ” ê²½ìš° ì‘ì—…ì— íŠ¹ì •í•œ ë°ì´í„° ì„¸íŠ¸ì—ì„œ ëª¨ë¸ì„ í›ˆë ¨í•©ë‹ˆë‹¤. ì´ íŠœí† ë¦¬ì–¼ì—ì„œëŠ” ì„ íƒí•œ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬ë¡œ ì‚¬ì „ í•™ìŠµëœ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤.\n",
    "\n",
    "* Fine-tune a pretrained model with ğŸ¤— Transformers [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer).\n",
    "* Fine-tune a pretrained model in TensorFlow with Keras.\n",
    "\n",
    "<a id='data-processing'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ad9QLLWYPEq"
   },
   "source": [
    "## Prepare a dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DzFuIrndYPEq"
   },
   "source": [
    "ì‚¬ì „ í›ˆë ¨ëœ ëª¨ë¸ì„ ë¯¸ì„¸ ì¡°ì •í•˜ê¸° ì „ì— ë°ì´í„° ì„¸íŠ¸ë¥¼ ë‹¤ìš´ë¡œë“œí•˜ê³  í›ˆë ¨ì„ ìœ„í•´ ì¤€ë¹„í•˜ì„¸ìš”. \n",
    "\n",
    "Begin by loading the [Yelp Reviews](https://huggingface.co/datasets/yelp_review_full) dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "DnOWzpWgYPEq",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:46:07.901056Z",
     "start_time": "2024-01-16T02:44:13.588054Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Downloading readme:   0%|          | 0.00/6.72k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a751b94981d6445d9924cb88d86eb4ed"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/299M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "19349f2d560048a69acd802334eaa892"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Downloading data:   0%|          | 0.00/23.5M [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2381717df87548c9bed86dd27aca3d56"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating train split:   0%|          | 0/650000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "cebc73da927a484d89f5b64b229165cf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Generating test split:   0%|          | 0/50000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c8012e6f4da84bf8963ee1ea94083fc8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "{'label': 0,\n 'text': 'My expectations for McDonalds are t rarely high. But for one to still fail so spectacularly...that takes something special!\\\\nThe cashier took my friends\\'s order, then promptly ignored me. I had to force myself in front of a cashier who opened his register to wait on the person BEHIND me. I waited over five minutes for a gigantic order that included precisely one kid\\'s meal. After watching two people who ordered after me be handed their food, I asked where mine was. The manager started yelling at the cashiers for \\\\\"serving off their orders\\\\\" when they didn\\'t have their food. But neither cashier was anywhere near those controls, and the manager was the one serving food to customers and clearing the boards.\\\\nThe manager was rude when giving me my order. She didn\\'t make sure that I had everything ON MY RECEIPT, and never even had the decency to apologize that I felt I was getting poor service.\\\\nI\\'ve eaten at various McDonalds restaurants for over 30 years. I\\'ve worked at more than one location. I expect bad days, bad moods, and the occasional mistake. But I have yet to have a decent experience at this store. It will remain a place I avoid unless someone in my party needs to avoid illness from low blood sugar. Perhaps I should go back to the racially biased service of Steak n Shake instead!'}"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"yelp_review_full\")\n",
    "dataset[\"train\"][100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q98PAZXeYPEr"
   },
   "source": [
    "í…ìŠ¤íŠ¸ë¥¼ ì²˜ë¦¬í•˜ê³  ê°€ë³€ ì‹œí€€ìŠ¤ ê¸¸ì´ë¥¼ ì²˜ë¦¬í•˜ê¸° ìœ„í•œ íŒ¨ë”© ë° truncation ì „ëµì„ í¬í•¨í•˜ë ¤ë©´ í† í¬ë‚˜ì´ì €ê°€ í•„ìš”í•©ë‹ˆë‹¤. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "PcQAADoWYPEr",
    "ExecuteTime": {
     "end_time": "2024-01-16T02:47:57.994127Z",
     "start_time": "2024-01-16T02:46:07.900712Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "tokenizer_config.json:   0%|          | 0.00/29.0 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7bf6a748a51c44a4a6c2d6b58d54dc59"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "818f4667a7d14e5284719742049053ae"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "vocab.txt:   0%|          | 0.00/213k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f81803d9bc74fd2940d6c9369af820a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "tokenizer.json:   0%|          | 0.00/436k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f8c5710510944a38888731558802ddb0"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/650000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26655bb3880a4d2492887372fb68a70d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Map:   0%|          | 0/50000 [00:00<?, ? examples/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "29569bfcd64d47368575aa57518ff47b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True)\n",
    "\n",
    "\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hUSU1cTkYPEr"
   },
   "source": [
    "ì›í•˜ëŠ” ê²½ìš° ì „ì²´ ë°ì´í„° ì„¸íŠ¸ì˜ ë” ì‘ì€ í•˜ìœ„ ì§‘í•©ì„ ë§Œë“¤ì–´ ë¯¸ì„¸ ì¡°ì •í•˜ì—¬ ì†Œìš” ì‹œê°„ì„ ì¤„ì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wFprVB42YPEr",
    "ExecuteTime": {
     "start_time": "2024-01-16T03:06:25.449344Z"
    }
   },
   "outputs": [],
   "source": [
    "small_train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
    "small_eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cMZ9jGOBYPEs"
   },
   "source": [
    "<a id='trainer'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SralBKDRYPEs"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q0s0gHSwYPEs"
   },
   "source": [
    "ğŸ¤— TransformersëŠ” êµìœ¡ì— ìµœì í™”ëœ [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) í´ë˜ìŠ¤ë¥¼ ì œê³µí•©ë‹ˆë‹¤. ìì‹ ì˜ í›ˆë ¨ ë£¨í”„. [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) APIëŠ” ë¡œê¹…, ê¸°ìš¸ê¸° ëˆ„ì , í˜¼í•© ì •ë°€ë„ì™€ ê°™ì€ ë‹¤ì–‘í•œ í›ˆë ¨ ì˜µì…˜ê³¼ ê¸°ëŠ¥ì„ ì§€ì›í•©ë‹ˆë‹¤.\n",
    "\n",
    "ëª¨ë¸ì„ ë¡œë“œí•˜ì—¬ ì‹œì‘í•˜ê³  ì˜ˆìƒ ë ˆì´ë¸” ìˆ˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤. Yelp Review [ë°ì´í„° ì„¸íŠ¸ ì¹´ë“œ](https://huggingface.co/datasets/yelp_review_full#data-fields)ì—ì„œ 5ê°œì˜ ë ˆì´ë¸”ì´ ìˆìŒì„ ì•Œ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OyFEy_lQYPEs",
    "ExecuteTime": {
     "start_time": "2024-01-16T03:06:25.449437Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQwEc4UJYPEs"
   },
   "source": [
    "### Training hyperparameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cF-akgyNYPEs"
   },
   "source": [
    "ë‹¤ìŒìœ¼ë¡œ ì¡°ì •í•  ìˆ˜ ìˆëŠ” ëª¨ë“  í•˜ì´í¼íŒŒë¼ë¯¸í„°ì™€ ë‹¤ì–‘í•œ í›ˆë ¨ ì˜µì…˜ì„ í™œì„±í™”í•˜ê¸° ìœ„í•œ í”Œë˜ê·¸ê°€ í¬í•¨ëœ [TrainingArguments](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments) í´ë˜ìŠ¤ë¥¼ ë§Œë“­ë‹ˆë‹¤. \n",
    "\n",
    "ì´ íŠœí† ë¦¬ì–¼ì˜ ê²½ìš° ê¸°ë³¸ [í•˜ì´í¼íŒŒë¼ë¯¸í„°](https://huggingface.co/docs/transformers/main_classes/trainer#transformers.TrainingArguments)ë¡œ ì‹œì‘í•  ìˆ˜ ìˆì§€ë§Œ ììœ ë¡­ê²Œ ì‹¤í—˜í•˜ì—¬ ìµœì ì˜ ì„¤ì •ì„ ì°¾ìœ¼ì‹­ì‹œì˜¤.\n",
    "\n",
    "êµìœ¡ì—ì„œ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì €ì¥í•  ìœ„ì¹˜ë¥¼ ì§€ì •í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "BHE2m__mYPEs",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:00:47.737858Z",
     "start_time": "2024-01-16T03:00:47.687284Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBlN8CxeYPEs"
   },
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wftvJTpUYPEt"
   },
   "source": [
    "[íŠ¸ë ˆì´ë„ˆ](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)ëŠ” íŠ¸ë ˆì´ë‹ ì¤‘ì— ëª¨ë¸ ì„±ëŠ¥ì„ ìë™ìœ¼ë¡œ í‰ê°€í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. ë©”íŠ¸ë¦­ì„ ê³„ì‚°í•˜ê³  ë³´ê³ í•˜ë ¤ë©´ [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)ì— í•¨ìˆ˜ë¥¼ ì „ë‹¬í•´ì•¼ í•©ë‹ˆë‹¤. ğŸ¤— ë°ì´í„°ì…‹ ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œëŠ” `load_metric`(ìì„¸í•œ ë‚´ìš©ì€ ì´ [íŠœí† ë¦¬ì–¼](https://huggingface.co/docs/datasets/metrics.html) í•¨ìˆ˜ë¥¼ ì°¸ì¡°í•˜ì„¸ìš”) í•¨ìˆ˜ì™€ í•¨ê»˜ ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê°„ë‹¨í•œ [`accuracy`](https://huggingface.co/metrics/accuracy) í•¨ìˆ˜ë¥¼ ì œê³µí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "E3YrEnhoYPEt",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:00:54.089232Z",
     "start_time": "2024-01-16T03:00:49.696589Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/sv3y8crx3jx6kn5k220bs8bh0000gn/T/ipykernel_66702/2135776078.py:4: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ğŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"accuracy\")\n",
      "/Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages/datasets/load.py:752: FutureWarning: The repository for accuracy contains custom code which must be executed to correctly load the metric. You can inspect the repository content at https://raw.githubusercontent.com/huggingface/datasets/2.16.1/metrics/accuracy/accuracy.py\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this metric from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "Downloading builder script:   0%|          | 0.00/1.65k [00:00<?, ?B/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "88cdf1f54be2482e9e4b5807e52db959"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datasets import load_metric\n",
    "\n",
    "metric = load_metric(\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0T4dE7SdYPEt"
   },
   "source": [
    "`metric`ì—ì„œ `compute`ë¥¼ í˜¸ì¶œí•˜ì—¬ ì˜ˆì¸¡ì˜ ì •í™•ë„ë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤. ê³„ì‚°`ì— ì˜ˆì¸¡ì„ ì „ë‹¬í•˜ê¸° ì „ì— ì˜ˆì¸¡ì„ ë¡œê·¸ë¡œ ë³€í™˜í•´ì•¼ í•©ë‹ˆë‹¤(ëª¨ë“  ğŸ¤— íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ ë¡œê·¸ë¥¼ ë°˜í™˜í•œë‹¤ëŠ” ì ì„ ê¸°ì–µí•˜ì„¸ìš”):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "qsu8oe3mYPEt",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:00:54.114702Z",
     "start_time": "2024-01-16T03:00:54.089927Z"
    }
   },
   "outputs": [],
   "source": [
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uBLY7W2fYPEt"
   },
   "source": [
    "ë¯¸ì„¸ ì¡°ì • ì¤‘ì— í‰ê°€ ì§€í‘œë¥¼ ëª¨ë‹ˆí„°ë§í•˜ë ¤ë©´ í›ˆë ¨ ì¸ìˆ˜ì— `evaluation_strategy` ë§¤ê°œ ë³€ìˆ˜ë¥¼ ì§€ì •í•˜ì—¬ ê° ì—í¬í¬ê°€ ëë‚  ë•Œ í‰ê°€ ì§€í‘œë¥¼ ë³´ê³ í•˜ì„¸ìš”:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "90PrvJHuYPEt",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:00:54.141517Z",
     "start_time": "2024-01-16T03:00:54.101541Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "\n",
    "training_args = TrainingArguments(output_dir=\"test_trainer\", evaluation_strategy=\"epoch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PvIl7C95YPEt"
   },
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "veLNmLXPYPEt"
   },
   "source": [
    "ëª¨ë¸, í›ˆë ¨ ì¸ìˆ˜, í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ì„¸íŠ¸, í‰ê°€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ [Trainer](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer) ê°œì²´ë¥¼ ë§Œë“­ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "LB34Rs1CYPEt",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:00:54.209357Z",
     "start_time": "2024-01-16T03:00:54.135827Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[10], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m trainer \u001B[38;5;241m=\u001B[39m Trainer(\n\u001B[0;32m----> 2\u001B[0m     model\u001B[38;5;241m=\u001B[39m\u001B[43mmodel\u001B[49m,\n\u001B[1;32m      3\u001B[0m     args\u001B[38;5;241m=\u001B[39mtraining_args,\n\u001B[1;32m      4\u001B[0m     train_dataset\u001B[38;5;241m=\u001B[39msmall_train_dataset,\n\u001B[1;32m      5\u001B[0m     eval_dataset\u001B[38;5;241m=\u001B[39msmall_eval_dataset,\n\u001B[1;32m      6\u001B[0m     compute_metrics\u001B[38;5;241m=\u001B[39mcompute_metrics,\n\u001B[1;32m      7\u001B[0m )\n",
      "\u001B[0;31mNameError\u001B[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=small_train_dataset,\n",
    "    eval_dataset=small_eval_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lNkIhvl5YPEt"
   },
   "source": [
    "Then fine-tune your model by calling [train()](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer.train):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "64mBHIIwYPEt",
    "ExecuteTime": {
     "start_time": "2024-01-16T03:00:54.197997Z"
    }
   },
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "co9uV5XpYPEt"
   },
   "source": [
    "<a id='keras'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WSqrmVbMYPEt"
   },
   "source": [
    "ğŸ¤— íŠ¸ëœìŠ¤í¬ë¨¸ ëª¨ë¸ì€ Keras APIë¥¼ í†µí•´ í…ì„œí”Œë¡œìš°ì˜ íŠ¸ë ˆì´ë‹ë„ ì§€ì›í•©ë‹ˆë‹¤."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_QMc_CsmYPEt"
   },
   "source": [
    "### Convert dataset to TensorFlow format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "81RTdn7VYPEt"
   },
   "source": [
    "[DefaultDataCollator](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DefaultDataCollator)ëŠ” ëª¨ë¸ì´ í•™ìŠµí•  í…ì„œë¥¼ ì¼ê´„ ì²˜ë¦¬ë¡œ ì¡°ë¦½í•©ë‹ˆë‹¤. í…ì„œí”Œë¡œ í…ì„œë¥¼ ë°˜í™˜í•˜ë ¤ë©´ `return_tensors`ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "43IPsyWoYPEt",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:01:00.341024Z",
     "start_time": "2024-01-16T03:00:54.389419Z"
    }
   },
   "outputs": [],
   "source": [
    "from transformers import DefaultDataCollator\n",
    "\n",
    "data_collator = DefaultDataCollator(return_tensors=\"tf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYwPhTJsYPEt"
   },
   "source": [
    "<Tip>\n",
    "\n",
    "[íŠ¸ë ˆì´ë„ˆ](https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.Trainer)ëŠ” ê¸°ë³¸ì ìœ¼ë¡œ [DataCollatorWithPadding](https://huggingface.co/docs/transformers/main/en/main_classes/data_collator#transformers.DataCollatorWithPadding)ì„ ì‚¬ìš©í•˜ë¯€ë¡œ ë°ì´í„° ì½œë ˆì´í„°ë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì§€ì •í•  í•„ìš”ê°€ ì—†ìŠµë‹ˆë‹¤.\n",
    "\n",
    "</Tip>\n",
    "\n",
    "ë‹¤ìŒìœ¼ë¡œ, [`to_tf_dataset`](https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.to_tf_dataset) ë©”ì„œë“œë¥¼ ì‚¬ìš©í•˜ì—¬ í† í°í™”ëœ ë°ì´í„°ì…‹ì„ í…ì„œí”Œë¡œ ë°ì´í„°ì…‹ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤. ì…ë ¥ì€ `columns`ì—, ë ˆì´ë¸”ì€ `label_cols`ì— ì§€ì •í•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ECvyhmAnYPEu",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:01:02.093316Z",
     "start_time": "2024-01-16T03:01:00.343781Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages/datasets/arrow_dataset.py:400: FutureWarning: The output of `to_tf_dataset` will change when a passing single element list for `labels` or `columns` in the next datasets version. To return a tuple structure rather than dict, pass a single string.\n",
      "Old behaviour: columns=['a'], labels=['labels'] -> (tf.Tensor, tf.Tensor)  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor)  \n",
      "New behaviour: columns=['a'],labels=['labels'] -> ({'a': tf.Tensor}, {'labels': tf.Tensor})  \n",
      "             : columns='a', labels='labels' -> (tf.Tensor, tf.Tensor) \n",
      "  warnings.warn(\n",
      "2024-01-16 12:01:00.375512: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-01-16 12:01:00.376493: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    }
   ],
   "source": [
    "tf_train_dataset = small_train_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "\n",
    "tf_validation_dataset = small_eval_dataset.to_tf_dataset(\n",
    "    columns=[\"attention_mask\", \"input_ids\", \"token_type_ids\"],\n",
    "    label_cols=[\"labels\"],\n",
    "    shuffle=False,\n",
    "    collate_fn=data_collator, # mapí•©ìˆ˜ì— í•´ë‹¹ í† ì¹˜í…ì„œë¥¼ í…ì„œí”Œë¡œìš° í…ì„œë¡œ ë³€í™˜í•˜ëŠ” í•¨ìˆ˜ë¥¼ ë„£ì–´ì¤€ë‹¤.\n",
    "    batch_size=8,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTrHUaH3YPEu"
   },
   "source": [
    "### Compile and fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tUYOaT9SYPEu"
   },
   "source": [
    "ì˜ˆìƒ ë ˆì´ë¸” ìˆ˜ë¡œ TensorFlow ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤:"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"bert-base-cased\", num_labels=5)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-16T03:11:25.990439Z",
     "start_time": "2024-01-16T03:11:21.308632Z"
    }
   },
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "source": [
    "ê·¸ëŸ° ë‹¤ìŒ ë‹¤ë¥¸ Keras ëª¨ë¸ê³¼ ë§ˆì°¬ê°€ì§€ë¡œ [`fit`](https://keras.io/api/models/model_training_apis/)ì„ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ ì»´íŒŒì¼í•˜ê³  ë¯¸ì„¸ ì¡°ì •í•©ë‹ˆë‹¤:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "lZumOFlOYPEu",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:13:11.899375Z",
     "start_time": "2024-01-16T03:11:33.009020Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-16 12:11:39.279207: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4/125 [..............................] - ETA: 36:08 - loss: 1.7206 - sparse_categorical_accuracy: 0.1562"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[16], line 7\u001B[0m\n\u001B[1;32m      1\u001B[0m model\u001B[38;5;241m.\u001B[39mcompile(\n\u001B[1;32m      2\u001B[0m     optimizer\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39moptimizers\u001B[38;5;241m.\u001B[39mAdam(learning_rate\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m5e-5\u001B[39m),\n\u001B[1;32m      3\u001B[0m     loss\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mkeras\u001B[38;5;241m.\u001B[39mlosses\u001B[38;5;241m.\u001B[39mSparseCategoricalCrossentropy(from_logits\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m),\n\u001B[1;32m      4\u001B[0m     metrics\u001B[38;5;241m=\u001B[39mtf\u001B[38;5;241m.\u001B[39mmetrics\u001B[38;5;241m.\u001B[39mSparseCategoricalAccuracy(),\n\u001B[1;32m      5\u001B[0m )\n\u001B[0;32m----> 7\u001B[0m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtf_train_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mtf_validation_dataset\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/keras/engine/training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1562\u001B[0m ):\n\u001B[1;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2494\u001B[0m   (graph_function,\n\u001B[1;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1865\u001B[0m     args,\n\u001B[1;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1867\u001B[0m     executing_eagerly)\n\u001B[1;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=5e-5),\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "    metrics=tf.metrics.SparseCategoricalAccuracy(),\n",
    ")\n",
    "\n",
    "model.fit(tf_train_dataset, validation_data=tf_validation_dataset, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0ihxfklkYPEu"
   },
   "source": [
    "<a id='pytorch_native'></a>"
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "SbGfBzrrZMrs",
    "ExecuteTime": {
     "end_time": "2024-01-16T03:06:25.449806Z",
     "start_time": "2024-01-16T03:06:25.448742Z"
    }
   },
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/huggingface/notebooks/blob/master/transformers_doc/training.ipynb",
     "timestamp": 1683448994633
    }
   ],
   "machine_shape": "hm",
   "gpuType": "T4",
   "collapsed_sections": [
    "_QMc_CsmYPEt",
    "FTrHUaH3YPEu"
   ]
  },
  "accelerator": "GPU",
  "gpuClass": "standard",
  "language_info": {
   "name": "python"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
