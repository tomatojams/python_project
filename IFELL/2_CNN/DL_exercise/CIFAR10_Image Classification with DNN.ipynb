{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXYH9ESLRRLY"
   },
   "source": [
    "# Image Classification\n",
    "\n",
    "tf.data.Dataset을 이용해 모델이 데이터를 효율적으로 활용할 수 있도록 구현해보는게 목적입니다.\n",
    "\n",
    "기본적인 머신러닝 작업과정은 아래와 같습니다.\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Test the model\n",
    "6. Improve the model and repeat the process\n",
    "\n",
    "* 모델 완성 후 평가 지표에 따라서 모델을 평가해 봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjTHjdo6RS3n"
   },
   "source": [
    "## Project 설명\n",
    "### Task\n",
    "* CIFAR 10 데이터셋을 이용해 classification을 진행해보자.\n",
    "* [CIFAR 10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "### Baseline\n",
    "* 오버피팅을 방지하기 위한 다양한 방법들을 사용해보자.\n",
    "    * 하이퍼파라미터 조절 (데이터 로드, 모델, Optimizer 등)\n",
    "    * 모델 구성 변경 (layer의 갯수)\n",
    "* Training\n",
    "    * tf.data.Dataset 과 model.fit()을 사용\n",
    "\n",
    "* Evaluation\n",
    "    * 모델의 정확도와 크기를 이용해 점수를 제공하는 메트릭으로 평가해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9Bg8w9j0PZ"
   },
   "source": [
    "### 구글 드라이브 마운트\n",
    "* Google의 Colab과 Drive를 이용해 노트북을 이용해 언제 어디서든 딥러닝 모델을 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RRYFNY5jjzWF",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:13.547961Z",
     "start_time": "2023-12-27T06:42:13.465787Z"
    }
   },
   "source": [
    "# 코드 호환성을 위한 분기\n",
    "use_colab = True\n",
    "assert use_colab in [True, False]"
   ],
   "execution_count": 173,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6vefMxCgj2U6",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:13.564022Z",
     "start_time": "2023-12-27T06:42:13.551213Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 174,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2qZQXTBcM6t"
   },
   "source": [
    "### 번외) GPU 서버를 어떻게 구성하면 좋을까?\n",
    "1. 로컬 머신 (노트북, 데스크탑) 구매\n",
    "    * GPU 노트북, 데스크탑, 서버 등 원하는 방법으로 다양하게 구비할 수 있다.\n",
    "    * Colab과 다르게 세션이 종료되지않으며, 비교적 자유롭게 사용할 수 있다.\n",
    "    * 원격 접속 및 오프라인 관리가 어려우며, 부수적인 유지보수 비용이 발생한다.\n",
    "\n",
    "2. 클라우드 등 서버 사용\n",
    "    * AWS, 네이버 클라우드 등\n",
    "    * 오프라인 관리가 필요없으며, 안정적이다.\n",
    "    * 비싸다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Due8naADzEZc"
   },
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TlUX4NtWRL5b",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:13.614660Z",
     "start_time": "2023-12-27T06:42:13.571143Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow.keras.losses\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 175,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjsldx-rzIfG"
   },
   "source": [
    "### load data\n",
    "* CIFAR 10 dataset을 로드한다. (npy)\n",
    "* 학습에 사용되는 대표적인 데이터셋들은 프레임워크내 코드로 제공된다.\n",
    "\n",
    "```\n",
    "tf.keras.dataset.cifar10\n",
    "tf.keras.dataset.cifar100\n",
    "tf.keras.dataset.mnist\n",
    "tf.keras.dataset.fashion_mnist\n",
    "tf.keras.dataset.imdb\n",
    "\n",
    "```\n",
    "\n",
    "* 다양한 데이터셋을 쉽게 가져와 사용할 수 있다.\n",
    "\n",
    "### 데이터셋 사용방법\n",
    "* Data split\n",
    "    * sklearn (머신러닝 프레임워크)를 이용해 데이터를 손쉽게 나눌 수 있다.\n",
    "\n",
    "```\n",
    "test_data_split, valid_data, test_labels_split, valid_labels = \\\n",
    "    train_test_split(test_data, test_labels, test_size=0.2, shuffle=True)\n",
    "```\n",
    "\n",
    "* test_size를 조절해 원하는 크기만큼의 데이터를 분리해 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C5QyC6CZMgLT",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:13.987791Z",
     "start_time": "2023-12-27T06:42:13.591924Z"
    }
   },
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.cifar10.load_data()"
   ],
   "execution_count": 176,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_bshB8j2Qu3Z",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:13.987926Z",
     "start_time": "2023-12-27T06:42:13.965416Z"
    }
   },
   "source": [
    "# !cd /root/.keras/datasets/ && ls -al"
   ],
   "execution_count": 177,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fKduNOW08ugw",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:14.004840Z",
     "start_time": "2023-12-27T06:42:13.977362Z"
    }
   },
   "source": [
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(test_labels[0]) # 데이터셋 제작할때, [3] => 3 으로 데이터 형태를 변경해줘야합니다."
   ],
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n",
      "[3]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "INZN9eNPRL5h",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:15.111932Z",
     "start_time": "2023-12-27T06:42:13.985761Z"
    }
   },
   "source": [
    "test_data, valid_data, test_labels, valid_labels = \\\n",
    "    train_test_split(test_data, test_labels, test_size=0.1, shuffle=True) # 0~1의 값으로 줍니다.\n",
    "# test_size => 0.1 = 10%\n",
    "# test_size => 0.2 = 20%\n",
    "\n",
    "# raw data normalization\n",
    "# RGB 값이 0~255 사이 값인 것을 이용해 Normalization 진행\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape([-1,32,32,3])\n",
    "train_labels = train_labels.reshape([-1])\n",
    "\n",
    "valid_data = valid_data / 255.\n",
    "valid_data = valid_data.reshape([-1,32,32,3])\n",
    "valid_labels = valid_labels.reshape([-1])\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape([-1,32,32,3])\n",
    "test_labels = test_labels.reshape([-1])\n"
   ],
   "execution_count": 179,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nd8fwv5AeaFy",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:15.126885Z",
     "start_time": "2023-12-27T06:42:15.088012Z"
    }
   },
   "source": [
    "# [데이터수, 32, 32, 3] [데이터수,]\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(valid_data.shape, valid_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ],
   "execution_count": 180,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000,)\n",
      "(1000, 32, 32, 3) (1000,)\n",
      "(9000, 32, 32, 3) (9000,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_5B8vqPzNYY"
   },
   "source": [
    "### dataset 구성\n",
    "* tf.data.Dataset을 이용해 데이터셋을 구성한다.\n",
    "    * 위에서 불러온 raw data (cifar10) 데이터셋을 모델이 학습 할 수 있도록 전달해 주는 데이터셋이다.\n",
    "* tf data Dataset을 사용해야하는 이유?\n",
    "    * 직접 Generator를 작성할 필요가 없다\n",
    "    * map 함수를 이용해 전처리 과정을 직접 조절할 수 있다.\n",
    "    * 메모리에 부담이 되지 않게 동작한다.\n",
    "\n",
    "\n",
    "### 직접 적용해보자\n",
    "* map 함수를 적용할 함수 구현 후 dataset을 구현하며 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KB2O5Gf8RL5n",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:15.175847Z",
     "start_time": "2023-12-27T06:42:15.101720Z"
    }
   },
   "source": [
    "def one_hot_label(image, label): # label => one_hot\n",
    "  label = tf.one_hot(label, depth=10)\n",
    "  return image, label"
   ],
   "execution_count": 181,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQuarDIdj0nn"
   },
   "source": [
    "* 위 one_hot_label 함수는 아래와 같이 동작한다.\n",
    "# one_hot vector 예시\n",
    "\n",
    "```Python\n",
    "tf.one_hot(\n",
    "    indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None\n",
    ")\n",
    "\n",
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "# [[1., 0., 0.],\n",
    "#  [0., 1., 0.],\n",
    "#  [0., 0., 1.]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl0pvav6kJMT"
   },
   "source": [
    "### map 함수를 포함한 dataset 구성\n",
    "* Dataset을 딥러닝 데이터를 쉽게 불러오기 위한 일종의 Generator 입니다.\n",
    "* 학습에 사용할 데이터셋은 총 3개\n",
    "    * Train dataset, Valid dataset, Test dataset 입니다.\n",
    "        * Raw data에서 분리한 데이터들\n",
    "    * 데이터셋은 tf.data.Dataset으로 구성되며, 구현 파트에선 데이터를 불러오는 형식만을 지정해준다.\n",
    "        * shuffle, batch 옵션을 이용해 다양하게 데이터를 로드해올 수 있다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4YFNeX5zokDu",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:15.176350Z",
     "start_time": "2023-12-27T06:42:15.113134Z"
    }
   },
   "source": [
    "batch_size = 32"
   ],
   "execution_count": 182,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5smuqDGFRL5s",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:22.108898Z",
     "start_time": "2023-12-27T06:42:15.153221Z"
    }
   },
   "source": [
    "# for train\n",
    "N = len(train_data)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data,train_labels))\n",
    "train_dataset = train_dataset.map(one_hot_label) # 함수의 이름을 써서 구현\n",
    "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# # for valid\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((valid_data,valid_labels))\n",
    "valid_dataset = valid_dataset.map(one_hot_label)\n",
    "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
    "print(valid_dataset)\n",
    "\n",
    "# # for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data,test_labels))\n",
    "test_dataset = test_dataset.map(one_hot_label)\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n"
   ],
   "execution_count": 183,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 32, 32, 3), dtype=tf.float64, name=None), TensorSpec(shape=(None, 10), dtype=tf.float32, name=None))>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s_YijINvd7I"
   },
   "source": [
    "\n",
    "* 데이터 타입의 경우 Tensorflow 버전에 따라 tf.float32 or tf.float64로 출력될 수 있으나 학습에 큰 영향을 주진 않는다.\n",
    "* 해당 자료형은 tf.cast를 이용해 따로 타입을 지정해줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sak_LGn0jVSz"
   },
   "source": [
    "### Save point 설정\n",
    "* Model weight를 저장할 폴더를 지정한다.\n",
    "* 폴더가 없다면 새로 생성해준다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aoGnJiFQn-9a",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:22.122466Z",
     "start_time": "2023-12-27T06:42:21.099918Z"
    }
   },
   "source": [
    "# the save point\n",
    "if use_colab:\n",
    "    checkpoint_dir ='.//cifar10_classification/exp1'\n",
    "else:\n",
    "    checkpoint_dir = 'cifar10_classification/exp1'\n",
    "\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ],
   "execution_count": 184,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28Zgtrndp8ag"
   },
   "source": [
    "### Model Savepoints\n",
    "* 모델 저장시 모델의 파라미터를 저장한다.\n",
    "    * 위에 구현된 모델의 shape을 기준으로 파라미터만 저장\n",
    "* 저장된 데이터는 checkpoint 형태로 저장되며, load data를 이용해 불러올 수 있다.\n",
    "    * 저장된 모델 데이터를 불러올 시에는 저장된 모델과 같은 shape인 모델이 메모리 상에 있어야 한다.\n",
    "\n",
    "```\n",
    "model = model() # 구현했던 모델\n",
    "model.load_weights(checkpoint_dir)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9zJFca-nq4v"
   },
   "source": [
    "### 데이터 확인\n",
    "* 학습에 사용할 데이터를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8zViOfERL5v",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:22.212295Z",
     "start_time": "2023-12-27T06:42:21.119596Z"
    }
   },
   "source": [
    "index = 219 # index를 변경해 확인해보자 (0~49999)\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(32, 32, 3))\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ],
   "execution_count": 185,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label = 9\n"
     ]
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 2 Axes>",
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAesAAAGdCAYAAAAyiFt9AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8pXeV/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAA+L0lEQVR4nO3de3xU9Z0//teZe0IyuRByg3BVQUWgGyVNUUslBel+Wa20D6rdiqyLD23iQ0271XQVrLaN1V1K20eEx1qRdleE6q/qeilujQbXFrBEWe9RMJhwSbjmNsnMJHM+vz8oY0cC+bwzE+Yc5vX0cR4PmbzPZz5nzsy85/M557yPoZRSICIiIstyJLsDREREdHpM1kRERBbHZE1ERGRxTNZEREQWx2RNRERkcUzWREREFsdkTUREZHFM1kRERBbnSnYHPs80Tezfvx+ZmZkwDCPZ3SEiIiGlFLq7u1FcXAyHY+TGhMFgEOFwOO52PB4PfD5fAno0ciyXrPfv34+SkpJkd4OIiOLU2tqKcePGjUjbwWAQkyZkoO1gJO62CgsL0dzcbOmEPWLJuq6uDg899BDa2towc+ZM/OpXv8Ls2bOHXC8zMxMA8K8b34QvPVPruQZM/Z1lCH/luQ39aqxOQSwAGE79vhiQzTJIqshKZzCcDlm8y6kf6zBk+8chfF1EbQu2szhDtu/PyxW8KAB8bv1YQ5mitiNKvy/B/gFR20FJuFOwkQAkb8OIKXtNeoWDtZ6w/v4PyV5CUXwo3C9qOxDW/+4ciOhvY19vD+78xsXR7/OREA6H0XYwgubGCfBnDn/03tVtYlLppwiHw6mXrDdt2oTq6mqsXbsWZWVlWL16NRYsWICmpibk5+efdt0TicOXngnfqLM7WTuYrE9iqWQt2D+jMmTJIDNT9tHzefRjHcJkPSBI1u6wLNO4BgSfCadgIwE4Bbt+QJisHcJkrUL62+kSJmunIN4pnBI2QyOTrE84E4cy/ZmOuJK1XYzIFq5atQrLly/HsmXLcMEFF2Dt2rVIT0/HunXrRuLpiIgoRUWUGfdiBwlP1uFwGI2NjaioqPjsSRwOVFRUYOvWrSfFh0IhdHV1xSxEREQ6TKi4FztIeLI+fPgwIpEICgoKYh4vKChAW1vbSfG1tbXIysqKLjy5jIiIdJkJ+M8Okj7RX1NTg87OzujS2tqa7C4RERFZSsJPMMvLy4PT6UR7e3vM4+3t7SgsLDwp3uv1wuv1JrobRESUAiJKISI4oXaw9e0g4SNrj8eD0tJS1NfXRx8zTRP19fUoLy9P9NMREVEKS5Vj1iNy6VZ1dTWWLl2Kiy++GLNnz8bq1asRCASwbNmykXg6IiKis9qIJOslS5bg0KFDWLFiBdra2jBr1ixs3rz5pJPOiIiI4mFCIRLH6DilR9YAUFVVhaqqqmGv7zaccBt6xRqcTkEBEEGhi+P90D9T0OOSte106r/80uICpqAIhKSACgC4pEVRBC+LtGiNEnRFWp5Bsp0mZBXJTEnHAUh2v2kKK+kJGlcO2VeG09Cv6OFyyfo9IKgyKb2U1i2pRAIgO03/NQyGZe8Vp+A7yKX5nXmCKfhU9EoKvwi+2+IV71S2XZJ10s8GJyIiotOz3I08iIiIdKXK2eBM1kREZFvmX5d41rcDToMTERFZHEfWRERkW5E4zwaPZ90zicmaiIhsK6KOL/GsbwdM1kREZFs8Zk1ERESWwJE1ERHZlgkDEXHJo9j17YDJmoiIbMtUx5d41rcDyyZrA/1woF8r1i2osOcwZHvG69Vv3Cmr9AeXoIygU/jrb0BwgMMhLGXqFZZsdRj68dJyo6ao67LtlPTb6xTUvgTQLyw3GhoQlI+VHoQz9fseklXhhNOjf/tbh5I17ozo9zsckb3e0hK8kq8VpyF7r3gd+vFK+NlMd+q/Lg6XJJZHWBPNssmaiIhoKJE4p8HjWfdMYrImIiLbSpVkzbkKIiIii+PImoiIbMtUhviWs59f3w6YrImIyLY4DU5ERESWwJE1ERHZVgQOROIYd8oupEseJmsiIrItFecxa8Vj1kRERCOLx6yJiIjIEjiyJiIi24ooByIqjmPWrA0eH4/ThMepV+TYJ6jL7BHWnva69GsbQ1hj2xQUcXYI6wm7BbFOQX1gAPBp7pfP6L/NDGHtduXQ77shqPUNAAb0++IWzqQFB4TfEG5BnXKHZO8DkQG9GvwAEA52i9o+uPeodmxudo6oba9vlHZssF9Wd9yMyN7jpqCWuCl9H0q+J4R3Z5bU+Xd6BJ+1sKgbcTFhwIxjktgUfM6TidPgREREFmfZkTUREdFQUuUEMyZrIiKyrfiPWXManIiIiBKAI2siIrKt4yeYxXEjD06DExERjSwzznKjPBuciIiIEoIjayIisq1UOcGMyZqIiGzLhCMliqIwWRMRkW1FlIFIHHfOimfdM8myydrndsLndurFCn5UuZ16bZ7gdOj/6hJUvgQA0UkRHmEZTp9gzyrhNJCkbUBWtlNYsRWm4HURVnmES/BeMSB7X3X2yMp2Hm3r0I4NdXaK2j524FPt2N62PaK2D7TplxstnnGJqO3zLvmSdqwyZCVYTeFNjh2Csp3S1OAUlEiWfBcCsoIgYYd+KdMBt7QkMQ3FssmaiIhoKJE4zwaPcBqciIhoZJnKATOOE8wkN2FJJl66RUREZHEcWRMRkW1xGpyIiMjiTMR3RrddToXjNDgREZHFcWRNRES2FX9RFHuMWZmsiYjItuIvN2qPZG2PXhIREaUwjqyJiMi2eD9rIiIii0uVaXDLJmuP0wGvS+9FlJTNNpyyGsEej6B+t1N2EYDkLeIW1p72OCW/FmXXGboEtYoBiAp+uwQ1lgHALXgHB/v6RG3vfvtN7dhA+z5R292tLaL4wJHD2rGO3h5R244+/TrlbvSL2va4vNqxe4K9orbhTdcOnfyFObK2ERJFO536b0Sn8CYChqAmt/SzrFz6ffGagjr8/WdutBr/ddb2SNb26CUREVEKS3iyvvfee2EYRswybdq0RD8NERERTGXEvdjBiEyDX3jhhXj55Zc/exKXZWfbiYjIxsw4p8FT+jprl8uFwsLCkWiaiIgo5YzIT4qPP/4YxcXFmDx5Mr797W+jpeXUJ9OEQiF0dXXFLERERDpO3CIznsUOEt7LsrIyrF+/Hps3b8aaNWvQ3NyMyy67DN3dg59xWltbi6ysrOhSUlKS6C4REdFZKgIj7sUOEp6sFy5ciG9+85uYMWMGFixYgBdffBEdHR343e9+N2h8TU0NOjs7o0tra2uiu0RERGRrI37mV3Z2Ns477zzs2rVr0L97vV54vfrXYhIREZ0Q71R2yk6Df15PTw92796NoqKikX4qIiJKMRHEOxVuDwlP1t///vexZcsW7NmzB3/+85/x9a9/HU6nE9dee22in4qIiCgp6urqMHHiRPh8PpSVleGNN944bfzq1asxdepUpKWloaSkBHfccQeCwaD28yV8Gnzv3r249tprceTIEYwZMwaXXnoptm3bhjFjxojaGeX1IF1zejwkKMXpNmS/o1wY0I71SWpfAvAJzmuQngIhqPAJaYlCQ9a4KN7lkpVVTfPpv+Z9HR2itj956TntWHV0v6htvyErTZshqKnrEf4Gd3v1X3Nl+ERt9wqmGD1h2ZUgzdvq9dtOzxG1Pf6CGaJ4h9IvT+rWLKN8gsutHx8RlAQFZKWaleB9Fek/c7U1kjENvmnTJlRXV2Pt2rUoKyvD6tWrsWDBAjQ1NSE/P/+k+A0bNuCuu+7CunXr8KUvfQkfffQRbrjhBhiGgVWrVmk9Z8Jf0Y0bNya6SSIiokEl40Yeq1atwvLly7Fs2TIAwNq1a/HCCy9g3bp1uOuuu06K//Of/4w5c+bguuuuAwBMnDgR1157LbZv3679nPY4sk5ERDQI9ddbZA53UcJ5y3A4jMbGRlRUVEQfczgcqKiowNatWwdd50tf+hIaGxujU+WffPIJXnzxRXzta1/Tfl7WASUiopT3+YJcp7pS6fDhw4hEIigoKIh5vKCgAB9++OGgbV933XU4fPgwLr30UiilMDAwgJtvvhk//OEPtfvHkTUREdnWiWnweBYAKCkpiSnQVVtbm7A+NjQ04Kc//SkefvhhvPnmm/j973+PF154Affff792GxxZExGRbcV756wT67a2tsLv90cfP1X9j7y8PDidTrS3t8c83t7efsp7Ytxzzz34zne+g3/+538GAFx00UUIBAK46aab8K//+q9wOIYeN3NkTUREKc/v98csp0rWHo8HpaWlqK//7GoE0zRRX1+P8vLyQdfp7e09KSE7ncevwlBK75R8jqyJiMi2InHeInM461ZXV2Pp0qW4+OKLMXv2bKxevRqBQCB6dvj111+PsWPHRqfSFy1ahFWrVuELX/gCysrKsGvXLtxzzz1YtGhRNGkPhcmaiIhsK1HT4BJLlizBoUOHsGLFCrS1tWHWrFnYvHlz9KSzlpaWmJH03XffDcMwcPfdd2Pfvn0YM2YMFi1ahJ/85Cfaz8lkTUREJFRVVYWqqqpB/9bQ0BDzb5fLhZUrV2LlypXDfj4mayIisi0TDphxTIPHs+6ZxGRNRES2FVEGInFMg8ez7plk2WSdHjyIUa5erdi9+49qt5ufXzB00N9Iy8nWjtU8qS/KFNTkdmmc2v+3ZPW7ZXWqdS4z+FxntEMHIrIXMRDWr/WuhP0ek68f3+eR3VXO13VMFO8Y0K897RDWbjcj+q/hgJK9V0xD/yvGYXhEbRs9+p/7T/73RVHbHm+aKH7S1MnasYZD/34Dx+P196dDWDpT8mlTpv6+1z3DmfRZNlkTERENJRknmCUDkzUREdmWivOuWyqOdc8kJmsiIrKtCAxExDcRjl3fDuzxk4KIiCiFcWRNRES2Zar4jjubNjkXjsmaiIhsy4zzmHU8655J9uglERFRCuPImoiIbMuEATOOk8TiWfdMYrImIiLbSpUKZpwGJyIisjjLjqwLj72AjJBPK/a9Pfqb0dF7jqgfeWPmasc6XbLTCs2wfvm+kPAkiIx0t3asU1BGEAAiZr8oPtQf1I51OPRLXwJAOvK0YyMO2XZmZ+n/4j7cJ/so9boHv7H9qYzu1y832hORlbP0G/rvW6ehd+/dExyCtg3habluQUnL8KFPRW03vfq8KN6X9U3t2AklhaK21YD+Z8IQvsclNZIlpUylZU/jkSonmFk2WRMREQ3FRJzlRm1yzNoePymIiIhSGEfWRERkWyrOs8GVTUbWTNZERGRbvOsWERGRxaXKCWb26CUREVEK48iaiIhsi9PgREREFpcq5UY5DU5ERGRxHFkTEZFtcRqciIjI4pisk6xl93sYlebRir0gY4x2uy6PbOY/0jNVv22jT9S2K3uidqxDuKeOtLdoxx46dljUdnv7EVF8z9F92rHn5R4StV08+XLt2ECnfn1tADA69fvi7ZTVNA95M0TxkV79mtydwu+eHKd+fejIgKx+t6Q2uFNJa9Trv+YOh+xz37vvI1H8/21+TjvW/Q/fELVdkJ+rHSt9DRX0948y9NuWxJIeyyZrIiKioXBkTUREZHGpkqx5NjgREZHFcWRNRES2pRDftdKyszCSh8maiIhsK1WmwZmsiYjItlIlWfOYNRERkcVxZE1ERLaVKiNrJmsiIrKtVEnWnAYnIiKyOI6siYjItpQyoOIYHcez7plk2WS97yCQ5tW7Aq5o9H7tdovSZVfV9e5+UTvWmTNe1LaRWagd+/4H74ra3v5/e7VjDxzqErXd2RsWxc8Y26Edu621VdS2+kB/34/zyT6Uef3675VRwprMvYK2ASDk0v+o+hxuUdv9AwHtWFN4Uaph6L/mDqdwos/Uf80jZr+oaYewGH/3x+9ox775B6+o7b/7+69rx2b7/aK2lWB/OgX1vsOyUvlx4f2siYiIyBLEyfq1117DokWLUFxcDMMw8Mwzz8T8XSmFFStWoKioCGlpaaioqMDHH3+cqP4SERFFnTjBLJ7FDsTJOhAIYObMmairqxv07w8++CB++ctfYu3atdi+fTtGjRqFBQsWIBgMxt1ZIiKiv3XimHU8ix2Ij1kvXLgQCxcuHPRvSimsXr0ad999N6666ioAwG9/+1sUFBTgmWeewbe+9a34ektERJSCEnrMurm5GW1tbaioqIg+lpWVhbKyMmzdunXQdUKhELq6umIWIiIiHZwGH4a2tjYAQEFBQczjBQUF0b99Xm1tLbKysqJLSUlJIrtERERnsVSZBk/62eA1NTXo7OyMLq3CS3eIiCh1qThH1SmZrAsLj1833N7eHvN4e3t79G+f5/V64ff7YxYiIiL6TEKT9aRJk1BYWIj6+vroY11dXdi+fTvKy8sT+VRERERQOF7cZdhLsjdAk/hs8J6eHuzatSv67+bmZuzcuRO5ubkYP348br/9dvz4xz/Gueeei0mTJuGee+5BcXExrr766kT2m4iICCYMGClQwUycrHfs2IGvfOUr0X9XV1cDAJYuXYr169fjBz/4AQKBAG666SZ0dHTg0ksvxebNm+Hz+UTPk+YfjXSfXlk+09Gr3W6PI1fUjwGlf314Xnq6qO2w0q/J92mbfllNAJh0Yal2bPD9XUMH/Y09//cXUfy02fqxbx2YIWo71+/Ujp2SIyvOY+zL0I7tPNwjavtwr6w8qT83Wzs2358lajvS8qF2rNMj+2JLdwkm75yytoNh/TGRw5TVv4yYsr44oL8/j334pqjtd9IytWOnz/t7UdujfPqlacOCY7vBfnskQDsRJ+u5c+dCnaagrGEYuO+++3DffffF1TEiIqKh8EYeREREFmcqAwbvZ01ERETJxpE1ERHZ1omzuuNZ3w6YrImIyLZS5Zg1p8GJiIgsjiNrIiKyrVQZWTNZExGRbaXK2eBM1kREZFupcoIZj1kTERFZHEfWRERkW8dH1vEcs05gZ0aQZZP1mJnfxKhRerWZswb2abfbB/1a3wDQb+jX5e009etUA0AkrF/T3JNRJGo7a+xY7diBT2T3EC/J7xfFf3Fat3Zs14CwhrxP/3UZky2bSNp/IKAdKymBDQDnGvr7HgAio/Rr2uecN1XUdt+B3dqx0u9Et6Tet0P2rdmt9OtxO2Wl2IGI7D0eMQRfpUrW9r6dr2vHOtJGidr+wtwK7VjDof/9Zhqy78J4pMoJZpwGJyIisjjLjqyJiIiGohDfPaltMgvOZE1ERPbFaXAiIiIaVF1dHSZOnAifz4eysjK88cYbp43v6OhAZWUlioqK4PV6cd555+HFF1/Ufj6OrImIyL6SMA++adMmVFdXY+3atSgrK8Pq1auxYMECNDU1IT8//6T4cDiMr371q8jPz8dTTz2FsWPH4tNPP0V2drb2czJZExGRfcU5DS6+xAHAqlWrsHz5cixbtgwAsHbtWrzwwgtYt24d7rrrrpPi161bh6NHj+LPf/4z3G43AGDixImi5+Q0OBER2daJCmbxLADQ1dUVs4RCoUGfLxwOo7GxERUVn1325nA4UFFRga1btw66zn//93+jvLwclZWVKCgowPTp0/HTn/4UkUhEezuZrImIKOWVlJQgKysrutTW1g4ad/jwYUQiERQUFMQ8XlBQgLa2tkHX+eSTT/DUU08hEongxRdfxD333IN///d/x49//GPt/nEanIiIbCtRZ4O3trbC7/dHH/d6vXH37QTTNJGfn4//+I//gNPpRGlpKfbt24eHHnoIK1eu1GqDyZqIiOxLGcM67hyzPgC/3x+TrE8lLy8PTqcT7e3tMY+3t7ejsLBw0HWKiorgdrvhdH5W2e38889HW1sbwuEwPB7PkM9r2WRtDrTBHEjXiu0PdWi32+uUlePzpumXzXO5ZC9n59E92rHO3hZR2659h7Vjy/27RG0XXdolis/37teOnWg0i9p2Qq8kLQBkpQ/+QTqVY4ISlb7+PlHbhwKykpNHevXbH28MiNpOdwm+6EzZqbNup/6Rtn5BOUsAcAm+oPsjsnqjws2EUvrHHg1BmVQAcAqKV7ds+x9R25l5+p+Jc2bM0o5VsMe1y8Ph8XhQWlqK+vp6XH311QCOj5zr6+tRVVU16Dpz5szBhg0bYJomHI7jn4mPPvoIRUVFWoka4DFrIiKysUSdYCZRXV2NRx55BL/5zW/wwQcf4JZbbkEgEIieHX799dejpqYmGn/LLbfg6NGjuO222/DRRx/hhRdewE9/+lNUVlZqP6dlR9ZERERDSsJ11kuWLMGhQ4ewYsUKtLW1YdasWdi8eXP0pLOWlpboCBo4fvLaSy+9hDvuuAMzZszA2LFjcdttt+HOO+/Ufk4mayIiIqGqqqpTTns3NDSc9Fh5eTm2bds27OdjsiYiIttKldrgTNZERGRvdrl1Vhx4ghkREZHFcWRNRES2xWlwIiIiq0vC2eDJwGRNREQ2Zvx1iWd96+MxayIiIovjyJqIiOyL0+DJ5fUcX3Q4A/p1sPsO7hH1w5l/rnZsZvZoUds5jle1YwtGvyNqO2uU/qTJgX79usYA0NkVFsUf69KvhXxOkU/UtitNv+/hwW9Pe0qZLv1P8V+UrNb3Kx1BUfyEMfqd9xqyaT2HoCa3U1h33OvV/4oJC7+OHBDU2JbWlBzB2uDS85kMQd9V+Jio7d5De7VjnZgpiD2DGTBFkjWnwYmIiCzOsiNrIiKiISXoFplWx2RNRES2Ndw7Z/3t+nbAaXAiIiKL48iaiIjsK0VOMGOyJiIi+0qRY9acBiciIrI4jqyJiMi2DHV8iWd9O2CyJiIi++IxayIiIotLkWPWlk3WWVPmISPTrxWbts+t3e6At0nUD3dWgXasz9krajvb+Yl2bH7uAVHbpku/hGTzfv1YADh8SPbmPnec/tvsvHNkNUGPduVqx+7/VFbiM7tIP9bcky5qu9OUlXgNhATlLE3ZUCFtjP7r4gwLSnwCcA2kacd6xHc/kpQblbUsnRpVpn5fIobsVCHDkGynbP94oF8m1+PQf1HCdplbthHLJmsiIqIhcRqciIjI4lIkWYsv3XrttdewaNEiFBcXwzAMPPPMMzF/v+GGG2AYRsxy5ZVXJqq/REREKUecrAOBAGbOnIm6urpTxlx55ZU4cOBAdHniiSfi6iQREdGgVAIWGxBPgy9cuBALFy48bYzX60VhYeGwO0VERKQlRc4GH5EKZg0NDcjPz8fUqVNxyy234MiRI6eMDYVC6OrqilmIiIjoMwlP1ldeeSV++9vfor6+Hj/72c+wZcsWLFy4EJHI4Jee1NbWIisrK7qUlJQkuktERHSWOlHBLJ7FDhJ+Nvi3vvWt6P9fdNFFmDFjBqZMmYKGhgbMmzfvpPiamhpUV1dH/93V1cWETUREeng2eGJMnjwZeXl52LVr16B/93q98Pv9MQsRERF9ZsST9d69e3HkyBEUFQnKQREREVGUeBq8p6cnZpTc3NyMnTt3Ijc3F7m5ufjRj36ExYsXo7CwELt378YPfvADnHPOOViwYEFCO05ERGQgzrtuJawnI0ucrHfs2IGvfOUr0X+fON68dOlSrFmzBm+//TZ+85vfoKOjA8XFxZg/fz7uv/9+eL1e0fN4nCY8Tr06t16v/svtyh4r6seofP3j557wblHbbsHBEl+2bBJkIKK/a8eOktUGT8uVvb1VsE8/dkC/zjsAOEPHtGOzMmR1k0cX6tf7vtyVKWr7k8Oyqx7Cffr1u0Nh/XrPADAuTz/e7BA1jbD+7oEhqD193MgdbJTU+gYAJajJLd5KwaVF5ilO5D0Vt9J/X7lc+tsoiY1bily6JU7Wc+fOhVKnfru99NJLcXWIiIiIYrE2OBER2VeKnA3OZE1ERPaVIsl6xM8GJyIiovhwZE1ERLYVbxWylK1gRkREdMZwGpyIiIisgCNrIiKyrxQZWTNZExGRbaXKMWtOgxMREVkcR9ZERGRfLDeaXO0HD6Cnt0cr1tepX3s6FJHVcHb1dWvH9juE9YQH9OdfesL6NXwB4GiX/hswHJTV4/aPks0b9fXq14V/721R0/C59SeHzIFeUduOfP39OfW80aK2vzMvVxTfdlR/O71u/fcsALQdy9GOdQnrjmdAUDPbIatRD0MyMSirmW1Kp0YFH31TmBuUQ1AbXFjT3BgY0I51COqfS2LjxmPWRERE1sZj1kRERGQJHFkTEZF9cRqciIjI4uKcBrdLsuY0OBERkcVxZE1ERPbFaXAiIiKLS5FkzWlwIiIii+PImoiIbIvXWRMREZElWHZkfejQAQR6u7RiHSH9MoUOp2yTO9qPaccGvbJSjP19Yf3YHv2SnQDQ1+fRjnU5ZfUPXYasdKMK6rfvccv2zyiffllDU1ITEoDh1i9j64KslOkF02WlNWdA/zXcdeCIqO134NeOHeXXf18BQEbgqHbs4b6QqO0+wWsi+2TKSnwCgCGoL20I34cRQVeU0i8fCgDhkH5pWp/SL3k8oGT7koZm2WRNREQ0pBQ5wYzJmoiIbCtVjlkzWRMRkb3ZJOHGgyeYERERWRxH1kREZF88Zk1ERGRtqXLMmtPgREREFseRNRER2RenwYmIiKyN0+BEREQ0qLq6OkycOBE+nw9lZWV44403tNbbuHEjDMPA1VdfLXo+JmsiIrIvlYBFaNOmTaiursbKlSvx5ptvYubMmViwYAEOHjx42vX27NmD73//+7jsssvEz2nZaXCvzwuvT68edsSVo92uU1DDFwBCgh15TFgONyvk1o7NcKaJ2nb79GtP9/TJ6lQfi8hqg3eG9V/zrsOyusnB1oB2bHuHfq1vAJgzoP++GpPdLmq7L6RfjxsAPN4M7djnXvlQ1HZbh37d+bajh0RtRzr1a09nZaSL2p5UUKQdG1Cyb2SXsDa4w63/WQ6FZV8UTsk8raAfABBof087dv8Hv9dvt1f2WYtLEo5Zr1q1CsuXL8eyZcsAAGvXrsULL7yAdevW4a677hp0nUgkgm9/+9v40Y9+hP/93/9FR0eH6Dk5siYiopTX1dUVs4RCg/+oCofDaGxsREVFRfQxh8OBiooKbN269ZTt33fffcjPz8eNN944rP4xWRMRkW2dOMEsngUASkpKkJWVFV1qa2sHfb7Dhw8jEomgoKAg5vGCggK0tbUNus7rr7+ORx99FI888siwt9Oy0+BERERDStA0eGtrK/z+zw5Peb2y2xKfSnd3N77zne/gkUceQV5e3rDbYbImIiL7SlCy9vv9Mcn6VPLy8uB0OtHeHnueSnt7OwoLC0+K3717N/bs2YNFixZFHzPN4+fmuFwuNDU1YcqUKUM+L6fBiYiINHk8HpSWlqK+vj76mGmaqK+vR3l5+Unx06ZNwzvvvIOdO3dGl3/4h3/AV77yFezcuRMlJSVaz8uRNRER2VYyiqJUV1dj6dKluPjiizF79mysXr0agUAgenb49ddfj7Fjx6K2thY+nw/Tp0+PWT87OxsATnr8dJisiYjIvpJw6daSJUtw6NAhrFixAm1tbZg1axY2b94cPemspaUFDkdiJ66ZrImIiISqqqpQVVU16N8aGhpOu+769evFz8dkTUREtpUqtcGZrImIyL54161kM/66DE1BUC5TVkUQPkP/JRrlHRC1/dYH+rF/+ouszGNXQL88aWevqGkcC8jKJQb69F/DkCnbQeGBfu3YSNAnantvYIx27OzzZSVbzx+v328A2NnUpR3733/aI2rb7dF/rxw6eljUtjdN/zXPEpaxjQj6faRL//UDgGBQ9lkela7fl3SfR9S2V/AdlCY8TtrXpV8W9MCuT7Rje4PC2ss0JAsnayIioiGkyMha9DOstrYWl1xyCTIzM5Gfn4+rr74aTU1NMTHBYBCVlZUYPXo0MjIysHjx4pMuHiciIkoEIwGLHYiS9ZYtW1BZWYlt27bhj3/8I/r7+zF//nwEAp/d+eiOO+7Ac889hyeffBJbtmzB/v37cc011yS840RERKlCNA2+efPmmH+vX78e+fn5aGxsxOWXX47Ozk48+uij2LBhA6644goAwGOPPYbzzz8f27Ztwxe/+MXE9ZyIiIjT4EPr7OwEAOTm5gIAGhsb0d/fH3PrsGnTpmH8+PGnvHVYKBQ66dZkREREOhJ11y2rG3ayNk0Tt99+O+bMmRMtmdbW1gaPxxMtpXbC6W4dVltbG3NbMt06qURERNGRdTyLDQw7WVdWVuLdd9/Fxo0b4+pATU0NOjs7o0tra2tc7REREZ1thnXpVlVVFZ5//nm89tprGDduXPTxwsJChMNhdHR0xIyuT3XrMOD4PUMTdd9QIiJKQTYZHcdDNLJWSqGqqgpPP/00XnnlFUyaNCnm76WlpXC73TG3DmtqakJLS8ugtw4jIiKKR6ocsxaNrCsrK7FhwwY8++yzyMzMjB6HzsrKQlpaGrKysnDjjTeiuroaubm58Pv9uPXWW1FeXs4zwYmIiIZJlKzXrFkDAJg7d27M44899hhuuOEGAMDPf/5zOBwOLF68GKFQCAsWLMDDDz+ckM4SERHFSJFLt0TJWqmht8rn86Gurg51dXXD7hQABHo6YJp69ZMl0ximU3aY3u3Rr22854CsbvJzr+nXz93xoX7tYQBwevXrDzscsho+AxHZa+jz6r+GHsHrDQD5OX7t2JkTZPW7p47J0o49uk+274+ly2qDR1CkHTtqdI+obYdhasdeNu1Lorbz8vK1Y3e+/46o7eYjR7Rjjx6W7Z+unqAo3ic472Z0Tq6o7d5e/eL9+dnporadngLtWEfnKO3YYPDMVbJOlbtuJfbu2ERERJRwvJEHERHZF6fBiYiIrI3T4ERERGQJHFkTEZF9cRqciIjI4pisiYiIrI3HrImIiMgSOLImIiL74jQ4ERGRtRlKwdCornm69e3Assn6WMdh9IUCWrFqQL9dpyErOeny6pf5DLbvFrU9oXCCdmxLh35pUgDo6evTjnXpV5sEABgOtyxeUPpU9cu2c/q5F2jHzpksbNvfpR3bfkhW5vGtD0ThCGXolz7N8WfIGlcR7VCfT7/kJAAUn+LWuIOJmPrvWQDY99cbCek41tEparuwQP/1BgCnR/8zcaxb/30FAD0B/fKxhiH4MgSgfPrfb6F9x7Rj+8NhUT9oaJZN1kREREPiNDgREZG18WxwIiIisgSOrImIyL44DU5ERGRtnAYnIiIiS+DImoiI7IvT4ERERNaWKtPgTNZERGRfKTKy5jFrIiIii+PImoiIbM0uU9nxsGyyLiqcgPRRenWI1YB+PVxDCQthu/TrWnf1HBY1HQh/qB07IHwzOlyCGughWT1hj1NWG7wnGNSOHTD161QDwPa33tCOfedt2ds9zaf/Go7LHyNq25cm60t/j3496fxcv6jtUFC/Jneov1/U9tFjR7RjM7yy91V2pn797qwc2f4xBd8pAOASfN5G54wWtZ2Tma0da0Zk/TZzirRjAznnaMf2h/Q/83FT6vgSz/o2wGlwIiIii7PsyJqIiGgoPBuciIjI6ng2OBEREVkBR9ZERGRbhnl8iWd9O2CyJiIi++I0OBEREVkBR9ZERGRbPBuciIjI6lKkKAqTNRER2RZH1knmdrvhdmuW+nTol/ozhP1wGPqH9cOFE0Rt5+Tv1Y6d3h0WtR0w9ctC/mnHm6K2I8JSjGFBCURDsC8BoH1fq3Zsf1jWb0PwbinIyxO1PeXcKaL4cydP1I71p2eI2j4UCmnHHu08Kmo7x+/Tjs3O0I8FAJ9b/+vL4ZCdnhMIy8qqugb048PCtp2CLy2nR/YaBoP6fQn0CsoGn8lyoynCssmaiIhoSClyNjiTNRER2VaqTIPz0i0iIiKL48iaiIjsi2eDExERWRunwYmIiMgSOLImIiL74tngRERE1sZpcCIiIrIEjqyJiMi+THV8iWd9G2CyJiIi++Ix6+RyOpxwataJllwmJz0+oQSN5xWMEbW9cPqF2rHBgW5R26/vb9GOfbGrU9R2JCSrUy6px57u9YraznDrxx8NBkRtm4KOH9i/T9R2RlaWKL5Y8N4yPW5R2919+nWcmz7eI2p7bF6OduzoSeNEbcOjee8AADmjc0VNNzV9JIovKCjWjp0883JR293HDmrHfvLRX0RtjxmVrh1rHPlEP7Zf9h0RDwNxHrNOWE9GFo9ZExERWZwoWdfW1uKSSy5BZmYm8vPzcfXVV6OpqSkmZu7cuTAMI2a5+eabE9ppIiIiAJ9VMItnsQFRst6yZQsqKyuxbds2/PGPf0R/fz/mz5+PQCB2enH58uU4cOBAdHnwwQcT2mkiIiLgs0u34lnsQJSsN2/ejBtuuAEXXnghZs6cifXr16OlpQWNjY0xcenp6SgsLIwufr8/oZ0mIiJKprq6OkycOBE+nw9lZWV44403Thn7yCOP4LLLLkNOTg5ycnJQUVFx2vjBxHXMurPz+IlJubmxJ288/vjjyMvLw/Tp01FTU4Pe3t5TthEKhdDV1RWzEBERaVEJWIQ2bdqE6upqrFy5Em+++SZmzpyJBQsW4ODBwU8GbGhowLXXXotXX30VW7duRUlJCebPn499+/RPTB12sjZNE7fffjvmzJmD6dOnRx+/7rrr8F//9V949dVXUVNTg//8z//EP/7jP56yndraWmRlZUWXkpKS4XaJiIhSjKFU3IvUqlWrsHz5cixbtgwXXHAB1q5di/T0dKxbt27Q+Mcffxzf/e53MWvWLEybNg2//vWvYZom6uvrtZ9z2JduVVZW4t1338Xrr78e8/hNN90U/f+LLroIRUVFmDdvHnbv3o0pU6ac1E5NTQ2qq6uj/+7q6mLCJiKiM+rzs7perxfeQS4lDYfDaGxsRE1NTfQxh8OBiooKbN26Veu5ent70d/ff9Ks9OkMa2RdVVWF559/Hq+++irGjTv9tZFlZWUAgF27dg36d6/XC7/fH7MQERFpMROwACgpKYmZ5a2trR306Q4fPoxIJIKCgoKYxwsKCtDW1qbV5TvvvBPFxcWoqKjQ3kzRyFophVtvvRVPP/00GhoaMGnSpCHX2blzJwCgqKhI8lRERERDGu5U9t+uDwCtra0xg8XBRtWJ8MADD2Djxo1oaGiAz+fTXk+UrCsrK7FhwwY8++yzyMzMjP6KyMrKQlpaGnbv3o0NGzbga1/7GkaPHo23334bd9xxBy6//HLMmDFDtkVERERniO7Mbl5eHpxOJ9rb22Meb29vR2Fh4WnX/bd/+zc88MADePnll8U5UTQNvmbNGnR2dmLu3LkoKiqKLps2bQIAeDwevPzyy5g/fz6mTZuG733ve1i8eDGee+45UaeIiIi0nOGzwT0eD0pLS2NODjtxslh5efkp13vwwQdx//33Y/Pmzbj44otlT4phTIOfTklJCbZs2SLuxGA6uo4hNKBXX9YheLF1642fYAruyNLZK9vr6QP6NZlzxstOunMH9dt2u2TnGZqhkCg+f3Seduzf/7+rZH3pj2jHPvXc/ydqu+80lxx+ntMlq8cdDOnvHwAwBdN8A4Zsf3Z06+/PTz/9VNT20WnnaMcePtojars7qP+a+LNldfvD/f2i+P6IqR170cxSUdtHDh3Qjv20uWnooL+RlaH/upx77vnaseFgEInJBBrirUI2jHWrq6uxdOlSXHzxxZg9ezZWr16NQCCAZcuWAQCuv/56jB07Nnrc+2c/+xlWrFiBDRs2YOLEidFZ6YyMDGRkZGg9p2Vv5EFERDSUeKuQDWfdJUuW4NChQ1ixYgXa2towa9YsbN68OXrSWUtLCxyOzyau16xZg3A4jG984xsx7axcuRL33nuv1nMyWRMREQlVVVWhqqpq0L81NDTE/HvPnj1xPx+TNRER2VcSpsGTgcmaiIhsyzCPL/Gsbwe8nzUREZHFcWRNRET2xWlwIiIiixvmnbNi1rcBToMTERFZHEfWRERkW4mqDW51TNZERGRfPGadXB/v2gevL00rNt2rFwcAXq9skw1BKU5DWMrU583Xju0YO17Utgv6ZQRz8/4kantfYLco/tzps7RjL5izSNT2/vaD2rFZ2/8iaju892NBtOwD39PZIYrv+Ny9dk+nKFO/vCsAKKV/55+J44tFbUcM/SNtnQFZCVY49Eu8jh8nu+vf0huWiuIzMrK0Y7NdslKmYybov+ZTbrpN1LbXq7/v0zIztWODglK9pMeyyZqIiGhICtF7Ug97fRtgsiYiItviMWsiIiKrU4jzmHXCejKieOkWERGRxXFkTURE9sWzwYmIiCzOBGDEub4NcBqciIjI4jiyJiIi2+LZ4ERERFaXIsesOQ1ORERkcRxZExGRfaXIyNqyydqfUwhf2iit2JwM/drgHo+sH0pwxXxPoE/Udnggoh0bCOvXhgYAh0e/5m95+ZdEbbeNzRHFT582RTu2u/0TUduqR78G8eWzZ4naxhfO0w71Z+rXhgYAn88rih+dp1/ve/QYWW3wi2ecrx2b7pXVv/dnZmvHjsr0i9r2COpaewQ1/gHAJahpDgBKMEkZHpCdumya+qcrK2HiCfeH9WMjA9qxvYEzOGmbIsma0+BEREQWZ9mRNRER0ZBS5DprJmsiIrItXrpFRERkdTxmTURERFbAkTUREdmXqQAjjtGxaY+RNZM1ERHZF6fBiYiIyAo4siYiIhuLc2QtKHyVTEzWRERkXykyDW7ZZN3Z24Gg0iuFZyj9Mp+ZGfolCgHA69bfkT5Pv6htl+CkCJdDdtW/y69fzvKCqypEbXudXxXFO536NV6dhn4JVgBwGfr70/XlC0Vtp6dlaMem+dJFbTtdsrKdhqG//91uWdsel365XunXmkPQlVC/fjlLAAiF9eMHIrL31cCArC/9gnilZG1HBFU7TFP2PeERfK8YghKsAy4eYU00yyZrIiKiIZkKcU1l82xwIiKiEabM40s869sA5yqIiIgsjiNrIiKyL55gRkREZHE8Zk1ERGRxKTKy5jFrIiIii+PImoiI7EshzpF1wnoyopisiYjIvjgNTkRERFbAkTUREdmXaQKCkqyDr299lk3WHZ098IT06vn29fRqt5vWrV8zGwAy0/TrWudmCtvO0G97lKAfAJDu06+Zne6U1RN2Swo+A3C5BX3xyCZ7lEP/Lexwytp2OwXbKZxKG8mJN3NA1npHT5d2bHhAVv8+ovRrcg8IL6GRhEuvzpF+f0cEKxjCuvAKgs+noH43AAwI6pRL3uJndGaZ0+BERERkBaJkvWbNGsyYMQN+vx9+vx/l5eX4wx/+EP17MBhEZWUlRo8ejYyMDCxevBjt7e0J7zQRERGAz0bW8Sw2IErW48aNwwMPPIDGxkbs2LEDV1xxBa666iq89957AIA77rgDzz33HJ588kls2bIF+/fvxzXXXDMiHSciIoKp4l9sQHTMetGiRTH//slPfoI1a9Zg27ZtGDduHB599FFs2LABV1xxBQDgsccew/nnn49t27bhi1/8YuJ6TURElEKGfYJZJBLBk08+iUAggPLycjQ2NqK/vx8VFRXRmGnTpmH8+PHYunXrKZN1KBRCKBSK/rurS/9kFyIiSm1KmVBx3OYynnXPJPEJZu+88w4yMjLg9Xpx88034+mnn8YFF1yAtrY2eDweZGdnx8QXFBSgra3tlO3V1tYiKysrupSUlIg3goiIUpSKcwr8bDxmDQBTp07Fzp07sX37dtxyyy1YunQp3n///WF3oKamBp2dndGltbV12G0REVGKSZETzMTT4B6PB+eccw4AoLS0FH/5y1/wi1/8AkuWLEE4HEZHR0fM6Lq9vR2FhYWnbM/r9cLrlV2fTERElErivs7aNE2EQiGUlpbC7Xajvr4++rempia0tLSgvLw83qchIiI6mWnGv9iAaGRdU1ODhQsXYvz48eju7saGDRvQ0NCAl156CVlZWbjxxhtRXV2N3Nxc+P1+3HrrrSgvL+eZ4ERENDKUQlw1Ac/GafCDBw/i+uuvx4EDB5CVlYUZM2bgpZdewle/+lUAwM9//nM4HA4sXrwYoVAICxYswMMPPzy8jrmccGmW5XN79TfD6ZZNJoQFv7o6u8Oitgf69dsOhGRvqJysNO1Yr98vatvtlpUndQhec8m+BAAl+KCZwl/QkYh+fCSiX7YRAPr7ZWU7ZW3LtvPo0WPascoh2/eSd605gl+aA/36ZU+Pk31PGILXxe2VlQ4O9+u/t0Jh6Xbqi0T02+7tDYxYP1KV6Jvx0UcfPe3ffT4f6urqUFdXF1eniIiIdCjThDLO/ku3LHsjDyIioiGlyDQ4b+RBRERkcRxZExGRfZkKMM7+kTWTNRER2ZdSAOI47myTZM1pcCIiIovjyJqIiGxLmQoqjmlwyeWfycRkTURE9qVMxDcNzku3iIiIRlSqjKx5zJqIiMjiLDeyPvErJxzs017HoQSbEZGVeRxw6P+eMRx65VFPEPUbsnKWXpdbOzYg2EYAGBCWG/VISrz2j2C5UeF0l2Ho91tabnTAQuVGAwH90pAsNzo4UbnRAdm+l5QbDYu3U5+k3Ghfby+AMzNqHVChuKayBzByn8VEMpTF5gD27t2LkpKSZHeDiIji1NrainHjxo1I28FgEJMmTUJbW1vcbRUWFqK5uRk+ny8BPRsZlkvWpmli//79yMzMhGF89mu1q6sLJSUlaG1thV944wk74XaePVJhGwFu59kmEduplEJ3dzeKi4vhEM7cSQSDQYTDshsoDcbj8Vg6UQMWnAZ3OByn/SXm9/vP6g/KCdzOs0cqbCPA7TzbxLudWVlZCezN4Hw+n+WTbKLwBDMiIiKLY7ImIiKyONska6/Xi5UrV8Lr9Sa7KyOK23n2SIVtBLidZ5tU2U67sdwJZkRERBTLNiNrIiKiVMVkTUREZHFM1kRERBbHZE1ERGRxtknWdXV1mDhxInw+H8rKyvDGG28ku0sJde+998IwjJhl2rRpye5WXF577TUsWrQIxcXFMAwDzzzzTMzflVJYsWIFioqKkJaWhoqKCnz88cfJ6WwchtrOG2644aR9e+WVVyans8NUW1uLSy65BJmZmcjPz8fVV1+NpqammJhgMIjKykqMHj0aGRkZWLx4Mdrb25PU4+HR2c65c+eetD9vvvnmJPV4eNasWYMZM2ZEC5+Ul5fjD3/4Q/TvZ8O+PNvYIllv2rQJ1dXVWLlyJd58803MnDkTCxYswMGDB5PdtYS68MILceDAgejy+uuvJ7tLcQkEApg5cybq6uoG/fuDDz6IX/7yl1i7di22b9+OUaNGYcGCBQgGg2e4p/EZajsB4Morr4zZt0888cQZ7GH8tmzZgsrKSmzbtg1//OMf0d/fj/nz58fcBOSOO+7Ac889hyeffBJbtmzB/v37cc011ySx13I62wkAy5cvj9mfDz74YJJ6PDzjxo3DAw88gMbGRuzYsQNXXHEFrrrqKrz33nsAzo59edZRNjB79mxVWVkZ/XckElHFxcWqtrY2ib1KrJUrV6qZM2cmuxsjBoB6+umno/82TVMVFhaqhx56KPpYR0eH8nq96oknnkhCDxPj89uplFJLly5VV111VVL6M1IOHjyoAKgtW7YopY7vO7fbrZ588slozAcffKAAqK1btyarm3H7/HYqpdSXv/xlddtttyWvUyMkJydH/frXvz5r96XdWX5kHQ6H0djYiIqKiuhjDocDFRUV2Lp1axJ7lngff/wxiouLMXnyZHz7299GS0tLsrs0Ypqbm9HW1hazX7OyslBWVnbW7VcAaGhoQH5+PqZOnYpbbrkFR44cSXaX4tLZ2QkAyM3NBQA0Njaiv78/Zn9OmzYN48ePt/X+/Px2nvD4448jLy8P06dPR01NDXr/ektIO4pEIti4cSMCgQDKy8vP2n1pd5a7kcfnHT58GJFIBAUFBTGPFxQU4MMPP0xSrxKvrKwM69evx9SpU3HgwAH86Ec/wmWXXYZ3330XmZmZye5ewp24rd1g+zURt7yzkiuvvBLXXHMNJk2ahN27d+OHP/whFi5ciK1bt8LplN0D3QpM08Ttt9+OOXPmYPr06QCO70+Px4Ps7OyYWDvvz8G2EwCuu+46TJgwAcXFxXj77bdx5513oqmpCb///e+T2Fu5d955B+Xl5QgGg8jIyMDTTz+NCy64ADt37jzr9uXZwPLJOlUsXLgw+v8zZsxAWVkZJkyYgN/97ne48cYbk9gzite3vvWt6P9fdNFFmDFjBqZMmYKGhgbMmzcviT0bnsrKSrz77ru2P6diKKfazptuuin6/xdddBGKioowb9487N69G1OmTDnT3Ry2qVOnYufOnejs7MRTTz2FpUuXYsuWLcnuFp2C5afB8/Ly4HQ6TzoTsb29HYWFhUnq1cjLzs7Geeedh127diW7KyPixL5Ltf0KAJMnT0ZeXp4t921VVRWef/55vPrqqzG3si0sLEQ4HEZHR0dMvF3356m2czBlZWUAYLv96fF4cM4556C0tBS1tbWYOXMmfvGLX5x1+/JsYflk7fF4UFpaivr6+uhjpmmivr4e5eXlSezZyOrp6cHu3btRVFSU7K6MiEmTJqGwsDBmv3Z1dWH79u1n9X4FgL179+LIkSO22rdKKVRVVeHpp5/GK6+8gkmTJsX8vbS0FG63O2Z/NjU1oaWlxVb7c6jtHMzOnTsBwFb7czCmaSIUCp01+/Ksk+wz3HRs3LhReb1etX79evX++++rm266SWVnZ6u2trZkdy1hvve976mGhgbV3Nys/vSnP6mKigqVl5enDh48mOyuDVt3d7d666231FtvvaUAqFWrVqm33npLffrpp0oppR544AGVnZ2tnn32WfX222+rq666Sk2aNEn19fUluecyp9vO7u5u9f3vf19t3bpVNTc3q5dffln93d/9nTr33HNVMBhMdte13XLLLSorK0s1NDSoAwcORJfe3t5ozM0336zGjx+vXnnlFbVjxw5VXl6uysvLk9hruaG2c9euXeq+++5TO3bsUM3NzerZZ59VkydPVpdffnmSey5z1113qS1btqjm5mb19ttvq7vuuksZhqH+53/+Ryl1duzLs40tkrVSSv3qV79S48ePVx6PR82ePVtt27Yt2V1KqCVLlqiioiLl8XjU2LFj1ZIlS9SuXbuS3a24vPrqqwrAScvSpUuVUscv37rnnntUQUGB8nq9at68eaqpqSm5nR6G021nb2+vmj9/vhozZoxyu91qwoQJavny5bb7oTnY9gFQjz32WDSmr69Pffe731U5OTkqPT1dff3rX1cHDhxIXqeHYajtbGlpUZdffrnKzc1VXq9XnXPOOepf/uVfVGdnZ3I7LvRP//RPasKECcrj8agxY8aoefPmRRO1UmfHvjzb8BaZREREFmf5Y9ZERESpjsmaiIjI4pisiYiILI7JmoiIyOKYrImIiCyOyZqIiMjimKyJiIgsjsmaiIjI4pisiYiILI7JmoiIyOKYrImIiCyOyZqIiMji/n+WzsiRqGTOswAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ci_kGCiiVYN"
   },
   "source": [
    "### 모델 구성\n",
    "* 직접 모델을 구현해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zc-5rcdFAmDP",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:22.212426Z",
     "start_time": "2023-12-27T06:42:21.700315Z"
    }
   },
   "source": [
    "# 1번 방법\n",
    "# model = Sequential()\n",
    "# model.add() # (32#필터갯수, 3#필터사이즈)\n",
    "# \n",
    "# # 2번 방법\n",
    "# model = Sequential([\n",
    "#                     #layer,\n",
    "#                     #layer,\n",
    "# ]) \n",
    "\n",
    "# 모델의 output\n",
    "# 1번 구현 방법\n",
    "... # loss fn => from_logits 는 마지막 레이어의 activation과 관련\n",
    "#model.add(layers.Dense(10, activation='softmax')) # from_logits=False\n",
    "\n",
    "# 2번 구현 방법\n",
    "#model.add(layers.Dense(10)) # activation을 거치지않은 데이터를 logits\n",
    "# from_logits=True => 마지막 레이어에 activation이 없다."
   ],
   "execution_count": 186,
   "outputs": [
    {
     "data": {
      "text/plain": "Ellipsis"
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# F API\n",
    "input_tensor = layers.Input(shape=(32,32,3,)) # 1개 데이터의 특성\n",
    "\n",
    "x = layers.Conv2D(32, 3, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(input_tensor)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "x = layers.Conv2D(32,3,strides= 2, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(input_tensor)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPool2D((2,2))(x)\n",
    "x = layers.Dropout(0.1)(x)\n",
    "\n",
    "x = layers.Conv2D(64, 3, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Conv2D(64, 3, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "x = layers.Conv2D(128, 3, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Conv2D(128, 3, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "x = layers.Dropout(0.3)(x)\n",
    "\n",
    "# x = layers.Conv2D(256, 3, padding='same', kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x= layers.Dropout(0.4)(x)\n",
    "# x = layers.Activation('relu')(x)\n",
    "# x = layers.MaxPool2D((2,2))(x)\n",
    "\n",
    "\n",
    "x = layers.Flatten()(x)\n",
    "# x = layers.Dense(512, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Activation('relu')(x)\n",
    "# \n",
    "\n",
    "x = layers.Dense(256, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "x = layers.Dense(64, kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "x= layers.Dense(10,kernel_initializer=tf.keras.initializers.HeUniform(), kernel_regularizer=tf.keras.regularizers.L2(0.0001))(x)\n",
    "output_tensor = layers.Activation('softmax')(x)\n",
    "\n",
    "\n",
    "# 최종 모델 완성\n",
    "model = tf.keras.Model(input_tensor, output_tensor)"
   ],
   "metadata": {
    "id": "7UJxwGG2uTe9",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:23.540644Z",
     "start_time": "2023-12-27T06:42:21.776918Z"
    }
   },
   "execution_count": 187,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA76LqFwpH-X"
   },
   "source": [
    "* 모델이 잘 생성 되었는지 간단하게 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g8BnMTZyRL53",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:24.457076Z",
     "start_time": "2023-12-27T06:42:23.544662Z"
    }
   },
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "predictions = model(train_data[0:1], training=False)\n",
    "print(\"Predictions: \", predictions.numpy()) # 총 10개의 데이터가 나오면 모델이 잘 구성된겁니다."
   ],
   "execution_count": 188,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions:  [[0.14181507 0.06159389 0.17036344 0.15410633 0.11789883 0.08184543\n",
      "  0.07129439 0.02128848 0.12902722 0.05076691]]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nct8JiQxpLsX"
   },
   "source": [
    "* 위 Predictions 결과가 총 10개 짜리 리스트로 출력 된다면, 현재 테스크에서 정상적인 출력입니다.\n",
    "    * cifar10 dataset은 정답이 총 10개로 이뤄져 있습니다.\n",
    "    * 출력값은 마지막 output layer에 activation의 유무에 따라서 값이 달라지며, activation을 통과하기전 데이터를 logit이라고 이야기합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJRZU65fl2xz"
   },
   "source": [
    "### Model compile\n",
    "* 학습을 위한 Optimizer와 Loss fn을 설정해준다.\n",
    "    * Optimzier는 learning rate를 인자로 가지며, 모델의 학습정도를 컨트롤합니다.\n",
    "    * Loss fn은 모델의 예측결과와 실제 정답간의 차이를 loss로 계산해 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P3I0O8MaRL57",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:24.477697Z",
     "start_time": "2023-12-27T06:42:24.462440Z"
    }
   },
   "source": [
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4), # learning rate가 기본값으로 1e-3으로 들어가있습니다.\n",
    "              loss= tf.keras.losses.CategoricalCrossentropy(from_logits=False)\n",
    "             ,\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": 189,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3KF1BT7aRL5-",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:24.802203Z",
     "start_time": "2023-12-27T06:42:24.483027Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 190,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_32\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_65 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_241 (Conv2D)         (None, 30, 30, 32)        896       \n",
      "                                                                 \n",
      " batch_normalization_291 (Ba  (None, 30, 30, 32)       128       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_323 (Activation)  (None, 30, 30, 32)       0         \n",
      "                                                                 \n",
      " max_pooling2d_216 (MaxPooli  (None, 15, 15, 32)       0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " dropout_60 (Dropout)        (None, 15, 15, 32)        0         \n",
      "                                                                 \n",
      " conv2d_242 (Conv2D)         (None, 13, 13, 64)        18496     \n",
      "                                                                 \n",
      " batch_normalization_292 (Ba  (None, 13, 13, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_324 (Activation)  (None, 13, 13, 64)       0         \n",
      "                                                                 \n",
      " conv2d_243 (Conv2D)         (None, 11, 11, 64)        36928     \n",
      "                                                                 \n",
      " batch_normalization_293 (Ba  (None, 11, 11, 64)       256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_325 (Activation)  (None, 11, 11, 64)       0         \n",
      "                                                                 \n",
      " max_pooling2d_217 (MaxPooli  (None, 5, 5, 64)         0         \n",
      " ng2D)                                                           \n",
      "                                                                 \n",
      " conv2d_244 (Conv2D)         (None, 3, 3, 128)         73856     \n",
      "                                                                 \n",
      " batch_normalization_294 (Ba  (None, 3, 3, 128)        512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_326 (Activation)  (None, 3, 3, 128)        0         \n",
      "                                                                 \n",
      " conv2d_245 (Conv2D)         (None, 1, 1, 128)         147584    \n",
      "                                                                 \n",
      " batch_normalization_295 (Ba  (None, 1, 1, 128)        512       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_327 (Activation)  (None, 1, 1, 128)        0         \n",
      "                                                                 \n",
      " dropout_61 (Dropout)        (None, 1, 1, 128)         0         \n",
      "                                                                 \n",
      " flatten_28 (Flatten)        (None, 128)               0         \n",
      "                                                                 \n",
      " dense_107 (Dense)           (None, 256)               33024     \n",
      "                                                                 \n",
      " dropout_62 (Dropout)        (None, 256)               0         \n",
      "                                                                 \n",
      " batch_normalization_296 (Ba  (None, 256)              1024      \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_328 (Activation)  (None, 256)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 64)                16448     \n",
      "                                                                 \n",
      " batch_normalization_297 (Ba  (None, 64)               256       \n",
      " tchNormalization)                                               \n",
      "                                                                 \n",
      " activation_329 (Activation)  (None, 64)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 10)                650       \n",
      "                                                                 \n",
      " activation_330 (Activation)  (None, 10)               0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 330,826\n",
      "Trainable params: 329,354\n",
      "Non-trainable params: 1,472\n",
      "_________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OKIiPxAgoItQ",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:42:24.805388Z",
     "start_time": "2023-12-27T06:42:24.562391Z"
    }
   },
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir, # save point dir\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n",
    "                                            monitor='val_loss',\n",
    "                                            restore_best_weights=True,\n",
    "                                            verbose=1)"
   ],
   "execution_count": 191,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B3sOL3HCRL6A",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:48:54.019913Z",
     "start_time": "2023-12-27T06:42:24.563655Z"
    }
   },
   "source": [
    "max_epochs = 50\n",
    "\n",
    "# using `tf.data.Dataset`\n",
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=len(train_data) // batch_size,\n",
    "                    epochs=max_epochs,\n",
    "                    validation_data=valid_dataset,\n",
    "                    validation_steps=len(valid_data) // batch_size,\n",
    "                    callbacks=[cp_callback,early_stopping_cb]\n",
    "                    )"
   ],
   "execution_count": 192,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 15:42:25.800740: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1562/1562 [==============================] - ETA: 0s - loss: 2.1477 - accuracy: 0.2800"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-27 15:45:14.692510: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: val_loss improved from inf to 1.76856, saving model to .//cifar10_classification/exp1\n",
      "1562/1562 [==============================] - 172s 107ms/step - loss: 2.1477 - accuracy: 0.2800 - val_loss: 1.7686 - val_accuracy: 0.4163\n",
      "Epoch 2/50\n",
      "1562/1562 [==============================] - ETA: 0s - loss: 1.7292 - accuracy: 0.4278\n",
      "Epoch 2: val_loss improved from 1.76856 to 1.53686, saving model to .//cifar10_classification/exp1\n",
      "1562/1562 [==============================] - 165s 105ms/step - loss: 1.7292 - accuracy: 0.4278 - val_loss: 1.5369 - val_accuracy: 0.5111\n",
      "Epoch 3/50\n",
      " 515/1562 [========>.....................] - ETA: 1:43 - loss: 1.5928 - accuracy: 0.4812"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[192], line 4\u001B[0m\n\u001B[1;32m      1\u001B[0m max_epochs \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m50\u001B[39m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m# using `tf.data.Dataset`\u001B[39;00m\n\u001B[0;32m----> 4\u001B[0m history \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[43m                    \u001B[49m\u001B[43msteps_per_epoch\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mtrain_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      6\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmax_epochs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      7\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_data\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvalid_dataset\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      8\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mvalidation_steps\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mvalid_data\u001B[49m\u001B[43m)\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[38;5;241;43m/\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m      9\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m[\u001B[49m\u001B[43mcp_callback\u001B[49m\u001B[43m,\u001B[49m\u001B[43mearly_stopping_cb\u001B[49m\u001B[43m]\u001B[49m\n\u001B[1;32m     10\u001B[0m \u001B[43m                    \u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/keras/utils/traceback_utils.py:65\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 65\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     67\u001B[0m     filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/keras/engine/training.py:1564\u001B[0m, in \u001B[0;36mModel.fit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1556\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m tf\u001B[38;5;241m.\u001B[39mprofiler\u001B[38;5;241m.\u001B[39mexperimental\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[1;32m   1557\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   1558\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1561\u001B[0m     _r\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m,\n\u001B[1;32m   1562\u001B[0m ):\n\u001B[1;32m   1563\u001B[0m     callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[0;32m-> 1564\u001B[0m     tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1565\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[1;32m   1566\u001B[0m         context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001B[0m, in \u001B[0;36mfilter_traceback.<locals>.error_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m filtered_tb \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m--> 150\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mfn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    151\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mException\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m    152\u001B[0m   filtered_tb \u001B[38;5;241m=\u001B[39m _process_traceback_frames(e\u001B[38;5;241m.\u001B[39m__traceback__)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    912\u001B[0m compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mxla\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    914\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m OptionalXlaContext(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_jit_compile):\n\u001B[0;32m--> 915\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    917\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mexperimental_get_tracing_count()\n\u001B[1;32m    918\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001B[0m, in \u001B[0;36mFunction._call\u001B[0;34m(self, *args, **kwds)\u001B[0m\n\u001B[1;32m    944\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[1;32m    945\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[1;32m    946\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[0;32m--> 947\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[1;32m    948\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    949\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[1;32m    950\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[1;32m    951\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2496\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   2493\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[1;32m   2494\u001B[0m   (graph_function,\n\u001B[1;32m   2495\u001B[0m    filtered_flat_args) \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[0;32m-> 2496\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   2497\u001B[0m \u001B[43m    \u001B[49m\u001B[43mfiltered_flat_args\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1862\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[0;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[1;32m   1858\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPossibleTapeGradientTypes(args)\n\u001B[1;32m   1859\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m gradients_util\u001B[38;5;241m.\u001B[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001B[1;32m   1860\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[1;32m   1861\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[0;32m-> 1862\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1863\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m   1864\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[1;32m   1865\u001B[0m     args,\n\u001B[1;32m   1866\u001B[0m     possible_gradient_type,\n\u001B[1;32m   1867\u001B[0m     executing_eagerly)\n\u001B[1;32m   1868\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/function.py:499\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[0;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[1;32m    497\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    498\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 499\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    500\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    501\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    502\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    503\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    504\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    505\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    506\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[1;32m    507\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[1;32m    508\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    511\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[1;32m    512\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001B[0m, in \u001B[0;36mquick_execute\u001B[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[0;32m---> 54\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     55\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     56\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[1;32m     57\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjLV8zaxgc4V"
   },
   "source": [
    "### 학습 결과를 정리해봅시다.\n",
    "* Model 학습을 진행하며 저장된 결과를 전달 받은 history 객체를 이용해 학습 과정을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kH93caN_RL6E",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.019631Z"
    }
   },
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Valid Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Valid Loss')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5B3sWG8UIz3"
   },
   "source": [
    "### 모델 평가\n",
    "* Model 학습 후 저장된 weight를 다시 불러와 테스트를 진행합니다.\n",
    "    * 학습이 진행되며, 가장 낮은 val-loss를 이용해 모델을 저장했기 때문에 가장 작은 val-loss를 가지는 곳의 파라미터가 저장되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VC8Sjhk9lSMF",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:48:54.026846Z",
     "start_time": "2023-12-27T06:48:54.024079Z"
    }
   },
   "source": [
    "model.load_weights(checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb3Lm60fwWgf"
   },
   "source": [
    "* 모델 파라미터를 불러온 후 테스트 데이터셋을 이용해 평가를 진행합니다.\n",
    "* 가장 기본적인 Accuracy를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ByXBzpzzRL6K",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.024294Z"
    }
   },
   "source": [
    "results = model.evaluate(test_dataset, steps=len(test_data) // batch_size)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8cfSwvB5RL6O",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:48:54.052845Z",
     "start_time": "2023-12-27T06:48:54.027991Z"
    }
   },
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YJnX3YfnRL6T",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.029362Z"
    }
   },
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(32, 32, 3))\n",
    "  p.axis('off')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q6NOnoZYIrR"
   },
   "source": [
    "### 평가 메트릭을 설정해보자\n",
    "* 인공지능 모델을 이용해 문제를 해결할 시에 해당 분야에서 고유하게 사용하던 평가 메트릭 혹은 새로운 메트릭이 사용되기도 합니다.\n",
    "* Classification에서 사용되었던 평가 지표를 사용해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJE2--mMZO-7"
   },
   "source": [
    "## Measuring final score\n",
    "* 모델 평가 지표\n",
    "\n",
    "### \\begin{equation*} M = 50(P + min(\\frac{1}{S}, 1)) \\end{equation*}\n",
    "\n",
    "* P : Model-accuracy\n",
    "* S : Size of model (MB)\n",
    "\n",
    "\n",
    "### \\begin{equation*} S = \\frac{Parameters * float_{size}}{MB} \\end{equation*}\n",
    "\\begin{equation*} = \\frac{M_p * 32} {1024^2} \\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "* 해당 지표는 분류 평가를 위한 내용이며, 모델의 크기에 따른 정확도를 나타내는 지표입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4R945JcpRL6Y",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.030556Z"
    }
   },
   "source": [
    "def final_score():\n",
    "    print(\"Model params num : \" + str(model.count_params()))\n",
    "    print(\"Accuracy : \" + str(results[1]))\n",
    "\n",
    "    s = (model.count_params() * 32) / (1024 ** 2)\n",
    "    score = 50 * (results[1] + min((1/s), 1))\n",
    "\n",
    "    print(\"score : \" + str(score))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbuQllIxv2ww"
   },
   "source": [
    "### 스코어 결과\n",
    "* 위의 스코어는 분류모델에 적용되는 스코어입니다.\n",
    "* 모델의 크기 (MB) 와 정확도를 이용해 스코어를 출력합니다.\n",
    "    * 40 이상의 스코어에 도전해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NWs2D_Y5RL6a",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.031923Z"
    }
   },
   "source": [
    "final_score()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56iBGUMV2B-y"
   },
   "source": [
    "### 추가 과제\n",
    "* 높은 스코어를 달성하신 분들께선 더 맞추기 어려운 데이터셋으로 도전해보세요.\n",
    "\n",
    "```\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.cifar100.load_data()\n",
    "```\n",
    "\n",
    "* 데이터 로드 파트에서 위 코드를 고치면 더 세분화된 분류를 진행하는 데이터셋을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "56c1gImLgAVk",
    "ExecuteTime": {
     "start_time": "2023-12-27T06:48:54.033185Z"
    }
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
