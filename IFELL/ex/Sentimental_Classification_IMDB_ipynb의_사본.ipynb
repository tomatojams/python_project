{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "553px",
    "left": "792px",
    "right": "61px",
    "top": "71px",
    "width": "375px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9oq4UnWajC9u"
   },
   "source": [
    "# Sentiment Classification\n",
    "\n",
    "### Task\n",
    "* IMDB 영화사이트에서 50000개의 영화평을 가지고 positive/negative인지 구분해보자.\n",
    "* 데이터 불러오기를 제외한 딥러닝 트레이닝 과정을 직접 구현해보는 것이 목표 입니다.\n",
    "\n",
    "### Dataset\n",
    "* [IMDB datasets](https://www.imdb.com/interfaces/)\n",
    "\n",
    "### Base code\n",
    "* Dataset: train, val, test로 split\n",
    "* Input data shape: (`batch_size`, `max_sequence_length`)\n",
    "* Output data shape: (`batch_size`, 1)\n",
    "* Architecture:\n",
    "  * RNN을 이용한 간단한 classification 모델 가이드\n",
    "  * `Embedding` - `SimpleRNN` - `Dense (with Sigmoid)`\n",
    "  * [`tf.keras.layers`](https://www.tensorflow.org/api_docs/python/tf/keras/layers) 사용\n",
    "* Training\n",
    "  * `model.fit` 사용\n",
    "* Evaluation\n",
    "  * `model.evaluate` 사용 for test dataset\n",
    "\n",
    "### Try some techniques\n",
    "* Training-epochs 조절\n",
    "* Change model architectures (Custom model)\n",
    "  * Use another cells (LSTM, GRU, etc.)\n",
    "  * Use dropout layers\n",
    "* Embedding size 조절\n",
    "  * 또는 one-hot vector로 학습\n",
    "* Number of words in the vocabulary 변화\n",
    "* `pad` 옵션 변화\n",
    "* Data augmentation (if possible)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iKq6mIljjC9v"
   },
   "source": [
    "## 자연어처리에 관한 work flow\n",
    "\n",
    "The flowchart of the algorithm is roughly:\n",
    "\n",
    "<img src=\"https://user-images.githubusercontent.com/11681225/46912373-d2a3a800-cfae-11e8-8201-ef17b65834f5.png\" alt=\"natural_language_flowchart\" style=\"width: 300px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OW9rRFr4jC9w"
   },
   "source": [
    "## Import modules"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Gbt0_EpOvL6C",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:46.697440600Z",
     "start_time": "2024-01-06T14:23:46.666360500Z"
    }
   },
   "source": [
    "use_colab = True\n",
    "assert use_colab in [True, False]"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ibO_zjJmvN3s",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d070f857-c609-4160-b893-17d556c7e91f",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:46.713972200Z",
     "start_time": "2024-01-06T14:23:46.687415600Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ct7ZVZ2EjC9x",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:49.552096600Z",
     "start_time": "2024-01-06T14:23:46.702446Z"
    }
   },
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "import tarfile\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import layers"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-e3ucn5_jC90"
   },
   "source": [
    "## Load Data\n",
    "\n",
    "* IMDB에서 다운받은 총 50000개의 영화평을 사용한다.\n",
    "* `tf.keras.datasets`에 이미 잘 가공된 데이터 셋이 있으므로 쉽게 다운받아 사용할 수 있다.\n",
    "* 원래는 text 데이터이지만 `tf.keras.datasets.imdb`는 이미 Tokenizing이 되어있다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DKOg8JCsjC91",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.200390300Z",
     "start_time": "2024-01-06T14:23:49.548572400Z"
    }
   },
   "source": [
    "# Load training and eval data from tf.keras\n",
    "imdb = tf.keras.datasets.imdb\n",
    "\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)\n",
    "train_labels = train_labels.astype(np.float64)\n",
    "test_labels = test_labels.astype(np.float64)"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "7mL9LbzXjC96",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "91170745-0e1a-49a8-8378-0433425c44b4",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.224060100Z",
     "start_time": "2024-01-06T14:23:52.202390700Z"
    }
   },
   "source": [
    "print(\"Train-set size: \", len(train_data))\n",
    "print(\"Test-set size:  \", len(test_data))"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train-set size:  25000\n",
      "Test-set size:   25000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "x0_MzKDJjC9-"
   },
   "source": [
    "### Data 출력\n",
    "* 데이터셋을 바로 불러왔을때 출력되는 데이터를 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QkWxsmedjC9_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "543ce45e-8083-4d83-b53e-5c943f293bd8",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.252634200Z",
     "start_time": "2024-01-06T14:23:52.219556200Z"
    }
   },
   "source": [
    "print(train_data[1])"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UxOl00BUjC-C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4a74f6e8-6f4d-4e52-9818-7110e732a0b7",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.255147700Z",
     "start_time": "2024-01-06T14:23:52.232576600Z"
    }
   },
   "source": [
    "print(\"sequence length: {}\".format(len(train_data[1])))"
   ],
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sequence length: 189\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XtrDXZZ3jC-F"
   },
   "source": [
    "* Label정보를 확인해보자\n",
    "  * 0.0 for a negative sentiment 부정적인 리뷰\n",
    "  * 1.0 for a positive sentiment 긍정적인 리뷰"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "pAQISHYVjC-G",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "63ceeeae-a035-4180-e4fa-bcc2d349063c",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.309594200Z",
     "start_time": "2024-01-06T14:23:52.249634400Z"
    }
   },
   "source": [
    "# negative sample\n",
    "index = 1\n",
    "print(\"text: {}\\n\".format(train_data[index]))\n",
    "print(\"label: {}\".format(train_labels[index]))"
   ],
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: [1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]\n",
      "\n",
      "label: 0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aE-lF_gqjC-K",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1dd43d3a-aff2-4a52-ce04-eaa3531ecc05",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.311594300Z",
     "start_time": "2024-01-06T14:23:52.265174600Z"
    }
   },
   "source": [
    "# positive sample\n",
    "index = 200\n",
    "print(\"text: {}\\n\".format(train_data[index]))\n",
    "print(\"label: {}\".format(train_labels[index]))"
   ],
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: [1, 14, 9, 6, 227, 196, 241, 634, 891, 234, 21, 12, 69, 6, 6, 176, 7, 4, 804, 4658, 2999, 667, 11, 12, 11, 85, 715, 6, 176, 7, 1565, 8, 1108, 10, 10, 12, 16, 1844, 2, 33, 211, 21, 69, 49, 2009, 905, 388, 99, 2, 125, 34, 6, 2, 1274, 33, 4, 130, 7, 4, 22, 15, 16, 6424, 8, 650, 1069, 14, 22, 9, 44, 4609, 153, 154, 4, 318, 302, 1051, 23, 14, 22, 122, 6, 2093, 292, 10, 10, 723, 8721, 5, 2, 9728, 71, 1344, 1576, 156, 11, 68, 251, 5, 36, 92, 4363, 133, 199, 743, 976, 354, 4, 64, 439, 9, 3059, 17, 32, 4, 2, 26, 256, 34, 2, 5, 49, 7, 98, 40, 2345, 9844, 43, 92, 168, 147, 474, 40, 8, 67, 6, 796, 97, 7, 14, 20, 19, 32, 2188, 156, 24, 18, 6090, 1007, 21, 8, 331, 97, 4, 65, 168, 5, 481, 53, 3084]\n",
      "\n",
      "label: 1.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YqlZw3GNjC-Q"
   },
   "source": [
    "## Prepare dataset\n",
    "\n",
    "### Convert the integers back to words\n",
    "\n",
    "* 실제 우리가 다루고 있는 데이터가 진짜 리뷰데이터인지 확인해보자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bUX_-fu3jC-Q",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.409590600Z",
     "start_time": "2024-01-06T14:23:52.293841600Z"
    }
   },
   "source": [
    "# A dictionary mapping words to an integer index\n",
    "word_index = imdb.get_word_index()\n",
    "\n",
    "# The first indices are reserved\n",
    "word_index = {k:(v+3) for k,v in word_index.items()}\n",
    "word_index[\"<PAD>\"] = 0\n",
    "word_index[\"<START>\"] = 1\n",
    "word_index[\"<UNK>\"] = 2  # unknown\n",
    "word_index[\"<UNUSED>\"] = 3\n",
    "\n",
    "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
    "\n",
    "def decode_review(text):\n",
    "  return ' '.join([reverse_word_index.get(i, '?') for i in text])\n"
   ],
   "execution_count": 10,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "len(word_index)"
   ],
   "metadata": {
    "id": "sWIHZFwGk2Xt",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ee0710ab-67c2-40fe-cdec-3ea2e555f919",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.429653100Z",
     "start_time": "2024-01-06T14:23:52.410593700Z"
    }
   },
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "88588"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VQd9gEAqjC-S"
   },
   "source": [
    "#### Text data 출력"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "z-ss_usJjC-T",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "603417a8-a412-442b-fe6e-a980c1564759",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.462271100Z",
     "start_time": "2024-01-06T14:23:52.425134Z"
    }
   },
   "source": [
    "print(train_data[5])\n",
    "len(train_data)"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 778, 128, 74, 12, 630, 163, 15, 4, 1766, 7982, 1051, 2, 32, 85, 156, 45, 40, 148, 139, 121, 664, 665, 10, 10, 1361, 173, 4, 749, 2, 16, 3804, 8, 4, 226, 65, 12, 43, 127, 24, 2, 10, 10]\n"
     ]
    },
    {
     "data": {
      "text/plain": "25000"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YZsvB20qjC-V",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "outputId": "56708c79-9312-4271-b7db-36d900bae76f",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.464783400Z",
     "start_time": "2024-01-06T14:23:52.439048300Z"
    }
   },
   "source": [
    "decode_review(train_data[5])"
   ],
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "\"<START> begins better than it ends funny that the russian submarine crew <UNK> all other actors it's like those scenes where documentary shots br br spoiler part the message <UNK> was contrary to the whole story it just does not <UNK> br br\""
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EJyBVg01TM0Y",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "73be7642-c6fa-4346-f334-a49a5a941e4f",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.504888200Z",
     "start_time": "2024-01-06T14:23:52.455760200Z"
    }
   },
   "source": [
    "print(train_labels[5])"
   ],
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z8yYy2OPjC-a"
   },
   "source": [
    "### Padding and truncating data using pad sequences\n",
    "* 전부 길이가 다른 리뷰들의 길이를 통일해주자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Wb0_NqMZjC-a",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.505888300Z",
     "start_time": "2024-01-06T14:23:52.471298Z"
    }
   },
   "source": [
    "from tensorflow.keras.utils import pad_sequences"
   ],
   "execution_count": 15,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fU6L4MjLjC-c",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.528449Z",
     "start_time": "2024-01-06T14:23:52.488341800Z"
    }
   },
   "source": [
    "num_seq_length = np.array([len(tokens) for tokens in list(train_data) + list(test_data)])\n",
    "train_seq_length = np.array([len(tokens) for tokens in train_data], dtype=np.int32)\n",
    "test_seq_length = np.array([len(tokens) for tokens in test_data], dtype=np.int32)\n",
    "print(len(train_seq_length))"
   ],
   "execution_count": 16,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wPg8nfTvjC-f",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.542472800Z",
     "start_time": "2024-01-06T14:23:52.519430600Z"
    }
   },
   "source": [
    "max_seq_length = 728"
   ],
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vmIjHB2CAzMv"
   },
   "source": [
    "* Max length보다 작은 리뷰의 퍼센트"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "R6OsdVicjC-h",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b573e409-bf35-4015-e9bf-df087954f130",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.581262300Z",
     "start_time": "2024-01-06T14:23:52.533953300Z"
    }
   },
   "source": [
    "print(np.sum(num_seq_length < max_seq_length) / len(num_seq_length))"
   ],
   "execution_count": 18,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.97304\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjzECbvIjC-k"
   },
   "source": [
    "* `max_seq_length`을 256으로 설정하면 전체 데이터 셋의 70%를 커버할 수 있다.\n",
    "* 30% 정도의 데이터가 256 단어가 넘는 문장으로 이루어져 있다.\n",
    "* 보통 미리 정한 `max_seq_length`를 넘어가는 문장의 데이터는 *truncate* 한다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mygycLN_jC-k",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.582261300Z",
     "start_time": "2024-01-06T14:23:52.549654500Z"
    }
   },
   "source": [
    "# padding 옵션은 두 가지가 있다.\n",
    "pad = 'pre'\n",
    "# pad = 'post'"
   ],
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nyIeOTuujC-m",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:52.994120900Z",
     "start_time": "2024-01-06T14:23:52.570236100Z"
    }
   },
   "source": [
    "train_data_pad = pad_sequences(train_data,\n",
    "                               maxlen=max_seq_length,\n",
    "                               padding=pad,\n",
    "                               value=word_index[\"<PAD>\"])\n",
    "test_data_pad = pad_sequences(test_data,\n",
    "                              maxlen=max_seq_length,\n",
    "                              padding=pad,\n",
    "                              value=word_index[\"<PAD>\"])"
   ],
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "quksHiyqjC-o",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "ca8027d7-42be-4539-c019-2276a803747d",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:53.006246400Z",
     "start_time": "2024-01-06T14:23:52.990589200Z"
    }
   },
   "source": [
    "print(train_data_pad.shape)\n",
    "print(test_data_pad.shape)"
   ],
   "execution_count": 21,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 728)\n",
      "(25000, 728)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d6YYEc0bjC-q"
   },
   "source": [
    "#### Padding data 출력"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "dCI9mcsVjC-r",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "aa44ede7-70c7-45bb-a467-dc0255b4d239",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:53.055102800Z",
     "start_time": "2024-01-06T14:23:53.005245100Z"
    }
   },
   "source": [
    "index = 0\n",
    "print(\"text: {}\\n\".format(decode_review(train_data[index])))\n",
    "print(\"token: {}\\n\".format(train_data[index]))\n",
    "print(\"pad: {}\".format(train_data_pad[index]))"
   ],
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text: <START> this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert <UNK> is an amazing actor and now the same being director <UNK> father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for <UNK> and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also <UNK> to the two little boy's that played the <UNK> of norman and paul they were just brilliant children are often left out of the <UNK> list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "\n",
      "token: [1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]\n",
      "\n",
      "pad: [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    0    0    0    0    0    1   14   22   16   43  530  973 1622\n",
      " 1385   65  458 4468   66 3941    4  173   36  256    5   25  100   43\n",
      "  838  112   50  670    2    9   35  480  284    5  150    4  172  112\n",
      "  167    2  336  385   39    4  172 4536 1111   17  546   38   13  447\n",
      "    4  192   50   16    6  147 2025   19   14   22    4 1920 4613  469\n",
      "    4   22   71   87   12   16   43  530   38   76   15   13 1247    4\n",
      "   22   17  515   17   12   16  626   18    2    5   62  386   12    8\n",
      "  316    8  106    5    4 2223 5244   16  480   66 3785   33    4  130\n",
      "   12   16   38  619    5   25  124   51   36  135   48   25 1415   33\n",
      "    6   22   12  215   28   77   52    5   14  407   16   82    2    8\n",
      "    4  107  117 5952   15  256    4    2    7 3766    5  723   36   71\n",
      "   43  530  476   26  400  317   46    7    4    2 1029   13  104   88\n",
      "    4  381   15  297   98   32 2071   56   26  141    6  194 7486   18\n",
      "    4  226   22   21  134  476   26  480    5  144   30 5535   18   51\n",
      "   36   28  224   92   25  104    4  226   65   16   38 1334   88   12\n",
      "   16  283    5   16 4472  113  103   32   15   16 5345   19  178   32]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KU115TnojC-t"
   },
   "source": [
    "### Create a validation set"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "cG6qc-5njC-t",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:53.056103300Z",
     "start_time": "2024-01-06T14:23:53.021483400Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "# num_val_data = int(0.1 * len(test_data_pad))\n",
    "# val_data_pad = test_data_pad[:num_val_data]\n",
    "# train_data_pad_partial = test_data_pad[num_val_data:]\n",
    "# \n",
    "# val_labels = test_labels[:num_val_data]\n",
    "# train_labels_partial = test_labels[num_val_data:]"
   ],
   "execution_count": 23,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "num_val_data = int(0.1 * len(train_data_pad))\n",
    "val_data_pad = train_data_pad[:num_val_data]\n",
    "train_data_pad_partial = train_data_pad[num_val_data:]\n",
    "\n",
    "val_labels = train_labels[:num_val_data]\n",
    "train_labels_partial = train_labels[num_val_data:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:53.077185900Z",
     "start_time": "2024-01-06T14:23:53.038544500Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "source": [
    "len(train_data_pad)"
   ],
   "metadata": {
    "id": "jlCfbzv6ZWC1",
    "outputId": "4077a679-2eba-4922-e296-93c045ba07ff",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:53.080192600Z",
     "start_time": "2024-01-06T14:23:53.054093300Z"
    }
   },
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "25000"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9CPqHeI9y7g2"
   },
   "source": [
    "### Dataset 구성"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "bVhh2SOcjC_C",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "a0296289-3a90-4152-ca55-90e05ae1e49c",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:54.231532400Z",
     "start_time": "2024-01-06T14:23:54.211217500Z"
    }
   },
   "source": [
    "batch_size = 64\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_data_pad_partial, train_labels_partial))\n",
    "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_data_pad, test_labels))\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)\n",
    "\n",
    "# for valid\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_data_pad, val_labels))\n",
    "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
    "print(valid_dataset)"
   ],
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 728), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 728), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n",
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 728), dtype=tf.int32, name=None), TensorSpec(shape=(None,), dtype=tf.float64, name=None))>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "id": "cxcQnl2FtsOC"
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I5KBM5sdjC-v"
   },
   "source": [
    "## Setup hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P1fls3PEjC-w",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:54.259622600Z",
     "start_time": "2024-01-06T14:23:54.231532400Z"
    }
   },
   "source": [
    "# Set the hyperparameter set\n",
    "max_epochs = 5\n",
    "embedding_size = 16\n",
    "rnn_units = 32\n",
    "vocab_size = 10000\n",
    "\n",
    "# the save point\n",
    "if use_colab:\n",
    "    checkpoint_dir ='./drive/My Drive/train_ckpt/sentimental/exp1'\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "else:\n",
    "    checkpoint_dir = 'sentimental/exp1'"
   ],
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMG2MOXUjC-y"
   },
   "source": [
    "## Build the model\n",
    "### Embedding layer\n",
    "\n",
    "* embedding-layer는 전체 vocabulary의 갯수(num_words)로 이루어진 index가 `embedding_size`의 *dense vector* 로 변환되는 과정이다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "0li13tSGjC-1",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:54.261624Z",
     "start_time": "2024-01-06T14:23:54.247578800Z"
    }
   },
   "source": [
    "# model = tf.keras.Sequential()\n",
    "# model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size\n",
    "#                                 ))\n",
    "# \n",
    "# model.add(layers.LSTM(units=rnn_units, return_sequences=True, \n",
    "#                       recurrent_initializer='glorot_uniform'))\n",
    "# model.add(layers.LSTM(units=rnn_units, return_sequences=True, \n",
    "#                       recurrent_initializer='glorot_uniform'))\n",
    "# model.add(layers.LSTM(units=rnn_units, return_sequences=False, \n",
    "#                       recurrent_initializer='glorot_uniform'))\n",
    "# # model.add(layers.GRU(units=rnn_units//8, return_sequences=False, stateful=True, recurrent_initializer='glorot_uniform'))\n",
    "# \n",
    "# model.add(layers.Dense(1)) # 이진 분류! 0 or 1"
   ],
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Embedding, Bidirectional, LSTM, Dense, Attention\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# 예제 데이터 생성\n",
    "\n",
    "\n",
    "# 입력 레이어\n",
    "inputs = Input(shape=(None,))\n",
    "# 임베딩 레이어\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_size)(inputs)\n",
    "# 양방향 LSTM 레이어\n",
    "lstm_layer = Bidirectional(LSTM(rnn_units, return_sequences=True))(embedding_layer)\n",
    "lstm_layer = Bidirectional(LSTM(rnn_units, return_sequences=True))(lstm_layer)\n",
    "lstm_layer = Bidirectional(LSTM(rnn_units, return_sequences=True))(lstm_layer)\n",
    "# Attention 레이어\n",
    "attention = Attention()([lstm_layer, lstm_layer])\n",
    "# 가중합 계산\n",
    "context = tf.reduce_sum(attention * lstm_layer, axis=1)\n",
    "# 출력 레이어\n",
    "output = Dense(1)(context)\n",
    "\n",
    "# 모델 생성\n",
    "model = Model(inputs=inputs, outputs=output)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.275350300Z",
     "start_time": "2024-01-06T14:23:54.265138700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size ))\n",
    "# model.add(Bidirectional(LSTM(units=rnn_units, return_sequences=True,\n",
    "#                              recurrent_initializer='glorot_uniform')))\n",
    "# model.add(Bidirectional(LSTM(units=rnn_units, return_sequences=True,\n",
    "#                              recurrent_initializer='glorot_uniform')))\n",
    "# model.add(Bidirectional(LSTM(units=rnn_units, return_sequences=False\n",
    "#                              ,\n",
    "#                              recurrent_initializer='glorot_uniform')))\n",
    "# \n",
    "# model.add(Dense(1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.290964200Z",
     "start_time": "2024-01-06T14:23:55.276352100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# model = tf.keras.Sequential()\n",
    "# model.add(layers.Embedding(input_dim=vocab_size, output_dim=embedding_size ))\n",
    "# model.add(LSTM(units=rnn_units, return_sequences=True,\n",
    "#                              recurrent_initializer='glorot_uniform'))\n",
    "# model.add(LSTM(units=rnn_units, return_sequences=True,\n",
    "#                              recurrent_initializer='glorot_uniform'))\n",
    "# model.add(LSTM(units=rnn_units, return_sequences=False\n",
    "#                              ,\n",
    "#                              recurrent_initializer='glorot_uniform'))\n",
    "# \n",
    "# model.add(Dense(1))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.312661200Z",
     "start_time": "2024-01-06T14:23:55.292012900Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-JC5OGALjC-8",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d8eebf8d-a568-47f7-91d9-64fe7bd34678",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.392547900Z",
     "start_time": "2024-01-06T14:23:55.308659400Z"
    }
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, None)]       0           []                               \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, None, 16)     160000      ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, None, 64)     12544       ['embedding[0][0]']              \n",
      "                                                                                                  \n",
      " bidirectional_1 (Bidirectional  (None, None, 64)    24832       ['bidirectional[0][0]']          \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " bidirectional_2 (Bidirectional  (None, None, 64)    24832       ['bidirectional_1[0][0]']        \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " attention (Attention)          (None, None, 64)     0           ['bidirectional_2[0][0]',        \n",
      "                                                                  'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLambda)  (None, None, 64)     0           ['attention[0][0]',              \n",
      "                                                                  'bidirectional_2[0][0]']        \n",
      "                                                                                                  \n",
      " tf.math.reduce_sum (TFOpLambda  (None, 64)          0           ['tf.math.multiply[0][0]']       \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 1)            65          ['tf.math.reduce_sum[0][0]']     \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 222,273\n",
      "Trainable params: 222,273\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DXObUdM6jC--"
   },
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Q-KOk-3ujC_A",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.394057Z",
     "start_time": "2024-01-06T14:23:55.342620400Z"
    }
   },
   "source": [
    "optimizer = tf.keras.optimizers.Adam(1e-4)\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cruLtRx2jC_C"
   },
   "source": [
    "## Train the model"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6qFJhZl6_NI5",
    "ExecuteTime": {
     "end_time": "2024-01-06T14:23:55.395067300Z",
     "start_time": "2024-01-06T14:23:55.355733600Z"
    }
   },
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=15,\n",
    "                                                     monitor='val_loss',\n",
    "                                                     restore_best_weights=True,\n",
    "                                                     verbose=1)\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # 관찰할 지표\n",
    "                              factor=0.2,  # 학습률을 줄이는 비율\n",
    "                              patience=4,  # 몇 번의 에포크 동안 감소하지 않아야 하는지\n",
    "                              min_lr=1e-9)"
   ],
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "waom7QxfjC_E",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "bd592f90-0ab6-4d6d-c605-0ed7a1499a8c",
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-06T14:23:55.371484200Z"
    }
   },
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    epochs=5,\n",
    "                    validation_data=valid_dataset,\n",
    "                    steps_per_epoch=len(train_labels) // batch_size ,\n",
    "                    validation_steps=len(val_labels) // batch_size ,\n",
    "                    callbacks=[cp_callback, early_stopping_cb, reduce_lr],\n",
    "                    )"
   ],
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      " 46/390 [==>...........................] - ETA: 1:24 - loss: 0.6938 - accuracy: 0.4942"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4VYoFVsVjC_G"
   },
   "source": [
    "## 모델 테스트\n",
    "* 테스트 데이터셋을 이용해 모델을 테스트해봅시다."
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1jiIGyqUvpY_",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0657ddb6-9326-41bb-8f7c-922597e57522",
    "is_executing": true
   },
   "source": [
    "model.load_weights(checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K-Z7Lg-TjC_G",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 504
    },
    "outputId": "7b8dfc92-9dbf-45cd-b54c-40cd84ef2f40",
    "is_executing": true
   },
   "source": [
    "results = model.evaluate(test_dataset)\n",
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.3f}\".format(results[1]))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "is_executing": true
   }
  }
 ]
}
