{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "accelerator": "GPU"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fXYH9ESLRRLY"
   },
   "source": [
    "# Image Classification\n",
    "\n",
    "tf.data.Dataset을 이용해 모델이 데이터를 효율적으로 활용할 수 있도록 구현해보는게 목적입니다.\n",
    "\n",
    "기본적인 머신러닝 작업과정은 아래와 같습니다.\n",
    "\n",
    "1. Examine and understand data\n",
    "2. Build an input pipeline\n",
    "3. Build the model\n",
    "4. Train the model\n",
    "5. Test the model\n",
    "6. Improve the model and repeat the process\n",
    "\n",
    "* 모델 완성 후 평가 지표에 따라서 모델을 평가해 봅시다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xjTHjdo6RS3n"
   },
   "source": [
    "## Project 설명\n",
    "### Task\n",
    "* CIFAR 10 데이터셋을 이용해 classification을 진행해보자.\n",
    "* [CIFAR 10 Dataset](https://www.cs.toronto.edu/~kriz/cifar.html)\n",
    "\n",
    "### Baseline\n",
    "* 오버피팅을 방지하기 위한 다양한 방법들을 사용해보자.\n",
    "    * 하이퍼파라미터 조절 (데이터 로드, 모델, Optimizer 등)\n",
    "    * 모델 구성 변경 (layer의 갯수)\n",
    "* Training\n",
    "    * tf.data.Dataset 과 model.fit()을 사용\n",
    "\n",
    "* Evaluation\n",
    "    * 모델의 정확도와 크기를 이용해 점수를 제공하는 메트릭으로 평가해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ew9Bg8w9j0PZ"
   },
   "source": [
    "### 구글 드라이브 마운트\n",
    "* Google의 Colab과 Drive를 이용해 노트북을 이용해 언제 어디서든 딥러닝 모델을 학습시켜보자."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "RRYFNY5jjzWF",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:22.621526Z",
     "start_time": "2023-12-27T06:33:22.608094Z"
    }
   },
   "source": [
    "# 코드 호환성을 위한 분기\n",
    "use_colab = True\n",
    "assert use_colab in [True, False]"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6vefMxCgj2U6"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P2qZQXTBcM6t"
   },
   "source": [
    "### 번외) GPU 서버를 어떻게 구성하면 좋을까?\n",
    "1. 로컬 머신 (노트북, 데스크탑) 구매\n",
    "    * GPU 노트북, 데스크탑, 서버 등 원하는 방법으로 다양하게 구비할 수 있다.\n",
    "    * Colab과 다르게 세션이 종료되지않으며, 비교적 자유롭게 사용할 수 있다.\n",
    "    * 원격 접속 및 오프라인 관리가 어려우며, 부수적인 유지보수 비용이 발생한다.\n",
    "\n",
    "2. 클라우드 등 서버 사용\n",
    "    * AWS, 네이버 클라우드 등\n",
    "    * 오프라인 관리가 필요없으며, 안정적이다.\n",
    "    * 비싸다..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Due8naADzEZc"
   },
   "source": [
    "### import packages"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "TlUX4NtWRL5b",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:31.201380Z",
     "start_time": "2023-12-27T06:33:26.010571Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Kjsldx-rzIfG"
   },
   "source": [
    "### load data\n",
    "* CIFAR 10 dataset을 로드한다. (npy)\n",
    "* 학습에 사용되는 대표적인 데이터셋들은 프레임워크내 코드로 제공된다.\n",
    "\n",
    "```\n",
    "tf.keras.dataset.cifar10\n",
    "tf.keras.dataset.cifar100\n",
    "tf.keras.dataset.mnist\n",
    "tf.keras.dataset.fashion_mnist\n",
    "tf.keras.dataset.imdb\n",
    "\n",
    "```\n",
    "\n",
    "* 다양한 데이터셋을 쉽게 가져와 사용할 수 있다.\n",
    "\n",
    "### 데이터셋 사용방법\n",
    "* Data split\n",
    "    * sklearn (머신러닝 프레임워크)를 이용해 데이터를 손쉽게 나눌 수 있다.\n",
    "\n",
    "```\n",
    "test_data_split, valid_data, test_labels_split, valid_labels = \\\n",
    "    train_test_split(test_data, test_labels, test_size=0.2, shuffle=True)\n",
    "```\n",
    "\n",
    "* test_size를 조절해 원하는 크기만큼의 데이터를 분리해 사용할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "C5QyC6CZMgLT",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:31.510060Z",
     "start_time": "2023-12-27T06:33:31.195629Z"
    }
   },
   "source": [
    "# Load training and eval data from tf.keras\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.cifar10.load_data()"
   ],
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "_bshB8j2Qu3Z",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:31.513208Z",
     "start_time": "2023-12-27T06:33:31.508151Z"
    }
   },
   "source": [
    "# !cd /root/.keras/datasets/ && ls -al"
   ],
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "fKduNOW08ugw",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:31.526353Z",
     "start_time": "2023-12-27T06:33:31.515030Z"
    }
   },
   "source": [
    "print(train_data.shape, train_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)\n",
    "print(test_labels[0]) # 데이터셋 제작할때, [3] => 3 으로 데이터 형태를 변경해줘야합니다."
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 32, 32, 3) (50000, 1)\n",
      "(10000, 32, 32, 3) (10000, 1)\n",
      "[3]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "INZN9eNPRL5h",
    "ExecuteTime": {
     "end_time": "2023-12-27T06:33:32.138194Z",
     "start_time": "2023-12-27T06:33:32.113265Z"
    }
   },
   "source": [
    "test_data, valid_data, test_labels, valid_labels = \\\n",
    "    train_test_split(test_data, test_labels, test_size=###, shuffle=True) # 0~1의 값으로 줍니다.\n",
    "                     # test_size => 0.1 = 10%\n",
    "                     # test_size => 0.2 = 20%\n",
    "\n",
    "# raw data normalization\n",
    "# RGB 값이 0~255 사이 값인 것을 이용해 Normalization 진행\n",
    "train_data = train_data / 255.\n",
    "train_data = train_data.reshape([-1,32,32,3])\n",
    "train_labels = train_labels.reshape([-1])\n",
    "\n",
    "valid_data = valid_data / 255.\n",
    "valid_data = valid_data.reshape([#TODO])\n",
    "valid_labels = valid_labels.reshape([-1])\n",
    "\n",
    "test_data = test_data / 255.\n",
    "test_data = test_data.reshape([#TODO])\n",
    "test_labels = test_labels.reshape([-1])\n"
   ],
   "execution_count": 6,
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (397921898.py, line 8)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;36m  Cell \u001B[0;32mIn[6], line 8\u001B[0;36m\u001B[0m\n\u001B[0;31m    train_data = train_data / 255.\u001B[0m\n\u001B[0m               ^\u001B[0m\n\u001B[0;31mSyntaxError\u001B[0m\u001B[0;31m:\u001B[0m invalid syntax\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Nd8fwv5AeaFy"
   },
   "source": [
    "# [데이터수, 32, 32, 3] [데이터수,]\n",
    "print(train_data.shape, train_labels.shape)\n",
    "print(valid_data.shape, valid_labels.shape)\n",
    "print(test_data.shape, test_labels.shape)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J_5B8vqPzNYY"
   },
   "source": [
    "### dataset 구성\n",
    "* tf.data.Dataset을 이용해 데이터셋을 구성한다.\n",
    "    * 위에서 불러온 raw data (cifar10) 데이터셋을 모델이 학습 할 수 있도록 전달해 주는 데이터셋이다.\n",
    "* tf data Dataset을 사용해야하는 이유?\n",
    "    * 직접 Generator를 작성할 필요가 없다\n",
    "    * map 함수를 이용해 전처리 과정을 직접 조절할 수 있다.\n",
    "    * 메모리에 부담이 되지 않게 동작한다.\n",
    "\n",
    "\n",
    "### 직접 적용해보자\n",
    "* map 함수를 적용할 함수 구현 후 dataset을 구현하며 사용해보자"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "KB2O5Gf8RL5n"
   },
   "source": [
    "def one_hot_label(image, label): # label => one_hot\n",
    "  label = tf.one_hot(label, depth=10)\n",
    "  return image, label"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RQuarDIdj0nn"
   },
   "source": [
    "* 위 one_hot_label 함수는 아래와 같이 동작한다.\n",
    "# one_hot vector 예시\n",
    "\n",
    "```Python\n",
    "tf.one_hot(\n",
    "    indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None\n",
    ")\n",
    "\n",
    "indices = [0, 1, 2]\n",
    "depth = 3\n",
    "tf.one_hot(indices, depth)  # output: [3 x 3]\n",
    "# [[1., 0., 0.],\n",
    "#  [0., 1., 0.],\n",
    "#  [0., 0., 1.]]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sl0pvav6kJMT"
   },
   "source": [
    "### map 함수를 포함한 dataset 구성\n",
    "* Dataset을 딥러닝 데이터를 쉽게 불러오기 위한 일종의 Generator 입니다.\n",
    "* 학습에 사용할 데이터셋은 총 3개\n",
    "    * Train dataset, Valid dataset, Test dataset 입니다.\n",
    "        * Raw data에서 분리한 데이터들\n",
    "    * 데이터셋은 tf.data.Dataset으로 구성되며, 구현 파트에선 데이터를 불러오는 형식만을 지정해준다.\n",
    "        * shuffle, batch 옵션을 이용해 다양하게 데이터를 로드해올 수 있다.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4YFNeX5zokDu"
   },
   "source": [
    "batch_size = ###"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5smuqDGFRL5s"
   },
   "source": [
    "# for train\n",
    "N = len(train_data)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((###, ###))\n",
    "train_dataset = train_dataset.map(#TODO) # 함수의 이름을 써서 구현\n",
    "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=###)\n",
    "print(train_dataset)\n",
    "\n",
    "# # for valid\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((#TODO, #TODO))\n",
    "valid_dataset = valid_dataset.map(#TODO)\n",
    "valid_dataset = valid_dataset.batch(batch_size=batch_size)\n",
    "print(valid_dataset)\n",
    "\n",
    "# # for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((#TODO, #TODO))\n",
    "test_dataset = test_dataset.map(#TODO)\n",
    "test_dataset = test_dataset.batch(batch_size=#TODO)\n",
    "print(test_dataset)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8s_YijINvd7I"
   },
   "source": [
    "\n",
    "* 데이터 타입의 경우 Tensorflow 버전에 따라 tf.float32 or tf.float64로 출력될 수 있으나 학습에 큰 영향을 주진 않는다.\n",
    "* 해당 자료형은 tf.cast를 이용해 따로 타입을 지정해줄 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sak_LGn0jVSz"
   },
   "source": [
    "### Save point 설정\n",
    "* Model weight를 저장할 폴더를 지정한다.\n",
    "* 폴더가 없다면 새로 생성해준다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "aoGnJiFQn-9a"
   },
   "source": [
    "# the save point\n",
    "if use_colab:\n",
    "    checkpoint_dir ='./drive/My Drive/train_ckpt/cifar10_classification/exp1'\n",
    "else:\n",
    "    checkpoint_dir = 'cifar10_classification/exp1'\n",
    "\n",
    "if not os.path.isdir(checkpoint_dir):\n",
    "    os.makedirs(checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "28Zgtrndp8ag"
   },
   "source": [
    "### Model Savepoints\n",
    "* 모델 저장시 모델의 파라미터를 저장한다.\n",
    "    * 위에 구현된 모델의 shape을 기준으로 파라미터만 저장\n",
    "* 저장된 데이터는 checkpoint 형태로 저장되며, load data를 이용해 불러올 수 있다.\n",
    "    * 저장된 모델 데이터를 불러올 시에는 저장된 모델과 같은 shape인 모델이 메모리 상에 있어야 한다.\n",
    "\n",
    "```\n",
    "model = model() # 구현했던 모델\n",
    "model.load_weights(checkpoint_dir)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E9zJFca-nq4v"
   },
   "source": [
    "### 데이터 확인\n",
    "* 학습에 사용할 데이터를 확인해보자."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s8zViOfERL5v"
   },
   "source": [
    "index = 219 # index를 변경해 확인해보자 (0~49999)\n",
    "print(\"label = {}\".format(train_labels[index]))\n",
    "plt.imshow(train_data[index].reshape(32, 32, 3))\n",
    "plt.colorbar()\n",
    "#plt.gca().grid(False)\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3ci_kGCiiVYN"
   },
   "source": [
    "### 모델 구성\n",
    "* 직접 모델을 구현해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zc-5rcdFAmDP"
   },
   "source": [
    "# 1번 방법\n",
    "model = Sequential()\n",
    "model.add() # (32#필터갯수, 3#필터사이즈)\n",
    "\n",
    "# 2번 방법\n",
    "model = Sequential([\n",
    "                    #layer,\n",
    "                    #layer,\n",
    "])\n",
    "\n",
    "# 모델의 output\n",
    "# 1번 구현 방법\n",
    "... # loss fn => from_logits 는 마지막 레이어의 activation과 관련\n",
    "#model.add(layers.Dense(10, activation='softmax')) # from_logits=False\n",
    "\n",
    "# 2번 구현 방법\n",
    "#model.add(layers.Dense(10)) # activation을 거치지않은 데이터를 logits\n",
    "# from_logits=True => 마지막 레이어에 activation이 없다."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# F API\n",
    "input_tensor = layers.Input(shape=(32 * 32 * 8,)) # 1개 데이터의 특성\n",
    "\n",
    "# hidden layer 구성\n",
    "x1 = layers.Dense(128, activation='relu')(input_tensor)\n",
    "\n",
    "x2 = layers.Dense(64, activation='relu')(x1)\n",
    "\n",
    "x3 = layers.Dense(32, activation='relu')(x2)\n",
    "\n",
    "output_tensor = layers.Dense(10)(x3)\n",
    "\n",
    "# 최종 모델 완성\n",
    "model = tf.keras.Model(input_tensor, output_tensor)"
   ],
   "metadata": {
    "id": "7UJxwGG2uTe9"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eA76LqFwpH-X"
   },
   "source": [
    "* 모델이 잘 생성 되었는지 간단하게 테스트해 봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "g8BnMTZyRL53"
   },
   "source": [
    "# without training, just inference a model in eager execution:\n",
    "predictions = model(train_data[0:1], training=False)\n",
    "print(\"Predictions: \", predictions.numpy()) # 총 10개의 데이터가 나오면 모델이 잘 구성된겁니다."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nct8JiQxpLsX"
   },
   "source": [
    "* 위 Predictions 결과가 총 10개 짜리 리스트로 출력 된다면, 현재 테스크에서 정상적인 출력입니다.\n",
    "    * cifar10 dataset은 정답이 총 10개로 이뤄져 있습니다.\n",
    "    * 출력값은 마지막 output layer에 activation의 유무에 따라서 값이 달라지며, activation을 통과하기전 데이터를 logit이라고 이야기합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vJRZU65fl2xz"
   },
   "source": [
    "### Model compile\n",
    "* 학습을 위한 Optimizer와 Loss fn을 설정해준다.\n",
    "    * Optimzier는 learning rate를 인자로 가지며, 모델의 학습정도를 컨트롤합니다.\n",
    "    * Loss fn은 모델의 예측결과와 실제 정답간의 차이를 loss로 계산해 모델을 학습합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "P3I0O8MaRL57"
   },
   "source": [
    "model.compile(optimizer=#TODO, # learning rate가 기본값으로 1e-3으로 들어가있습니다.\n",
    "              loss=#TODO,\n",
    "              metrics=['accuracy'])"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "3KF1BT7aRL5-"
   },
   "source": [
    "model.summary()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OKIiPxAgoItQ"
   },
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir, # save point dir\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "B3sOL3HCRL6A"
   },
   "source": [
    "max_epochs = #TODO\n",
    "\n",
    "# using `tf.data.Dataset`\n",
    "history = model.fit(#TODO - train_dataset,\n",
    "                    steps_per_epoch=#TODO, # train data의 길이 // batch 길이\n",
    "                    epochs=#TODO,\n",
    "                    validation_data=#TODO,\n",
    "                    validation_steps=#TODO,\n",
    "                    callbacks=[cp_callback]\n",
    "                    )"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fjLV8zaxgc4V"
   },
   "source": [
    "### 학습 결과를 정리해봅시다.\n",
    "* Model 학습을 진행하며 저장된 결과를 전달 받은 history 객체를 이용해 학습 과정을 출력해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kH93caN_RL6E"
   },
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(len(acc))\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Valid Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Valid Loss')\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R5B3sWG8UIz3"
   },
   "source": [
    "### 모델 평가\n",
    "* Model 학습 후 저장된 weight를 다시 불러와 테스트를 진행합니다.\n",
    "    * 학습이 진행되며, 가장 낮은 val-loss를 이용해 모델을 저장했기 때문에 가장 작은 val-loss를 가지는 곳의 파라미터가 저장되어 있습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VC8Sjhk9lSMF"
   },
   "source": [
    "model.load_weights(checkpoint_dir)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zb3Lm60fwWgf"
   },
   "source": [
    "* 모델 파라미터를 불러온 후 테스트 데이터셋을 이용해 평가를 진행합니다.\n",
    "* 가장 기본적인 Accuracy를 제공합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ByXBzpzzRL6K"
   },
   "source": [
    "results = model.evaluate(test_dataset, steps=len(test_data) // batch_size)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "8cfSwvB5RL6O"
   },
   "source": [
    "# loss\n",
    "print(\"loss value: {:.3f}\".format(results[0]))\n",
    "# accuracy\n",
    "print(\"accuracy value: {:.4f}%\".format(results[1]*100))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YJnX3YfnRL6T"
   },
   "source": [
    "test_batch_size = 16\n",
    "batch_index = np.random.choice(len(test_data), size=test_batch_size, replace=False)\n",
    "\n",
    "batch_xs = test_data[batch_index]\n",
    "batch_ys = test_labels[batch_index]\n",
    "y_pred_ = model(batch_xs, training=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 10))\n",
    "for i, (px, py) in enumerate(zip(batch_xs, y_pred_)):\n",
    "  p = fig.add_subplot(4, 8, i+1)\n",
    "  if np.argmax(py) == batch_ys[i]:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='blue')\n",
    "  else:\n",
    "    p.set_title(\"y_pred: {}\".format(np.argmax(py)), color='red')\n",
    "  p.imshow(px.reshape(32, 32, 3))\n",
    "  p.axis('off')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5q6NOnoZYIrR"
   },
   "source": [
    "### 평가 메트릭을 설정해보자\n",
    "* 인공지능 모델을 이용해 문제를 해결할 시에 해당 분야에서 고유하게 사용하던 평가 메트릭 혹은 새로운 메트릭이 사용되기도 합니다.\n",
    "* Classification에서 사용되었던 평가 지표를 사용해봅시다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NJE2--mMZO-7"
   },
   "source": [
    "## Measuring final score\n",
    "* 모델 평가 지표\n",
    "\n",
    "### \\begin{equation*} M = 50(P + min(\\frac{1}{S}, 1)) \\end{equation*}\n",
    "\n",
    "* P : Model-accuracy\n",
    "* S : Size of model (MB)\n",
    "\n",
    "\n",
    "### \\begin{equation*} S = \\frac{Parameters * float_{size}}{MB} \\end{equation*}\n",
    "\\begin{equation*} = \\frac{M_p * 32} {1024^2} \\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "* 해당 지표는 분류 평가를 위한 내용이며, 모델의 크기에 따른 정확도를 나타내는 지표입니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "4R945JcpRL6Y"
   },
   "source": [
    "def final_score():\n",
    "    print(\"Model params num : \" + str(model.count_params()))\n",
    "    print(\"Accuracy : \" + str(results[1]))\n",
    "\n",
    "    s = (model.count_params() * 32) / (1024 ** 2)\n",
    "    score = 50 * (results[1] + min((1/s), 1))\n",
    "\n",
    "    print(\"score : \" + str(score))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LbuQllIxv2ww"
   },
   "source": [
    "### 스코어 결과\n",
    "* 위의 스코어는 분류모델에 적용되는 스코어입니다.\n",
    "* 모델의 크기 (MB) 와 정확도를 이용해 스코어를 출력합니다.\n",
    "    * 40 이상의 스코어에 도전해보세요!"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "NWs2D_Y5RL6a"
   },
   "source": [
    "final_score()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "56iBGUMV2B-y"
   },
   "source": [
    "### 추가 과제\n",
    "* 높은 스코어를 달성하신 분들께선 더 맞추기 어려운 데이터셋으로 도전해보세요.\n",
    "\n",
    "```\n",
    "(train_data, train_labels), (test_data, test_labels) = \\\n",
    "    tf.keras.datasets.cifar100.load_data()\n",
    "```\n",
    "\n",
    "* 데이터 로드 파트에서 위 코드를 고치면 더 세분화된 분류를 진행하는 데이터셋을 사용할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "56c1gImLgAVk"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
