{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b84edb4e",
      "metadata": {
        "id": "b84edb4e"
      },
      "source": [
        "## Use case\n",
        "\n",
        "Raw LLM 생성에서 구조화된 출력을 얻는 것은 어렵습니다.\n",
        "\n",
        "예를 들어, 특정 스키마로 포맷된 모델 출력이 필요하다고 가정해 보겠습니다:\n",
        "\n",
        "- 데이터베이스에 삽입할 구조화된 행을 추출하는 경우\n",
        "- API 매개변수 추출\n",
        "- 사용자 쿼리의 다른 부분 추출(예: 시맨틱 검색과 키워드 검색)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97f474d4",
      "metadata": {
        "id": "97f474d4"
      },
      "source": [
        "## Overview\n",
        "\n",
        "이를 위한 두 가지 주요 접근 방식이 있습니다:\n",
        "\n",
        "- `Functions`: 일부 LLM은 functions를 호출하여 LLM 응답에서 임의의 엔티티를 추출할 수 있습니다.\n",
        "\n",
        "- `Parsing`: 출력 구문 분석기는 LLM 응답을 구조화하는 클래스입니다.\n",
        "\n",
        "일부 LLM만 함수(예: OpenAI)를 지원하며, 파서보다 더 일반적입니다.\n",
        "\n",
        "구문 분석기는 제공된 스키마에 열거된 내용(예: 사람의 특정 속성)을 정확하게 추출합니다.\n",
        "\n",
        "함수는 제공된 스키마 이외의 것(예: 사용자가 요청하지 않은 사람에 대한 속성)을 추론할 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "25d89f21",
      "metadata": {
        "id": "25d89f21"
      },
      "source": [
        "## Quickstart\n",
        "\n",
        "OpenAI 함수는 추출을 시작하는 한 가지 방법입니다.\n",
        "\n",
        "LLM 출력에서 추출할 속성을 지정하는 스키마를 정의합니다.\n",
        "\n",
        "그런 다음 `create_extraction_chain`을 사용하여 OpenAI 함수 호출을 통해 원하는 스키마를 추출할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3f5ec7a3",
      "metadata": {
        "id": "3f5ec7a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e08a169e-37dc-460f-98e0-5e3ff8831c57"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.3-py3-none-any.whl (803 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m803.6/803.6 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting openai\n",
            "  Downloading openai-1.9.0-py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.4/223.4 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
            "  Downloading langchain_community-0.0.15-py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2,>=0.1.14 (from langchain)\n",
            "  Downloading langchain_core-0.1.15-py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.6/229.6 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
            "  Downloading langsmith-0.0.83-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.3/49.3 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.9/75.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Collecting typing-extensions<5,>=4.7 (from openai)\n",
            "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.14->langchain) (23.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.5.0\n",
            "    Uninstalling typing_extensions-4.5.0:\n",
            "      Successfully uninstalled typing_extensions-4.5.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
            "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.3 langchain-community-0.0.15 langchain-core-0.1.15 langsmith-0.0.83 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.9.0 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass() #\"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\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l8mU8PR67jPR",
        "outputId": "32789feb-5392-4bb4-ed1d-e6ec8deaa534"
      },
      "id": "l8mU8PR67jPR",
      "execution_count": 5,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "3e017ba0",
      "metadata": {
        "id": "3e017ba0",
        "outputId": "9eb673e3-aed1-4fe3-c2e4-b25627b1109c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n",
              " {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ],
      "source": [
        "from langchain.chains import create_extraction_chain\n",
        "from langchain.chat_models import ChatOpenAI\n",
        "\n",
        "# Schema\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"height\": {\"type\": \"integer\"},\n",
        "        \"hair_color\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"name\", \"height\"],\n",
        "}\n",
        "\n",
        "# Input\n",
        "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
        "\n",
        "# Run chain\n",
        "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "chain.run(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6f7eb826",
      "metadata": {
        "id": "6f7eb826"
      },
      "source": [
        "## Option 1: OpenAI functions\n",
        "\n",
        "### Looking under the hood\n",
        "\n",
        "`create_extraction_chain` 호출할 때 어떤 일이 일어나는지 자세히 살펴봅시다.\n",
        "\n",
        "이 `정보_추출` 함수는 [여기](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/openai_functions/extraction.py)에 정의되어 있으며 딕셔너리를 반환합니다.\n",
        "\n",
        "\n",
        "모델 출력에서 `dict`를 볼 수 있습니다:\n",
        "```\n",
        " {\n",
        "      \"info\": [\n",
        "        {\n",
        "          \"name\": \"Alex\",\n",
        "          \"height\": 5,\n",
        "          \"hair_color\": \"blonde\"\n",
        "        },\n",
        "        {\n",
        "          \"name\": \"Claudia\",\n",
        "          \"height\": 6,\n",
        "          \"hair_color\": \"brunette\"\n",
        "        }\n",
        "      ]\n",
        "    }\n",
        "```\n",
        "\n",
        "그런 다음 `create_extraction_chain`은 [`JsonKeyOutputFunctionsParser`](https://github.com/langchain-ai/langchain/blob/f81e613086d211327b67b0fb591fd4d5f9a85860/libs/langchain/langchain/chains/openai_functions/extraction.py#L62)를 사용하여 원시 LLM 출력을 파싱합니다.\n",
        "\n",
        "그 결과 위의 체인에서 반환된 JSON 객체 목록이 생성됩니다:\n",
        "```\n",
        "[{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n",
        " {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]\n",
        " ```"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dcb03138",
      "metadata": {
        "id": "dcb03138"
      },
      "source": [
        "### Multiple entity types\n",
        "\n",
        "이를 더 확장할 수 있습니다.\n",
        "\n",
        "개와 사람을 구분하고 싶다고 가정해 봅시다.\n",
        "\n",
        "각 속성에 `person_` 및 `dog_` 접두사를 추가하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "01eae733",
      "metadata": {
        "id": "01eae733",
        "outputId": "1d6f2c98-d56f-49a5-f13e-78fd3dad49dc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'person_name': 'Alex',\n",
              "  'person_height': 5,\n",
              "  'person_hair_color': 'blonde',\n",
              "  'dog_name': 'Frosty',\n",
              "  'dog_breed': 'labrador'},\n",
              " {'person_name': 'Claudia',\n",
              "  'person_height': 6,\n",
              "  'person_hair_color': 'brunette'}]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [\"person_name\", \"person_height\"],\n",
        "}\n",
        "\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Alex's dog Frosty is a labrador and likes to play hide and seek.\"\"\"\n",
        "\n",
        "chain.run(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f205905c",
      "metadata": {
        "id": "f205905c"
      },
      "source": [
        "### Unrelated entities\n",
        "\n",
        "`필수: []`를 사용하면 모델이 단일 엔티티(사람 또는 개)에 대해 **사람 속성만** 또는  **개 속성만**을 반환하도록 허용합니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6ff4ac7e",
      "metadata": {
        "id": "6ff4ac7e",
        "outputId": "8a78b286-673d-4aee-aa09-8dc119261671",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde'},\n",
              " {'person_name': 'Claudia',\n",
              "  'person_height': 6,\n",
              "  'person_hair_color': 'brunette'},\n",
              " {'dog_name': 'Willow', 'dog_breed': 'German Shepherd'},\n",
              " {'dog_name': 'Milo', 'dog_breed': 'Border Collie'}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "    },\n",
        "    \"required\": [],\n",
        "}\n",
        "\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
        "Willow is a German Shepherd that likes to play with other dogs and can always be found playing with Milo, a border collie that lives close by.\"\"\"\n",
        "\n",
        "chain.run(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34f3b958",
      "metadata": {
        "id": "34f3b958"
      },
      "source": [
        "### Extra information\n",
        "\n",
        "The power of functions (파서만 사용할 때와 비교했을 때) 의미 추출을 수행할 수 있는 능력에 있습니다.\n",
        "\n",
        "특히 '스키마에 명시적으로 열거되지 않은 것을 요청할 수 있다'는 점입니다.\n",
        "\n",
        "개에 대한 지정되지 않은 추가 정보를 원한다고 가정해 봅시다.\n",
        "\n",
        "비정형 추출을 위한 자리 표시자인 `dog_extra_info`를 추가할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "40c7b26f",
      "metadata": {
        "id": "40c7b26f",
        "outputId": "8fdc7ef7-9fe9-4d0d-901e-4bb499ac50c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde'},\n",
              " {'person_name': 'Claudia',\n",
              "  'person_height': 6,\n",
              "  'person_hair_color': 'brunette'},\n",
              " {'dog_name': 'Willow',\n",
              "  'dog_breed': 'German Shepherd',\n",
              "  'dog_extra_info': 'likes to play with other dogs'},\n",
              " {'dog_name': 'Milo',\n",
              "  'dog_breed': 'border collie',\n",
              "  'dog_extra_info': 'lives close by'}]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"person_name\": {\"type\": \"string\"},\n",
        "        \"person_height\": {\"type\": \"integer\"},\n",
        "        \"person_hair_color\": {\"type\": \"string\"},\n",
        "        \"dog_name\": {\"type\": \"string\"},\n",
        "        \"dog_breed\": {\"type\": \"string\"},\n",
        "        \"dog_extra_info\": {\"type\": \"string\"},\n",
        "    },\n",
        "}\n",
        "\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "chain.run(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a949c60",
      "metadata": {
        "id": "3a949c60"
      },
      "source": [
        "이를 통해 개에 대한 추가 정보를 얻을 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf71ddce",
      "metadata": {
        "id": "bf71ddce"
      },
      "source": [
        "### Pydantic\n",
        "\n",
        "Pydantic은 Python용 데이터 유효성 검사 및 설정 관리 라이브러리입니다.\n",
        "\n",
        "이 라이브러리를 사용하면 객체를 인스턴스화할 때 자동으로 유효성이 검사되는 속성을 가진 데이터 클래스를 만들 수 있습니다.\n",
        "\n",
        "유형으로 주석이 달린 속성을 가진 클래스를 정의할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "d36a743b",
      "metadata": {
        "id": "d36a743b",
        "outputId": "34fc4da7-b7b7-4d58-c90a-ada043e7318b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Properties(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None),\n",
              " Properties(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ],
      "source": [
        "from typing import Optional\n",
        "\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "\n",
        "\n",
        "# Pydantic data class\n",
        "class Properties(BaseModel):\n",
        "    person_name: str\n",
        "    person_height: int\n",
        "    person_hair_color: str\n",
        "    dog_breed: Optional[str]\n",
        "    dog_name: Optional[str]\n",
        "\n",
        "\n",
        "# Extraction\n",
        "chain = create_extraction_chain_pydantic(pydantic_schema=Properties, llm=llm)\n",
        "\n",
        "# Run\n",
        "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
        "chain.run(inp)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07a0351a",
      "metadata": {
        "id": "07a0351a"
      },
      "source": [
        "trace에서 볼 수 있듯이, 위와 같이 Pydantic 스키마와 함께 `information_extraction` 함수를 사용합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbd9f121",
      "metadata": {
        "id": "cbd9f121"
      },
      "source": [
        "## 옵션 2: 파싱\n",
        "\n",
        "출력 구문 분석기는 언어 모델 응답을 구조화하는 데 도움이 되는 클래스입니다.\n",
        "\n",
        "위에 표시된 것처럼 `create_extraction_chain`에서 OpenAI 함수 호출의 출력을 구문 분석하는 데 사용됩니다.\n",
        "\n",
        "하지만 함수와 독립적으로 사용할 수도 있습니다.\n",
        "\n",
        "### Pydantic\n",
        "\n",
        "위와 마찬가지로 Pydantic 데이터 클래스를 기반으로 한 세대를 파싱해 보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "64650362",
      "metadata": {
        "id": "64650362",
        "outputId": "931a08bb-0698-4288-8921-901b120cf652",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text='Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"description\": \"Identifying information about all people in a text.\", \"properties\": {\"people\": {\"title\": \"People\", \"type\": \"array\", \"items\": {\"$ref\": \"#/definitions/Person\"}}}, \"required\": [\"people\"], \"definitions\": {\"Person\": {\"title\": \"Person\", \"type\": \"object\", \"properties\": {\"person_name\": {\"title\": \"Person Name\", \"type\": \"string\"}, \"person_height\": {\"title\": \"Person Height\", \"type\": \"integer\"}, \"person_hair_color\": {\"title\": \"Person Hair Color\", \"type\": \"string\"}, \"dog_breed\": {\"title\": \"Dog Breed\", \"type\": \"string\"}, \"dog_name\": {\"title\": \"Dog Name\", \"type\": \"string\"}}, \"required\": [\"person_name\", \"person_height\", \"person_hair_color\"]}}}\\n```\\nAlex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "People(people=[Person(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None), Person(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "from typing import Optional, Sequence\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        ")\n",
        "from pydantic import BaseModel, Field, validator\n",
        "\n",
        "\n",
        "class Person(BaseModel):\n",
        "    person_name: str\n",
        "    person_height: int\n",
        "    person_hair_color: str\n",
        "    dog_breed: Optional[str]\n",
        "    dog_name: Optional[str]\n",
        "\n",
        "\n",
        "class People(BaseModel):\n",
        "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
        "\n",
        "    people: Sequence[Person]\n",
        "\n",
        "\n",
        "# Run\n",
        "query = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=People)\n",
        "# print(parser.get_format_instructions())\n",
        "\n",
        "# Prompt\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# Run\n",
        "_input = prompt.format_prompt(query=query)\n",
        "print(_input)\n",
        "model = OpenAI(temperature=0)\n",
        "output = model(_input.to_string())\n",
        "parser.parse(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "826899df",
      "metadata": {
        "id": "826899df"
      },
      "source": [
        "LLM이 원하는 형식으로 출력하도록하기 위해 투샷 프롬프트를 제공합니다.\n",
        "\n",
        "그리고 조금 더 작업해야 합니다:\n",
        "\n",
        "* `Person`의 여러 인스턴스를 보유하는 클래스를 정의합니다.\n",
        "* LLM의 출력을 Pydantic 클래스로 명시적으로 파싱합니다.\n",
        "\n",
        "다른 경우에도 이와 같은 결과를 볼 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "837c350e",
      "metadata": {
        "id": "837c350e",
        "outputId": "a321fdb9-163d-4953-daa5-313b2451ad3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The output should be formatted as a JSON instance that conforms to the JSON schema below.\n",
            "\n",
            "As an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\n",
            "the object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\n",
            "\n",
            "Here is the output schema:\n",
            "```\n",
            "{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\n",
            "```\n",
            "text='Answer the user query.\\nThe output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"setup\": {\"title\": \"Setup\", \"description\": \"question to set up a joke\", \"type\": \"string\"}, \"punchline\": {\"title\": \"Punchline\", \"description\": \"answer to resolve the joke\", \"type\": \"string\"}}, \"required\": [\"setup\", \"punchline\"]}\\n```\\nTell me a joke.\\n'\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Joke(setup='Why did the tomato turn red?', punchline='Because it saw the salad dressing!')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        ")\n",
        "from pydantic import BaseModel, Field, validator\n",
        "\n",
        "\n",
        "# Define your desired data structure.\n",
        "class Joke(BaseModel):\n",
        "    setup: str = Field(description=\"question to set up a joke\")\n",
        "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
        "\n",
        "    # You can add custom validation logic easily with Pydantic.\n",
        "    @validator(\"setup\")\n",
        "    def question_ends_with_question_mark(cls, field):\n",
        "        if field[-1] != \"?\":\n",
        "            raise ValueError(\"Badly formed question!\")\n",
        "        return field\n",
        "\n",
        "\n",
        "# And a query intended to prompt a language model to populate the data structure.\n",
        "joke_query = \"Tell me a joke.\"\n",
        "\n",
        "# Set up a parser + inject instructions into the prompt template.\n",
        "parser = PydanticOutputParser(pydantic_object=Joke)\n",
        "print(parser.get_format_instructions())\n",
        "\n",
        "# Prompt\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
        ")\n",
        "\n",
        "# Run\n",
        "_input = prompt.format_prompt(query=joke_query)\n",
        "print(_input)\n",
        "model = OpenAI(temperature=0)\n",
        "output = model(_input.to_string())\n",
        "parser.parse(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3601bde",
      "metadata": {
        "id": "d3601bde"
      },
      "source": [
        "보시다시피, 우리가 원래 원했던 스키마를 따르는 `Joke` 클래스의 출력을 얻습니다: `setup`, `punchline`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 연습문제\n",
        "\n",
        "### 1. 기본 추출 연습\n",
        "* 주어진 텍스트에서 언급된 사람들의 이름과 나이를 추출하는 파이썬 스크립트를 작성합니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "1. 스키마 정의: 사람의 이름과 나이를 추출하기 위한 스키마를 정의합니다. 이 스키마는 이름을 문자열로, 나이를 정수로 갖는 구조를 가집니다.\n",
        "\n",
        "2. 텍스트 입력: 추출할 정보를 포함하는 샘플 텍스트를 준비합니다.\n",
        "\n",
        "3. 추출 체인 생성: langchain 라이브러리를 사용하여 추출 체인을 생성합니다. 이 체인은 입력된 텍스트에서 이름과 나이 정보를 추출합니다.\n",
        "\n",
        "4. 추출 실행 및 결과 확인: 생성된 체인을 실행하여 텍스트에서 정보를 추출하고, 결과를 확인합니다.\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "_gPL4ONYFgmK"
      },
      "id": "_gPL4ONYFgmK"
    },
    {
      "cell_type": "code",
      "source": [
        "# 스키마 정의\n",
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"name\": {\"type\": \"string\"},\n",
        "        \"age\": {\"type\": \"integer\"},\n",
        "    },\n",
        "    \"required\": [\"name\", \"age\"]\n",
        "}\n",
        "\n",
        "# 텍스트 입력\n",
        "input_text = \"John is 30 years old. Mary is two years younger than John.\"\n",
        "\n",
        "# 추출 체인 생성\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "# 추출 실행\n",
        "result = chain.run(input_text)\n",
        "\n",
        "# 결과 출력\n",
        "print(result)"
      ],
      "metadata": {
        "id": "XUjshGcN-q1q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d4f16b5-bb5a-4839-8795-184a5af03ad7"
      },
      "id": "XUjshGcN-q1q",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'John', 'age': 30}, {'name': 'Mary', 'age': 28}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional\n",
        "\n",
        "from langchain.chains import create_extraction_chain_pydantic\n",
        "from langchain.pydantic_v1 import BaseModel\n",
        "class Properties(BaseModel):\n",
        "    name :str\n",
        "    age :int\n",
        "\n",
        "# 텍스트 입력\n",
        "input_text = \"John is 30 years old. Mary is two years younger than John.\"\n",
        "\n",
        "# 추출 체인 생성\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain_pydantic(pydantic_schema= Properties, llm=llm)\n",
        "\n",
        "# 추출 실행\n",
        "result = chain.run(input_text)\n",
        "\n",
        "# 결과 출력\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2N_asPJjL6Xi",
        "outputId": "b0d233b2-0124-4c3b-dfe3-6cafbca5f14b"
      },
      "id": "2N_asPJjL6Xi",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Properties(name='John', age=30), Properties(name='Mary', age=28)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. 복잡한 쿼리 처리\n",
        "* 서술 문단에서 이벤트에 대한 자세한 정보(예: 이벤트 이름, 날짜, 위치, 참가자)를 추출하는 스크립트를 작성합니다.\n",
        "\n",
        "\n",
        "```\n",
        "1. 이벤트 정보 스키마 정의: 이벤트 이름, 날짜, 위치, 참가자 등의 정보를 포함하는 스키마를 정의합니다.\n",
        "\n",
        "2. 텍스트 입력: 추출할 정보를 포함하는 복잡한 서술 문단을 준비합니다\n",
        "\n",
        "3. 추출 체인 생성 및 실행: langchain 라이브러리를 사용하여 추출 체인을 생성하고, 준비된 텍스트에서 정보를 추출합니다.\n",
        "\n",
        "4. 결과 확인 및 분석: 추출된 결과를 확인하고, 스크립트가 복잡한 쿼리를 어떻게 처리하는지 분석합니다.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "dKYyaq_SGmn5"
      },
      "id": "dKYyaq_SGmn5"
    },
    {
      "cell_type": "code",
      "source": [
        "schema = {\n",
        "    \"properties\": {\n",
        "        \"event_name\": {\"type\": \"string\"},\n",
        "        \"date\": {\"type\": \"string\"}, # 날짜검증이 필요할 수도\n",
        "        \"location\": {\"type\": \"string\"},\n",
        "        \"participants\": {\"type\": \"array\", \"items\":{\"type\": \"string\"}},\n",
        "    },\n",
        "    \"required\": ['event_name','date','location']\n",
        "}\n",
        "\n",
        "# 텍스트 입력\n",
        "input_text = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
        "\n",
        "# 추출 체인 생성\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain(schema, llm)\n",
        "\n",
        "# 추출 실행\n",
        "result = chain.run(input_text)\n",
        "\n",
        "# 결과 출력\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VY2y3hinGNLS",
        "outputId": "e555fe2f-9fa4-4083-df33-d6f4183f5211"
      },
      "id": "VY2y3hinGNLS",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'event_name': 'annual science fair', 'date': 'March 15th', 'location': 'city hall', 'participants': ['Dr. Jane Doe', 'Prof. John Smith']}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import Optional, Sequence\n",
        "\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.output_parsers import PydanticOutputParser\n",
        "from langchain.prompts import (\n",
        "    PromptTemplate,\n",
        ")\n",
        "from pydantic import BaseModel, Field, validator\n",
        "class Event(BaseModel):\n",
        "    event_name: str\n",
        "    date: str\n",
        "    location: str\n",
        "    participants: list ## 리스트형태로\n",
        "\n",
        "query = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
        "\n",
        "# Set Parser\n",
        "parser = PydanticOutputParser(pydantic_object=Event)\n",
        "\n",
        "# Prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the query. \\n {format_instructions} \\m {query} \\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "# run chain\n",
        "_input = prompt.format_prompt(query=query)\n",
        "model = OpenAI(temperature=0)\n",
        "outputs = model(_input.to_string())\n",
        "parser.parse(outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDPAPiX4VQvT",
        "outputId": "55c7dfda-de99-4881-c1e5-31cc86cb5373"
      },
      "id": "bDPAPiX4VQvT",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Event(event_name='Annual Science Fair', date='March 15th', location='City Hall', participants=['Dr. Jane Doe', 'Prof. John Smith'])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Event(BaseModel):\n",
        "    name: str\n",
        "    event_name: str\n",
        "    date: str\n",
        "    location: str\n",
        "\n",
        "class People(BaseModel):\n",
        "    \"\"\"Event Participants\"\"\"\n",
        "    participants: Sequence[Event]\n",
        "\n",
        "query = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
        "\n",
        "# Set Parser\n",
        "parser = PydanticOutputParser(pydantic_object=People)\n",
        "\n",
        "# Prompt template\n",
        "prompt = PromptTemplate(\n",
        "    template=\"Answer the query. \\n {format_instructions} \\m {query} \\n\",\n",
        "    input_variables=[\"query\"],\n",
        "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
        ")\n",
        "\n",
        "# run chain\n",
        "_input = prompt.format_prompt(query=query)\n",
        "model = OpenAI(temperature=0)\n",
        "outputs = model(_input.to_string())\n",
        "parser.parse(outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrnKdmzHWfS7",
        "outputId": "7456b6bc-c173-437d-c13e-27a06e082741"
      },
      "id": "DrnKdmzHWfS7",
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "People(participants=[Event(name='Dr. Jane Doe', event_name='Annual Science Fair', date='March 15th', location='City Hall'), Event(name='Prof. John Smith', event_name='Annual Science Fair', date='March 15th', location='City Hall')])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 동적 스키마 생성\n",
        "* 사용자 입력에 기반하여 스키마를 자동으로 생성하는 파이썬 스크립트를 작성합니다. 이 스크립트는 사용자가 원하는 정보 유형을 입력하면 해당하는 스키마를 생성하고, 언어 모델을 사용하여 이 스키마에 따라 텍스트에서 정보를 추출합니다.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "1. 사용자 입력 처리: 사용자가 추출하고자 하는 정보 유형을 입력할 수 있는 인터페이스를 구현합니다. 예를 들어, 사용자가 \"이름\", \"나이\", \"직업\" 등을 입력할 수 있습니다.\n",
        "\n",
        "2. 동적 스키마 생성: 사용자의 입력을 기반으로 동적으로 스키마를 생성하는 함수를 구현합니다. 이 함수는 사용자가 입력한 정보 유형에 따라 적절한 스키마를 만듭니다.\n",
        "\n",
        "3. 추출 체인 설정 및 실행: 생성된 스키마를 사용하여 langchain 라이브러리의 추출 체인을 설정하고 실행합니다.\n",
        "\n",
        "4. 결과 출력 및 검증: 추출된 결과를 출력하고, 스크립트가 정확하게 사용자 요구 사항에 맞는 스키마를 생성했는지 검증합니다.\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "WanR5a9WIOi6"
      },
      "id": "WanR5a9WIOi6"
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dynamic_schema(user_inputs):\n",
        "    schema = {\"properties\": {}, \"required\": []}\n",
        "    for input in user_inputs:\n",
        "        # 여기에서 각 입력 유형에 대한 스키마 정의를 추가합니다.\n",
        "        schema[\"properties\"][input] = {\"type\": \"string\"}  # 예시: 모든 필드를 문자열로 처리 동적처리해줌\n",
        "        schema[\"required\"].append(input)\n",
        "    return schema\n",
        "\n",
        "# 사용자 입력\n",
        "user_inputs = ['name','age','occupation']  # 예시: 사용자가 입력한 필드\n",
        "\n",
        "# 스키마 생성\n",
        "dynamic_schema = create_dynamic_schema(user_inputs)\n",
        "\n",
        "# 텍스트 입력\n",
        "input_text = \"John, a 30-year-old engineer, works at Acme Corp.\"\n",
        "\n",
        "# 추출 체인 생성\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
        "chain = create_extraction_chain(dynamic_schema, llm)\n",
        "\n",
        "# 추출 실행\n",
        "result = chain.run(input_text)\n",
        "\n",
        "# 결과 출력\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1mD6pADTHS95",
        "outputId": "4ce4b7b8-d5f4-42d6-92d6-716f4b248edc"
      },
      "id": "1mD6pADTHS95",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'name': 'John', 'age': '30', 'occupation': 'engineer'}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vi5mss-BIJ6b"
      },
      "id": "vi5mss-BIJ6b",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}