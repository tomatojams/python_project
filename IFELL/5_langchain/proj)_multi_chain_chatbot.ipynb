{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 구글 드라이브 연결"
   ],
   "metadata": {
    "id": "AvGJfn3fKnIh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "dhBepVQ7kaYa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1dc42c0b-48ba-4222-9b7a-bfe423d09133"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 필수 설치 라이브러리"
   ],
   "metadata": {
    "id": "69rCi1LbKlkz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install -U langchain openai"
   ],
   "metadata": {
    "id": "E5cSH-P7kDDf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0dd705a2-7f1f-4fee-feab-a5c13ba1db36",
    "ExecuteTime": {
     "end_time": "2024-02-08T12:25:55.664137Z",
     "start_time": "2024-02-08T12:25:48.473374Z"
    }
   },
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (0.1.4)\r\n",
      "Collecting langchain\r\n",
      "  Obtaining dependency information for langchain from https://files.pythonhosted.org/packages/c1/c3/0e59a0c24e0c61b52271445df55302ab2f3dd8489a365721c7ef7ecaba24/langchain-0.1.5-py3-none-any.whl.metadata\r\n",
      "  Downloading langchain-0.1.5-py3-none-any.whl.metadata (13 kB)\r\n",
      "Requirement already satisfied: openai in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (1.10.0)\r\n",
      "Collecting openai\r\n",
      "  Obtaining dependency information for openai from https://files.pythonhosted.org/packages/37/34/f3c3d6bdc3eebf1b6a7c696dd6f934630af6cf5250cec099edf117cd3b53/openai-1.11.1-py3-none-any.whl.metadata\r\n",
      "  Downloading openai-1.11.1-py3-none-any.whl.metadata (18 kB)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (6.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.6.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (1.33)\r\n",
      "Collecting langchain-community<0.1,>=0.0.17 (from langchain)\r\n",
      "  Obtaining dependency information for langchain-community<0.1,>=0.0.17 from https://files.pythonhosted.org/packages/bf/b4/1b1b22ab0c57320c5476b735cfe1500e49ddc4425df9e4c2e569e4c4472e/langchain_community-0.0.19-py3-none-any.whl.metadata\r\n",
      "  Downloading langchain_community-0.0.19-py3-none-any.whl.metadata (7.9 kB)\r\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.1.16)\r\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.0.83)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (1.23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (3.5.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (0.26.0)\r\n",
      "Requirement already satisfied: sniffio in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: certifi in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Collecting langchain-core<0.2,>=0.1.16 (from langchain)\r\n",
      "  Obtaining dependency information for langchain-core<0.2,>=0.1.16 from https://files.pythonhosted.org/packages/ef/8c/e7fc5fa8b57e08ae03aecf184bde3e8dd69e96b168cab46fade4d62b3fec/langchain_core-0.1.21-py3-none-any.whl.metadata\r\n",
      "  Downloading langchain_core-0.1.21-py3-none-any.whl.metadata (6.0 kB)\r\n",
      "Collecting langsmith<0.1,>=0.0.83 (from langchain)\r\n",
      "  Obtaining dependency information for langsmith<0.1,>=0.0.83 from https://files.pythonhosted.org/packages/94/99/762b50b229516dd133e09c16213736b88d50d75e262b976e20cc244280ed/langsmith-0.0.87-py3-none-any.whl.metadata\r\n",
      "  Downloading langsmith-0.0.87-py3-none-any.whl.metadata (10 kB)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.1.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.1.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n",
      "Downloading langchain-0.1.5-py3-none-any.whl (806 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m806.7/806.7 kB\u001B[0m \u001B[31m2.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading openai-1.11.1-py3-none-any.whl (226 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m226.1/226.1 kB\u001B[0m \u001B[31m4.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0ma \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading langchain_community-0.0.19-py3-none-any.whl (1.6 MB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m4.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m00:01\u001B[0m00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading langchain_core-0.1.21-py3-none-any.whl (238 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m238.5/238.5 kB\u001B[0m \u001B[31m4.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m \u001B[36m0:00:01\u001B[0m\r\n",
      "\u001B[?25hDownloading langsmith-0.0.87-py3-none-any.whl (55 kB)\r\n",
      "\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m55.4/55.4 kB\u001B[0m \u001B[31m5.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\r\n",
      "\u001B[?25hInstalling collected packages: openai, langsmith, langchain-core, langchain-community, langchain\r\n",
      "  Attempting uninstall: openai\r\n",
      "    Found existing installation: openai 1.10.0\r\n",
      "    Uninstalling openai-1.10.0:\r\n",
      "      Successfully uninstalled openai-1.10.0\r\n",
      "  Attempting uninstall: langsmith\r\n",
      "    Found existing installation: langsmith 0.0.83\r\n",
      "    Uninstalling langsmith-0.0.83:\r\n",
      "      Successfully uninstalled langsmith-0.0.83\r\n",
      "  Attempting uninstall: langchain-core\r\n",
      "    Found existing installation: langchain-core 0.1.16\r\n",
      "    Uninstalling langchain-core-0.1.16:\r\n",
      "      Successfully uninstalled langchain-core-0.1.16\r\n",
      "  Attempting uninstall: langchain-community\r\n",
      "    Found existing installation: langchain-community 0.0.16\r\n",
      "    Uninstalling langchain-community-0.0.16:\r\n",
      "      Successfully uninstalled langchain-community-0.0.16\r\n",
      "  Attempting uninstall: langchain\r\n",
      "    Found existing installation: langchain 0.1.4\r\n",
      "    Uninstalling langchain-0.1.4:\r\n",
      "      Successfully uninstalled langchain-0.1.4\r\n",
      "Successfully installed langchain-0.1.5 langchain-community-0.0.19 langchain-core-0.1.21 langsmith-0.0.87 openai-1.11.1\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain, LLMRouterChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from pydantic import BaseModel"
   ],
   "metadata": {
    "id": "k9S8nGKhkF5O",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:45:39.035122300Z",
     "start_time": "2024-02-08T13:45:39.024551200Z"
    }
   },
   "execution_count": 16,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API 키 입력"
   ],
   "metadata": {
    "id": "X4k4IQXLKqJd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "# 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\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "metadata": {
    "id": "IF5T5HPykHoL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fdea00c0-bca2-4d4c-9465-9c0febcbd237",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:45:50.899151Z",
     "start_time": "2024-02-08T13:45:48.295798600Z"
    }
   },
   "execution_count": 17,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LLM 파트 구현\n",
    "* 게임룰에 대한 정보들을 얻는 방법을 프롬프트 체인을 이용해 구성했습니다.\n",
    "* 부루마블이라는 보드게임을 진행하기위한 기본적인 rule과 건물을 지을 수 있는 규칙이 들어간 데이터를 이용해서 문답을 진행합니다."
   ],
   "metadata": {
    "id": "Q-JehMyJK4OB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH = \"./chain_prompts\"\n",
    "RULE_1 = os.path.join(\n",
    "    PATH, \"game_basic.txt\"\n",
    ")\n",
    "RULE_2 = os.path.join(\n",
    "    PATH, \"game_building.txt\"\n",
    ")\n",
    "INTRO = os.path.join(\n",
    "    PATH, \"intro.txt\"\n",
    ")\n",
    "PHIL_2 = os.path.join(\n",
    "    PATH, \"Philosophy_2.txt\"\n",
    ")\n",
    "PHIL_3 = os.path.join(\n",
    "    PATH, \"Philosophy_3.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_prompt_template(file_path: str) -> str:\n",
    "    with open(file_path, \"r\", encoding='UTF8') as f:\n",
    "        prompt_template = f.read()\n",
    "\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "def create_chain(llm, template_path, output_key):\n",
    "    return LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=ChatPromptTemplate.from_template(\n",
    "            template=read_prompt_template(template_path)\n",
    "        ),\n",
    "        output_key=output_key,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1, max_tokens=200, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "rule_1 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=RULE_1,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "rule_2 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=RULE_2,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "intro = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=INTRO,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "\n",
    "phil_2 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=PHIL_2,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "phil_3 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=PHIL_3,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "\n",
    "\n",
    "destinations = [\n",
    "    \"basic: This page describes the basic rules used to play the board game Burumble.\",\n",
    "    \"building: This is where you'll find the rules for buildings as you play the board game.\",\n",
    "    \"into_myself: This is where you'll find the introduction of myself.\",\n",
    "    \"philosophy_myself: 데카트르철학.\",\n",
    "    \"philosophy_Confucius: This is where you'll find the philosophy of Confucius.\",\n",
    "]\n",
    "destinations = \"\\n\".join(destinations)\n",
    "router_prompt_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations)\n",
    "router_prompt = PromptTemplate.from_template(\n",
    "    template=router_prompt_template, output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt, verbose=True)\n",
    "\n",
    "multi_prompt_chain = MultiPromptChain( # 멀티프롬프트체인 라우터체인과 데이터네이션 체인 그리고 디펄트체의 합체\n",
    "    router_chain=router_chain, # 라우터를 쓰면서 텍스트양이 반으로 줄어듬 정확도도 올라감\n",
    "\n",
    "    destination_chains={\n",
    "    \"basic\": rule_1,\n",
    "    \"building\": rule_2,\n",
    "    \"into_myself\": intro, # 소개를 질문받으면 답변합니다.\n",
    "    \"philosophy_myself\": phil_2,\n",
    "    \"philosophy_Confucius\": phil_3,\n",
    "},\n",
    "\n",
    "    default_chain=ConversationChain(llm=llm, output_key=\"text\"),\n",
    ")\n",
    "\n",
    "\n",
    "class UserRequest(BaseModel):\n",
    "    user_message: str\n",
    "\n",
    "\n",
    "def gernerate_answer(req: UserRequest) -> Dict[str, str]:\n",
    "    context = req.dict()\n",
    "    context[\"input\"] = context[\"user_message\"]\n",
    "    answer = multi_prompt_chain.run(context)\n",
    "\n",
    "    return {\"answer\": answer}"
   ],
   "metadata": {
    "id": "5fnHwrb3myFZ",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:49:02.401484100Z",
     "start_time": "2024-02-08T13:49:01.987632800Z"
    }
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### User 데이터 입력\n",
    "* 유저 데이터 입력 후 결과를 확인 합니다."
   ],
   "metadata": {
    "id": "1uFhqhFLLdA_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_data = {\n",
    "    \"user_message\": \" 너는 뭘 할수있어?\"\n",
    "}"
   ],
   "metadata": {
    "id": "BmhMK-FlDVgO",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:49:03.162895600Z",
     "start_time": "2024-02-08T13:49:02.958878100Z"
    }
   },
   "execution_count": 28,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "request_instance = UserRequest(**user_data)"
   ],
   "metadata": {
    "id": "EThoAGelDMeJ",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:49:03.645701Z",
     "start_time": "2024-02-08T13:49:03.600864700Z"
    }
   },
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gernerate_answer(request_instance)"
   ],
   "metadata": {
    "id": "hhqWB9SxDPQM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b5db86d6-cdb7-458f-986f-f3ff981c3b4f",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:49:11.573747800Z",
     "start_time": "2024-02-08T13:49:04.067855900Z"
    }
   },
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain\\chains\\llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 소개\n",
      "\n",
      "자세히 묻지 않는다면, 3문장 이내로만 소개를 하자.\n",
      "챗봇이라는 용어는 되도록 쓰지말고, 친절한 당신의 인공지능 비서라고 생각해주세요.라는 식으로 표현하자.\n",
      "저는 인공지능으로 상담심리사를 연결하고 추천해주는 친절한 역할을 합니다.\n",
      "다만 가벼운 대화나, 상담사와의 대화를 통해 더 나은 방향으로 나아가는데 도움이 되는 정보를 제공할 수 있습니다.\n",
      "\n",
      "[message]\n",
      "너는 뭘 할수있어?\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'answer': '저는 인공지능으로 상담심리사를 연결하고 추천해주는 역할을 합니다. 또한 가벼운 대화나 상담사와의 대화를 통해 더 나은 방향으로 나아가는데 도움이 되는 정보를 제공할 수 있습니다.'}"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-08T12:53:09.589495Z",
     "start_time": "2024-02-08T12:53:09.576518Z"
    }
   },
   "execution_count": 70
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
