{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee7f95e4",
   "metadata": {
    "id": "ee7f95e4"
   },
   "source": [
    "## Use case\n",
    "\n",
    "챗봇은 핵심적인 LLM 사용 사례 중 하나입니다. 챗봇의 핵심 기능은 장시간 대화가 가능하고 사용자가 알고 싶어하는 정보에 액세스할 수 있다는 것입니다.\n",
    "\n",
    "기본적인 프롬프트와 LLM 외에도 메모리와 검색은 챗봇의 핵심 구성 요소입니다. 메모리는 챗봇이 과거의 상호작용을 기억할 수 있게 해주며, 검색은 챗봇에게 도메인별 최신 정보를 제공합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff48f490",
   "metadata": {
    "id": "ff48f490"
   },
   "source": [
    "## Overview\n",
    "\n",
    "채팅 모델 인터페이스는 원시 텍스트가 아닌 메시지를 기반으로 합니다. 채팅 시 고려해야 할 몇 가지 구성 요소가 중요합니다:\n",
    "\n",
    "* `채팅 모델`: 채팅 모델은 대화형 톤이 더 강하고 기본적으로 메시지 인터페이스를 지원합니다.\n",
    "* `프롬프트 템플릿`: 프롬프트 템플릿을 사용하면 기본 메시지, 사용자 입력, 채팅 기록 및 (선택 사항으로) 검색된 추가 컨텍스트를 결합하는 프롬프트를 쉽게 조합할 수 있습니다.\n",
    "\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "다음은 챗봇 인터페이스를 만드는 방법에 대한 간단한 미리보기입니다. 먼저 몇 가지 종속성을 설치하고 필요한 자격 증명을 설정해 보겠습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5070a1fd",
   "metadata": {
    "id": "5070a1fd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491096634,
     "user_tz": -540,
     "elapsed": 26418,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    },
    "outputId": "fc937a4d-8725-44c2-daae-3c1a443d13f8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.1.4-py3-none-any.whl (803 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m803.6/803.6 kB\u001B[0m \u001B[31m6.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting openai\n",
      "  Downloading openai-1.10.0-py3-none-any.whl (225 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m225.1/225.1 kB\u001B[0m \u001B[31m9.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.24)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-community<0.1,>=0.0.14 (from langchain)\n",
      "  Downloading langchain_community-0.0.16-py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting langchain-core<0.2,>=0.1.16 (from langchain)\n",
      "  Downloading langchain_core-0.1.16-py3-none-any.whl (230 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m230.3/230.3 kB\u001B[0m \u001B[31m15.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting langsmith<0.1,>=0.0.83 (from langchain)\n",
      "  Downloading langsmith-0.0.84-py3-none-any.whl (53 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m54.0/54.0 kB\u001B[0m \u001B[31m4.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.14)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.26.0-py3-none-any.whl (75 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.9/75.9 kB\u001B[0m \u001B[31m6.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Collecting typing-extensions<5,>=4.7 (from openai)\n",
      "  Downloading typing_extensions-4.9.0-py3-none-any.whl (32 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.2-py3-none-any.whl (49 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.4/49.4 kB\u001B[0m \u001B[31m1.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.9/76.9 kB\u001B[0m \u001B[31m4.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m4.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: typing-extensions, mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, jsonpatch, httpcore, langsmith, httpx, dataclasses-json, openai, langchain-core, langchain-community, langchain\n",
      "  Attempting uninstall: typing-extensions\n",
      "    Found existing installation: typing_extensions 4.5.0\n",
      "    Uninstalling typing_extensions-4.5.0:\n",
      "      Successfully uninstalled typing_extensions-4.5.0\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\n",
      "tensorflow-probability 0.22.0 requires typing-extensions<4.6.0, but you have typing-extensions 4.9.0 which is incompatible.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.26.0 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.4 langchain-community-0.0.16 langchain-core-0.1.16 langsmith-0.0.84 marshmallow-3.20.2 mypy-extensions-1.0.0 openai-1.10.0 typing-extensions-4.9.0 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 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\n",
    "\n",
    "# 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\n",
    "\n",
    "# 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\n",
    "\n",
    "# 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\n"
   ],
   "metadata": {
    "id": "gTBt0dfKyGuW"
   },
   "id": "gTBt0dfKyGuW",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vTgoaN3Vr0OM",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494344135,
     "user_tz": -540,
     "elapsed": 2835,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    },
    "outputId": "d4d0db75-78e7-4aa7-aa27-9f000b46d364"
   },
   "id": "vTgoaN3Vr0OM",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "··········\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88197b95",
   "metadata": {
    "id": "88197b95"
   },
   "source": [
    "일반 채팅 모델을 사용하면 모델에 하나 이상의 메시지를 전달하여 채팅 완료를 얻을 수 있습니다.\n",
    "\n",
    "채팅 모델은 메시지로 응답합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5b0d84ae",
   "metadata": {
    "id": "5b0d84ae",
    "outputId": "141373b3-7ded-4554-e0df-398a3e2ca3c4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494349010,
     "user_tz": -540,
     "elapsed": 947,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'aime la programmation.\")"
      ]
     },
     "metadata": {},
     "execution_count": 44
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage\n",
    "\n",
    "chat = ChatOpenAI()\n",
    "chat(\n",
    "    [\n",
    "        HumanMessage(\n",
    "            content=\"Translate this sentence from English to French: I love programming.\"\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7935d9a5",
   "metadata": {
    "id": "7935d9a5"
   },
   "source": [
    "메시지 목록을 전달하면 됩니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "afd27a9f",
   "metadata": {
    "id": "afd27a9f",
    "outputId": "e3202ff9-a486-41a8-cab0-0646961212b5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494351332,
     "user_tz": -540,
     "elapsed": 995,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "AIMessage(content=\"J'adore programmer.\")"
      ]
     },
     "metadata": {},
     "execution_count": 45
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage( # 지시사항 체인\n",
    "        content=\"You are a helpful assistant that translates English to French.\"\n",
    "    ),\n",
    "    HumanMessage(content=\"I love programming.\"),\n",
    "]\n",
    "chat(messages)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7a1d169",
   "metadata": {
    "id": "c7a1d169"
   },
   "source": [
    "그런 다음 채팅 모델을 과거 사용자 입력과 모델 출력을 기억하는 메모리가 내장된 '대화 체인'으로 감쌀 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fdb05d74",
   "metadata": {
    "id": "fdb05d74",
    "outputId": "4843aa0e-8f32-4abb-c458-9151d8a636d4",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 89
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491405257,
     "user_tz": -540,
     "elapsed": 1822,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Je adore la programmation.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "from langchain.chains import ConversationChain\n",
    "\n",
    "conversation = ConversationChain(llm=chat) # 기존체인을 기반으로 다시 대화 기존대화 기억가능\n",
    "conversation.run(\"Translate this sentence from English to French: I love programming.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d801a173",
   "metadata": {
    "id": "d801a173",
    "outputId": "bfc05c60-f47d-468e-bfb0-167d344a8bf3",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491407759,
     "user_tz": -540,
     "elapsed": 423,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'Ich liebe Programmieren.'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "conversation.run(\"Translate it to German.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e86788c",
   "metadata": {
    "id": "9e86788c"
   },
   "source": [
    "\n",
    "위에서 언급했듯이 챗봇의 핵심 구성 요소는 메모리 시스템입니다. 가장 간단하고 일반적으로 사용되는 메모리 형태 중 하나는 `ConversationBufferMemory`입니다:\n",
    "* 이 메모리는 `버퍼`에 메시지를 저장할 수 있습니다.\n",
    "* 체인에서 호출하면 저장된 모든 메시지를 반환합니다.\n",
    "\n",
    "여기서는 컨버세이션버퍼메모리에 대해 간단히 살펴보겠습니다. 다음과 같이 메모리에 몇 개의 채팅 메시지를 수동으로 추가할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1380a4ea",
   "metadata": {
    "id": "1380a4ea",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491410088,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "memory = ConversationBufferMemory()\n",
    "memory.chat_memory.add_user_message(\"hi!\")\n",
    "memory.chat_memory.add_ai_message(\"whats up?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d5d1f8",
   "metadata": {
    "id": "a3d5d1f8"
   },
   "source": [
    "이제 메모리에서 로드할 수 있습니다. 모든 `Memory` 클래스가 노출하는 핵심 메서드는 `load_memory_variables`입니다. 이 메서드는 초기 체인 입력을 받아 체인 입력에 추가되는 메모리 변수 목록을 반환합니다.\n",
    "\n",
    "이 간단한 메모리 유형은 메모리를 로드할 때 실제로 체인 입력을 고려하지 않으므로 지금은 빈 입력을 전달할 수 있습니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "982467e7",
   "metadata": {
    "id": "982467e7",
    "outputId": "b1249f4c-2911-4afc-c6b6-c536e2eebef1",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491417236,
     "user_tz": -540,
     "elapsed": 359,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'history': 'Human: hi!\\nAI: whats up?'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c1b20d4",
   "metadata": {
    "id": "7c1b20d4"
   },
   "source": [
    "대화 버퍼 창 메모리`를 사용하여 가장 최근의 `k` 상호작용을 슬라이딩 창으로 보관할 수도 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f72b9ff7",
   "metadata": {
    "id": "f72b9ff7",
    "outputId": "04228f22-f79e-4d7a-d828-4736be9af558",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491420553,
     "user_tz": -540,
     "elapsed": 732,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'history': 'Human: not much you\\nAI: not much'}"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "from langchain.memory import ConversationBufferWindowMemory\n",
    "\n",
    "memory = ConversationBufferWindowMemory(k=1)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})\n",
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b84f90a",
   "metadata": {
    "id": "7b84f90a"
   },
   "source": [
    "`ConversationSummaryBufferMemory`는 이 테마의 확장입니다.\n",
    "\n",
    "이 메모리는 시간 경과에 따른 대화의 요약을 생성합니다.\n",
    "\n",
    "이 메모리는 전체 메시지 기록이 많은 토큰을 소모하는 긴 대화에 가장 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca2596ed",
   "metadata": {
    "id": "ca2596ed",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491441932,
     "user_tz": -540,
     "elapsed": 6634,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    },
    "outputId": "52defeb5-5e8b-4a58-aeab-a69cc9a6f8ab"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.llms.openai.OpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.memory import ConversationSummaryMemory\n",
    "\n",
    "llm = OpenAI(temperature=0)\n",
    "memory = ConversationSummaryMemory(llm=llm)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context(\n",
    "    {\"input\": \"im working on better docs for chatbots\"},\n",
    "    {\"output\": \"oh, that sounds like a lot of work\"},\n",
    ")\n",
    "memory.save_context(\n",
    "    {\"input\": \"yes, but it's worth the effort\"},\n",
    "    {\"output\": \"agreed, good docs are important!\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "060f69b7",
   "metadata": {
    "id": "060f69b7",
    "outputId": "3ed64857-050d-43d5-c4c4-40433a512cd6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491493741,
     "user_tz": -540,
     "elapsed": 416,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'history': \"\\nThe human greets the AI and asks what's up. The AI responds by asking what's going on. The human then mentions working on better documentation for chatbots, to which the AI responds by acknowledging that it sounds like a lot of work. The human agrees, saying it's worth the effort. The AI also agrees, emphasizing the importance of good documentation.\"}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "memory.load_memory_variables({})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf036f6",
   "metadata": {
    "id": "4bf036f6"
   },
   "source": [
    "`ConversationSummaryBufferMemory`는 이를 조금 더 확장합니다:\n",
    "\n",
    "상호작용의 개수가 아닌 토큰 길이를 사용해 상호작용을 플러시할 시기를 결정합니다."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "!pip install tiktoken"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxvygL2ayY_g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491501599,
     "user_tz": -540,
     "elapsed": 6487,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    },
    "outputId": "17f9eb30-a145-44f4-87e1-2bedbbc8b059"
   },
   "id": "jxvygL2ayY_g",
   "execution_count": 12,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting tiktoken\n",
      "  Downloading tiktoken-0.5.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m10.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2023.6.3)\n",
      "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken) (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2.0.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken) (2023.11.17)\n",
      "Installing collected packages: tiktoken\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed tiktoken-0.5.2\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38b42728",
   "metadata": {
    "id": "38b42728",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706491503593,
     "user_tz": -540,
     "elapsed": 1998,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "from langchain.memory import ConversationSummaryBufferMemory\n",
    "\n",
    "memory = ConversationSummaryBufferMemory(llm=llm, max_token_limit=10)\n",
    "memory.save_context({\"input\": \"hi\"}, {\"output\": \"whats up\"})\n",
    "memory.save_context({\"input\": \"not much you\"}, {\"output\": \"not much\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0db09f",
   "metadata": {
    "id": "ff0db09f"
   },
   "source": [
    "## Conversation\n",
    "\n",
    "`ConversationChain`으로 내부의 내용을 풀 수 있습니다.\n",
    "\n",
    "메모리인 `ConversationSummaryMemory`를 지정하고 프롬프트를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fccd6995",
   "metadata": {
    "id": "fccd6995",
    "outputId": "f103f567-f115-4fa4-d5ff-2322f8859ce4",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706492015466,
     "user_tz": -540,
     "elapsed": 2375,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: 안녕 너는 누구야?\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'question': '안녕 너는 누구야?',\n",
       " 'chat_history': [HumanMessage(content='안녕 너는 누구야?'),\n",
       "  AIMessage(content='안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?')],\n",
       " 'text': '안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?'}"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import (\n",
    "    ChatPromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    "    MessagesPlaceholder,\n",
    "    SystemMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI()\n",
    "\n",
    "# Prompt\n",
    "prompt = ChatPromptTemplate(\n",
    "    messages=[ # 프롬프트 설정이 매우 중요함. 프롬프트 개선이 성능개선\n",
    "        SystemMessagePromptTemplate.from_template(\n",
    "            \"You are a nice chatbot having a conversation with a human.\"\n",
    "        ), # 지시내용\n",
    "        # The `variable_name` here is what must align with memory\n",
    "        MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "               # 대화의 이전 메시지들을 저장하는데 사용됩니다. 변수 이름은 \"chat_history\"로 설정됩니다.\n",
    "        HumanMessagePromptTemplate.from_template(\"{question}\"), #사용자의 질문을 받아들이기 위한 템플릿입니다.\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Notice that we `return_messages=True` to fit into the MessagesPlaceholder\n",
    "# Notice that `\"chat_history\"` aligns with the MessagesPlaceholder name\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True) # 대화맥락\n",
    "conversation = LLMChain(llm=llm, prompt=prompt, verbose=True, memory=memory)\n",
    "\n",
    "# Notice that we just pass in the `question` variables - `chat_history` gets populated by memory\n",
    "conversation({\"question\": \"안녕 너는 누구야?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb0cadfd",
   "metadata": {
    "id": "eb0cadfd",
    "outputId": "be570d0c-fde8-485d-877c-633f01e73af7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706492169458,
     "user_tz": -540,
     "elapsed": 2399,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: 안녕 너는 누구야?\n",
      "AI: 안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?\n",
      "Human: Translate this sentence from English to French: I love programming.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'question': 'Translate this sentence from English to French: I love programming.',\n",
       " 'chat_history': [HumanMessage(content='안녕 너는 누구야?'),\n",
       "  AIMessage(content='안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?'),\n",
       "  HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       "  AIMessage(content='Je suis désolé, mais je ne peux pas traduire directement de l\\'anglais vers le français. Cependant, la traduction de \"I love programming\" en français est \"J\\'adore programmer\".')],\n",
       " 'text': 'Je suis désolé, mais je ne peux pas traduire directement de l\\'anglais vers le français. Cependant, la traduction de \"I love programming\" en français est \"J\\'adore programmer\".'}"
      ]
     },
     "metadata": {},
     "execution_count": 22
    }
   ],
   "source": [
    "conversation(\n",
    "    {\"question\": \"Translate this sentence from English to French: I love programming.\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c56d6219",
   "metadata": {
    "id": "c56d6219",
    "outputId": "6a5f7f61-fa95-4b35-a153-89509835bd41",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706492173957,
     "user_tz": -540,
     "elapsed": 585,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mSystem: You are a nice chatbot having a conversation with a human.\n",
      "Human: 안녕 너는 누구야?\n",
      "AI: 안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?\n",
      "Human: Translate this sentence from English to French: I love programming.\n",
      "AI: Je suis désolé, mais je ne peux pas traduire directement de l'anglais vers le français. Cependant, la traduction de \"I love programming\" en français est \"J'adore programmer\".\n",
      "Human: Now translate the sentence to German.\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'question': 'Now translate the sentence to German.',\n",
       " 'chat_history': [HumanMessage(content='안녕 너는 누구야?'),\n",
       "  AIMessage(content='안녕하세요! 저는 인공지능 챗봇입니다. 대화하고 싶은 내용이 있으신가요?'),\n",
       "  HumanMessage(content='Translate this sentence from English to French: I love programming.'),\n",
       "  AIMessage(content='Je suis désolé, mais je ne peux pas traduire directement de l\\'anglais vers le français. Cependant, la traduction de \"I love programming\" en français est \"J\\'adore programmer\".'),\n",
       "  HumanMessage(content='Now translate the sentence to German.'),\n",
       "  AIMessage(content='Ich liebe das Programmieren.')],\n",
       " 'text': 'Ich liebe das Programmieren.'}"
      ]
     },
     "metadata": {},
     "execution_count": 23
    }
   ],
   "source": [
    "conversation({\"question\": \"Now translate the sentence to German.\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f35cc16",
   "metadata": {
    "id": "3f35cc16"
   },
   "source": [
    "## Chat Retrieval\n",
    "\n",
    "이제 [문서와 채팅](https://twitter.com/mayowaoshin/status/1640385062708424708?s=20) 또는 다른 지식 소스를 사용한다고 가정해 보겠습니다.\n",
    "\n",
    "이것은 채팅과 `문서 검색`을 결합한 인기 있는 사용 사례입니다.\n",
    "\n",
    "이를 통해 모델에 학습되지 않은 특정 정보에 대해 채팅할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a01e7b5",
   "metadata": {
    "id": "1a01e7b5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706492210512,
     "user_tz": -540,
     "elapsed": 32204,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    },
    "outputId": "5df99016-1861-4b52-9894-415bcadcb87b"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting chromadb\n",
      "  Downloading chromadb-0.4.22-py3-none-any.whl (509 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m509.0/509.0 kB\u001B[0m \u001B[31m5.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.0.3)\n",
      "Requirement already satisfied: requests>=2.28 in /usr/local/lib/python3.10/dist-packages (from chromadb) (2.31.0)\n",
      "Requirement already satisfied: pydantic>=1.9 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.10.14)\n",
      "Collecting chroma-hnswlib==0.7.3 (from chromadb)\n",
      "  Downloading chroma_hnswlib-0.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.4/2.4 MB\u001B[0m \u001B[31m8.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting fastapi>=0.95.2 (from chromadb)\n",
      "  Downloading fastapi-0.109.0-py3-none-any.whl (92 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m92.0/92.0 kB\u001B[0m \u001B[31m11.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Downloading uvicorn-0.27.0-py3-none-any.whl (60 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m60.6/60.6 kB\u001B[0m \u001B[31m7.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy>=1.22.5 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.23.5)\n",
      "Collecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.3.3-py2.py3-none-any.whl (40 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m40.7/40.7 kB\u001B[0m \u001B[31m1.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.9.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m5.4/5.4 MB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.16.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m6.4/6.4 MB\u001B[0m \u001B[31m37.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting opentelemetry-api>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_api-1.22.0-py3-none-any.whl (57 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m57.9/57.9 kB\u001B[0m \u001B[31m6.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting opentelemetry-exporter-otlp-proto-grpc>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_grpc-1.22.0-py3-none-any.whl (18 kB)\n",
      "Collecting opentelemetry-instrumentation-fastapi>=0.41b0 (from chromadb)\n",
      "  Downloading opentelemetry_instrumentation_fastapi-0.43b0-py3-none-any.whl (11 kB)\n",
      "Collecting opentelemetry-sdk>=1.2.0 (from chromadb)\n",
      "  Downloading opentelemetry_sdk-1.22.0-py3-none-any.whl (105 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m105.6/105.6 kB\u001B[0m \u001B[31m12.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tokenizers>=0.13.2 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.15.1)\n",
      "Collecting pypika>=0.48.9 (from chromadb)\n",
      "  Downloading PyPika-0.48.9.tar.gz (67 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.3/67.3 kB\u001B[0m \u001B[31m8.4 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Installing build dependencies ... \u001B[?25l\u001B[?25hdone\n",
      "  Getting requirements to build wheel ... \u001B[?25l\u001B[?25hdone\n",
      "  Preparing metadata (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "Requirement already satisfied: tqdm>=4.65.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (4.66.1)\n",
      "Collecting overrides>=7.3.1 (from chromadb)\n",
      "  Downloading overrides-7.7.0-py3-none-any.whl (17 kB)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.1.1)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (1.60.0)\n",
      "Collecting bcrypt>=4.0.1 (from chromadb)\n",
      "  Downloading bcrypt-4.1.2-cp39-abi3-manylinux_2_28_x86_64.whl (698 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m698.9/698.9 kB\u001B[0m \u001B[31m48.7 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (0.9.0)\n",
      "Collecting kubernetes>=28.1.0 (from chromadb)\n",
      "  Downloading kubernetes-29.0.0-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.6/1.6 MB\u001B[0m \u001B[31m48.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: tenacity>=8.2.3 in /usr/local/lib/python3.10/dist-packages (from chromadb) (8.2.3)\n",
      "Requirement already satisfied: PyYAML>=6.0.0 in /usr/local/lib/python3.10/dist-packages (from chromadb) (6.0.1)\n",
      "Collecting mmh3>=4.0.1 (from chromadb)\n",
      "  Downloading mmh3-4.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (67 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m67.6/67.6 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: packaging>=19.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (23.2)\n",
      "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: tomli>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb) (2.0.1)\n",
      "Collecting starlette<0.36.0,>=0.35.0 (from fastapi>=0.95.2->chromadb)\n",
      "  Downloading starlette-0.35.1-py3-none-any.whl (71 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m71.1/71.1 kB\u001B[0m \u001B[31m8.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: certifi>=14.05.14 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2023.11.17)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.8.2)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.17.3)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.7.0)\n",
      "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb) (2.0.7)\n",
      "Collecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m46.0/46.0 kB\u001B[0m \u001B[31m5.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (3.20.3)\n",
      "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Collecting deprecated>=1.2.6 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n",
      "Collecting importlib-metadata<7.0,>=6.0 (from opentelemetry-api>=1.2.0->chromadb)\n",
      "  Downloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
      "Collecting backoff<3.0.0,>=1.10.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.62.0)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.22.0-py3-none-any.whl (17 kB)\n",
      "Collecting opentelemetry-proto==1.22.0 (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb)\n",
      "  Downloading opentelemetry_proto-1.22.0-py3-none-any.whl (50 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m50.8/50.8 kB\u001B[0m \u001B[31m5.8 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting opentelemetry-instrumentation-asgi==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation_asgi-0.43b0-py3-none-any.whl (14 kB)\n",
      "Collecting opentelemetry-instrumentation==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_instrumentation-0.43b0-py3-none-any.whl (28 kB)\n",
      "Collecting opentelemetry-semantic-conventions==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_semantic_conventions-0.43b0-py3-none-any.whl (36 kB)\n",
      "Collecting opentelemetry-util-http==0.43b0 (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading opentelemetry_util_http-0.43b0-py3-none-any.whl (6.9 kB)\n",
      "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (67.7.2)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.14.1)\n",
      "Collecting asgiref~=3.0 (from opentelemetry-instrumentation-asgi==0.43b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb)\n",
      "  Downloading asgiref-3.7.2-py3-none-any.whl (24 kB)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.28->chromadb) (3.6)\n",
      "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers>=0.13.2->chromadb) (0.20.3)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer>=0.9.0->chromadb) (8.1.7)\n",
      "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Collecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.6.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (341 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m341.4/341.4 kB\u001B[0m \u001B[31m34.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.19.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.4 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.4/3.4 MB\u001B[0m \u001B[31m58.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.21.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m1.3/1.3 MB\u001B[0m \u001B[31m68.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m130.2/130.2 kB\u001B[0m \u001B[31m16.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.3.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.3.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2023.6.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.17.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (3.7.1)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m86.8/86.8 kB\u001B[0m \u001B[31m11.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.3.0)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette<0.36.0,>=0.35.0->fastapi>=0.95.2->chromadb) (1.2.0)\n",
      "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.5.1)\n",
      "Building wheels for collected packages: pypika\n",
      "  Building wheel for pypika (pyproject.toml) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pypika: filename=PyPika-0.48.9-py2.py3-none-any.whl size=53723 sha256=ebcf70e47c07ef4f4866e6fe757be2a958ac0fef0b04b25da083c07b33da1892\n",
      "  Stored in directory: /root/.cache/pip/wheels/e1/26/51/d0bffb3d2fd82256676d7ad3003faea3bd6dddc9577af665f4\n",
      "Successfully built pypika\n",
      "Installing collected packages: pypika, monotonic, mmh3, websockets, uvloop, uvicorn, python-dotenv, pulsar-client, overrides, opentelemetry-util-http, opentelemetry-semantic-conventions, opentelemetry-proto, importlib-metadata, humanfriendly, httptools, deprecated, chroma-hnswlib, bcrypt, backoff, asgiref, watchfiles, starlette, posthog, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, coloredlogs, opentelemetry-sdk, opentelemetry-instrumentation, onnxruntime, kubernetes, fastapi, opentelemetry-instrumentation-asgi, opentelemetry-exporter-otlp-proto-grpc, opentelemetry-instrumentation-fastapi, chromadb\n",
      "  Attempting uninstall: importlib-metadata\n",
      "    Found existing installation: importlib-metadata 7.0.1\n",
      "    Uninstalling importlib-metadata-7.0.1:\n",
      "      Successfully uninstalled importlib-metadata-7.0.1\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lida 0.0.10 requires kaleido, which is not installed.\n",
      "lida 0.0.10 requires python-multipart, which is not installed.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed asgiref-3.7.2 backoff-2.2.1 bcrypt-4.1.2 chroma-hnswlib-0.7.3 chromadb-0.4.22 coloredlogs-15.0.1 deprecated-1.2.14 fastapi-0.109.0 httptools-0.6.1 humanfriendly-10.0 importlib-metadata-6.11.0 kubernetes-29.0.0 mmh3-4.1.0 monotonic-1.6 onnxruntime-1.16.3 opentelemetry-api-1.22.0 opentelemetry-exporter-otlp-proto-common-1.22.0 opentelemetry-exporter-otlp-proto-grpc-1.22.0 opentelemetry-instrumentation-0.43b0 opentelemetry-instrumentation-asgi-0.43b0 opentelemetry-instrumentation-fastapi-0.43b0 opentelemetry-proto-1.22.0 opentelemetry-sdk-1.22.0 opentelemetry-semantic-conventions-0.43b0 opentelemetry-util-http-0.43b0 overrides-7.7.0 posthog-3.3.3 pulsar-client-3.4.0 pypika-0.48.9 python-dotenv-1.0.1 starlette-0.35.1 uvicorn-0.27.0 uvloop-0.19.0 watchfiles-0.21.0 websockets-12.0\n"
     ]
    }
   ],
   "source": [
    "!pip install chromadb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e220de",
   "metadata": {
    "id": "88e220de"
   },
   "source": [
    "블로그 게시물을 로드합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1b99b36c",
   "metadata": {
    "id": "1b99b36c",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494210737,
     "user_tz": -540,
     "elapsed": 961,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "# from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "# loader = WebBaseLoader(\"https://lilianweng.github.io/posts/2023-06-23-agent/\")\n",
    "# data = loader.load()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "\n",
    "loader = WebBaseLoader(\"https://www.iautocar.co.kr/news/articleView.html?idxno=32166\")\n",
    "data = loader.load()"
   ],
   "metadata": {
    "id": "GLhvptu1_E7g",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494362905,
     "user_tz": -540,
     "elapsed": 4806,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "id": "GLhvptu1_E7g",
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "3662ce79",
   "metadata": {
    "id": "3662ce79"
   },
   "source": [
    "이를 벡터로 분할하여 저장합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "058f1541",
   "metadata": {
    "id": "058f1541",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494362906,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)\n",
    "all_splits = text_splitter.split_documents(data)\n",
    "# 내용을 잘라놓음\n",
    "\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "vectorstore = Chroma.from_documents(documents=all_splits, embedding=OpenAIEmbeddings())\n",
    "# 임베딩해서 벡터로 저장"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "all_splits"
   ],
   "metadata": {
    "id": "Z736v8FGGCu2"
   },
   "id": "Z736v8FGGCu2",
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "603d9441",
   "metadata": {
    "id": "603d9441"
   },
   "source": [
    "이전과 마찬가지로 메모리를 생성하되, `ConversationSummaryMemory`를 사용하겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "f89fd3f5",
   "metadata": {
    "id": "f89fd3f5",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494366294,
     "user_tz": -540,
     "elapsed": 292,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "28503423",
   "metadata": {
    "id": "28503423",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494368211,
     "user_tz": -540,
     "elapsed": 332,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI()\n",
    "retriever = vectorstore.as_retriever()\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9c3bd5e",
   "metadata": {
    "id": "a9c3bd5e",
    "outputId": "257b7711-b55b-45d9-a004-568334e5bedb",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494388116,
     "user_tz": -540,
     "elapsed": 9672,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'question': '중요 주제가 뭐야?',\n",
       " 'chat_history': [SystemMessage(content='')],\n",
       " 'answer': '주어진 문맥에서 중요한 주제는 페라리와 그의 작품에 대한 언급입니다. 그의 작품과 전시에 대한 이야기가 여러 번 언급되었으며, 해외 전시에 대한 고민과 두려움도 언급되었습니다. 따라서 페라리와 그의 작품이 중요한 주제로 보입니다.'}"
      ]
     },
     "metadata": {},
     "execution_count": 50
    }
   ],
   "source": [
    "qa(\"중요 주제가 뭐야?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a29a7713",
   "metadata": {
    "id": "a29a7713",
    "outputId": "120aef2d-a556-4b23-f7b1-44397b4d62a7",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706494433703,
     "user_tz": -540,
     "elapsed": 10382,
     "user": {
      "displayName": "김지한",
      "userId": "10014313508394759418"
     }
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'question': '월 플라이 아이디어는 어떻게 시작되었어?',\n",
       " 'chat_history': [SystemMessage(content='The human asks what the important topic is. The AI believes that the important topic in the given context is the mention of Ferrari and his works. The discussion has repeatedly mentioned his works and exhibitions, as well as concerns and fears about international exhibitions. Therefore, Ferrari and his works appear to be an important topic.')],\n",
       " 'answer': '\"저의 월 플라워 아이디어는 그렇게 시작되었죠. 수지로 주조한 차에 레이저 가공 알루미늄 꽃잎, 가루 코팅 그리고 세 번째 에디션은 보이지 않는 전선에 매달려 있습니다.\"'}"
      ]
     },
     "metadata": {},
     "execution_count": 51
    }
   ],
   "source": [
    "qa(\"월 플라이 아이디어는 어떻게 시작되었어?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "1qPBDegQBhyCJ_ODsOypxLZ5uKg0jXlfy",
     "timestamp": 1706490918527
    },
    {
     "file_id": "https://github.com/langchain-ai/langchain/blob/master/docs/docs/use_cases/chatbots.ipynb",
     "timestamp": 1701660629860
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
