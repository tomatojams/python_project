{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "### 구글 드라이브 연결"
   ],
   "metadata": {
    "id": "AvGJfn3fKnIh"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "dhBepVQ7kaYa",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "1dc42c0b-48ba-4222-9b7a-bfe423d09133",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:56:26.042940200Z",
     "start_time": "2024-02-08T13:56:26.028755800Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 필수 설치 라이브러리"
   ],
   "metadata": {
    "id": "69rCi1LbKlkz"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# !pip install -U langchain openai"
   ],
   "metadata": {
    "id": "E5cSH-P7kDDf",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0dd705a2-7f1f-4fee-feab-a5c13ba1db36",
    "ExecuteTime": {
     "end_time": "2024-02-08T13:56:27.370096600Z",
     "start_time": "2024-02-08T13:56:27.356175700Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from typing import Dict, List\n",
    "\n",
    "from langchain.chains import ConversationChain, LLMChain, LLMRouterChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from pydantic import BaseModel"
   ],
   "metadata": {
    "id": "k9S8nGKhkF5O",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:14.596322Z",
     "start_time": "2024-02-08T15:25:13.435345Z"
    }
   },
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### API 키 입력"
   ],
   "metadata": {
    "id": "X4k4IQXLKqJd"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "# 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\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "metadata": {
    "id": "IF5T5HPykHoL",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "fdea00c0-bca2-4d4c-9465-9c0febcbd237",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:28.194151Z",
     "start_time": "2024-02-08T15:25:25.399462Z"
    }
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### LLM 파트 구현\n",
    "* 게임룰에 대한 정보들을 얻는 방법을 프롬프트 체인을 이용해 구성했습니다.\n",
    "* 부루마블이라는 보드게임을 진행하기위한 기본적인 rule과 건물을 지을 수 있는 규칙이 들어간 데이터를 이용해서 문답을 진행합니다."
   ],
   "metadata": {
    "id": "Q-JehMyJK4OB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "PATH = \"./chain_prompts\"\n",
    "RULE_1 = os.path.join(\n",
    "    PATH, \"game_basic.txt\"\n",
    ")\n",
    "RULE_2 = os.path.join(\n",
    "    PATH, \"game_building.txt\"\n",
    ")\n",
    "INTRO = os.path.join(\n",
    "    PATH, \"intro.txt\"\n",
    ")\n",
    "\n",
    "\n",
    "def read_prompt_template(file_path: str) -> str:\n",
    "    with open(file_path, \"r\", encoding='UTF8') as f:\n",
    "        prompt_template = f.read()\n",
    "\n",
    "    return prompt_template\n",
    "\n",
    "\n",
    "def create_chain(llm, template_path, output_key):\n",
    "    return LLMChain(\n",
    "        llm=llm,\n",
    "        prompt=ChatPromptTemplate.from_template(\n",
    "            template=read_prompt_template(template_path)\n",
    "        ),\n",
    "        output_key=output_key,\n",
    "        verbose=True,\n",
    "    )\n",
    "\n",
    "\n",
    "llm = ChatOpenAI(temperature=0.1, max_tokens=200, model=\"gpt-3.5-turbo\")\n",
    "\n",
    "rule_1 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=RULE_1,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "rule_2 = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=RULE_2,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "intro = create_chain(\n",
    "    llm=llm,\n",
    "    template_path=INTRO,\n",
    "    output_key=\"text\",\n",
    ")\n",
    "\n",
    "\n",
    "destinations = [\n",
    "    \"basic: This page describes the basic rules used to play the board game Burumble.\",\n",
    "    \"building: This is where you'll find the rules for buildings as you play the board game.\",\n",
    "    \"into_myself: This is where you'll find the introduction of myself.\",\n",
    "    \"philosophy_myself: 데카트르철학.\",\n",
    "    \"philosophy_Confucius: This is where you'll find the philosophy of Confucius.\",\n",
    "]\n",
    "destinations = \"\\n\".join(destinations)\n",
    "router_prompt_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations=destinations)\n",
    "router_prompt = PromptTemplate.from_template(\n",
    "    template=router_prompt_template, output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt, verbose=True)\n",
    "\n",
    "multi_prompt_chain = MultiPromptChain( # 멀티프롬프트체인 라우터체인과 데이터네이션 체인 그리고 디펄트체의 합체\n",
    "    router_chain=router_chain, # 라우터를 쓰면서 텍스트양이 반으로 줄어듬 정확도도 올라감\n",
    "\n",
    "    destination_chains={\n",
    "    \"basic\": rule_1,\n",
    "    \"building\": rule_2,\n",
    "    \"into_myself\": intro, # 소개를 질문받으면 답변합니다.\n",
    "},\n",
    "\n",
    "    default_chain=ConversationChain(llm=llm, output_key=\"text\"),\n",
    ")\n",
    "\n",
    "\n",
    "class UserRequest(BaseModel):\n",
    "    user_message: str\n",
    "\n",
    "\n",
    "def gernerate_answer(req: UserRequest) -> Dict[str, str]:\n",
    "    context = req.dict()\n",
    "    context[\"input\"] = context[\"user_message\"]\n",
    "    answer = multi_prompt_chain.run(context)\n",
    "\n",
    "    return {\"answer\": answer}"
   ],
   "metadata": {
    "id": "5fnHwrb3myFZ",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:31.306005Z",
     "start_time": "2024-02-08T15:25:30.963840Z"
    }
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### User 데이터 입력\n",
    "* 유저 데이터 입력 후 결과를 확인 합니다."
   ],
   "metadata": {
    "id": "1uFhqhFLLdA_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "user_data = {\n",
    "    \"user_message\": \" 너는 뭘 할수있어?\"\n",
    "}"
   ],
   "metadata": {
    "id": "BmhMK-FlDVgO",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:32.626939Z",
     "start_time": "2024-02-08T15:25:32.621966Z"
    }
   },
   "execution_count": 4,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "request_instance = UserRequest(**user_data)"
   ],
   "metadata": {
    "id": "EThoAGelDMeJ",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:33.294063Z",
     "start_time": "2024-02-08T15:25:33.284546Z"
    }
   },
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "gernerate_answer(request_instance)"
   ],
   "metadata": {
    "id": "hhqWB9SxDPQM",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b5db86d6-cdb7-458f-986f-f3ff981c3b4f",
    "ExecuteTime": {
     "end_time": "2024-02-08T15:25:39.472535Z",
     "start_time": "2024-02-08T15:25:33.777925Z"
    }
   },
   "execution_count": 6,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/sv3y8crx3jx6kn5k220bs8bh0000gn/T/ipykernel_43020/200149230.py:82: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  context = req.dict()\n",
      "/Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n",
      "/Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages/langchain/chains/llm.py:316: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMRouterChain chain...\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n",
      "\n",
      "\n",
      "\u001B[1m> Entering new LLMChain chain...\u001B[0m\n",
      "Prompt after formatting:\n",
      "\u001B[32;1m\u001B[1;3mHuman: 소개\n",
      "\n",
      "자세히 묻지 않는다면, 3문장 이내로만 소개를 하자.\n",
      "챗봇이라는 용어는 되도록 쓰지말고, 친절한 당신의 인공지능 비서라고 생각해주세요.라는 식으로 표현하자.\n",
      "저는 인공지능으로 상담심리사를 연결하고 추천해주는 친절한 역할을 합니다.\n",
      "다만 가벼운 대화나, 상담사와의 대화를 통해 더 나은 방향으로 나아가는데 도움이 되는 정보를 제공할 수 있습니다.\n",
      "\n",
      "[message]\n",
      "너는 뭘 할수있어?\n",
      "\n",
      "Answer:\u001B[0m\n",
      "\n",
      "\u001B[1m> Finished chain.\u001B[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'answer': '저는 인공지능으로 상담심리사를 연결하고 추천해주는 역할을 합니다. 또한 가벼운 대화나 도움이 되는 정보를 제공할 수 있습니다.'}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
