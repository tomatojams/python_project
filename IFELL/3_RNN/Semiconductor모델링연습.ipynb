{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "gpuType": "T4"
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  },
  "accelerator": "GPU",
  "gpuClass": "standard"
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "THNjjG50BYJY"
   },
   "source": [
    "# 반도체 박막 두께 분석\n",
    "\n",
    "### 배경\n",
    "\n",
    "최근 고사양 반도체 수요가 많아지면서 반도체를 수직으로 적층하는 3차원 공정이 많이 연구되고 있습니다. 반도체 박막을 수십 ~ 수백 층 쌓아 올리는 공정에서는 박막의 결함으로 인한 두께와 균일도가 저하되는 문제가 있습니다. 이는 소자 구조의 변형을 야기하며 성능 하락의 주요 요인이 됩니다. 이를 사전에 방지하기 위해서는 박막의 두께를 빠르면서도 정확히 측정하는 것이 중요합니다.\n",
    "\n",
    "박막의 두께를 측정하기 위해 광스펙트럼 분석이 널리 사용되고 있습니다. 하지만 광 스펙트럼을 분석하기 위해서는 관련 지식을 많이 가진 전문가가 필요하며 분석과정에 많은 컴퓨팅자원이 필요합니다. 빅데이터 분석을 통해 이를 해결하고자 반도체 소자의 두께 분석 알고리즘 경진대회를 개최합니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8XN-kkqUGNko"
   },
   "source": [
    "### 배경 자료\n",
    "\n",
    "반도체 박막은 얇은 반도체 막으로 박막의 종류와 두께는 반도체 소자의 특성을 결정짓는 중요한 요소 중 하나입니다. 박막의 두께를 측정하는 방법으로 반사율 측정이 널리 사용되며 반사율은 입사광 세기에 대한 반사광 세기의 비율로 정해집니다. (반사율 = 반사광/입사광) 반사율은 빛의 파장에 따라 변하며 파장에 따른 반사율의 분포를 반사율 스펙트럼이라고 합니다.\n",
    "\n",
    "\n",
    "\n",
    "### 구조 설명\n",
    "\n",
    "이번 대회에서 분석할 소자는 질화규소(layer_1)/이산화규소(layer_2)/질화규소(layer_3)/이산화규소(layer_4)/규소(기판) 총 5층 구조로 되어 있습니다. 대회의 목적은 기판인 규소를 제외한 layer_1 ~ layer_4의 두께를 예측하는 것으로 학습 데이터 파일에는 각 층의 두께와 반사율 스펙트럼이 포함되어 있습니다.\n",
    "\n",
    "\n",
    "\n",
    "### 데이터 설명\n",
    "\n",
    "train.csv 파일에는 4층 박막의 두께와 파장에 따른 반사율 스펙트럼이 주어집니다. 헤더의 이름에 따라 layer_1 ~ 4는 해당 박막의 두께,\n",
    "\n",
    "데이터값인 0 ~ 225은 빛의 파장에 해당하는 반사율이 됩니다. 헤더 이름인 0~225은 파장을 뜻하며 비식별화 처리가 되어있어 실제 값과는 다릅니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VHebfq47CZ-V",
    "ExecuteTime": {
     "end_time": "2024-01-09T12:55:17.227508300Z",
     "start_time": "2024-01-09T12:55:14.077747300Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from tensorflow.keras.layers import Dense, Conv2D, SeparableConv2D, Flatten, Dropout, MaxPooling2D, \\\n",
    "    BatchNormalization, ReLU, GlobalAveragePooling2D\n",
    "from tensorflow.keras import regularizers"
   ],
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ATOrWJKuLlBT",
    "ExecuteTime": {
     "end_time": "2024-01-09T12:55:17.242693200Z",
     "start_time": "2024-01-09T12:55:17.228510800Z"
    }
   },
   "source": [
    "use_colab = True\n",
    "assert use_colab in [True, False]"
   ],
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "lsFNOIeSn_Z9",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "37988dff-1a80-48ab-d9c2-ffcbb3369039",
    "ExecuteTime": {
     "end_time": "2024-01-09T12:55:18.281634300Z",
     "start_time": "2024-01-09T12:55:17.244198700Z"
    }
   },
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mgoogle\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcolab\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m drive\n\u001B[0;32m      2\u001B[0m drive\u001B[38;5;241m.\u001B[39mmount(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m/content/drive\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mModuleNotFoundError\u001B[0m: No module named 'google.colab'"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7qoXy0bqBqKt"
   },
   "source": [
    "### 데이터 로드\n",
    "* 새로운 버전의 Colab파일에선 왼쪽의 폴더 tree에서 직접 드라이브 마운트를 진행해야합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "kwp9HSrrD4XW",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "b082f9c2-d790-44fb-fdf5-ed7a4a807b8a",
    "ExecuteTime": {
     "end_time": "2024-01-09T05:41:50.643274Z",
     "start_time": "2024-01-09T05:41:50.076440Z"
    }
   },
   "source": [
    "train_d = np.load(\"/content/drive/MyDrive/Colab Notebooks/IFELL/data/semicon_train_data.npy\")\n",
    "test_d = np.load(\"/content/drive/MyDrive/Colab Notebooks/IFELL/data/semicon_test_data.npy\")\n",
    "\n",
    "# train data path\n",
    "# train_d = np.load(\"./semicon_train_data.npy\")\n",
    "\n",
    "# test data path\n",
    "# train_d = np.load(\"./semicon_test_data.npy\")\n",
    "print(train_d.shape, test_d.shape)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(729000, 230) (81000, 230)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "EHTnjvhZi4x9",
    "ExecuteTime": {
     "start_time": "2024-01-09T05:41:50.640258Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4968279d-725e-4e0c-a34a-735d1b2d626f"
   },
   "source": [
    "print(train_d[1].shape)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(230,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OsF_kurljuwU",
    "ExecuteTime": {
     "start_time": "2024-01-09T05:41:50.642087Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "5d7cd0fb-259d-45f4-ea38-0267ed92b2f3"
   },
   "source": [
    "print(test_d[0].shape)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(230,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "OdXgDw8oyTQf",
    "ExecuteTime": {
     "end_time": "2024-01-09T05:41:50.645418Z",
     "start_time": "2024-01-09T05:41:50.644664Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "953bc4eb-4a44-4b6a-d77a-409adf018192"
   },
   "source": [
    "# Raw Data 확인\n",
    "print(train_d[1000])\n",
    "# print(test_d[0])"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[7.00000000e+01 4.00000000e+01 1.50000000e+02 1.10000000e+02\n",
      " 4.02068880e-01 4.05173400e-01 4.22107550e-01 4.35197980e-01\n",
      " 4.66261860e-01 4.67785980e-01 4.76300870e-01 5.07203700e-01\n",
      " 5.23296600e-01 5.31541170e-01 5.23319200e-01 5.32340650e-01\n",
      " 5.38513840e-01 5.62478700e-01 5.74338900e-01 5.62083540e-01\n",
      " 5.83467800e-01 5.88462350e-01 5.89606940e-01 5.93186560e-01\n",
      " 5.93241930e-01 5.98241150e-01 5.87171000e-01 5.92055500e-01\n",
      " 6.06527860e-01 5.87087870e-01 5.94492100e-01 5.73233500e-01\n",
      " 5.94926300e-01 5.76777600e-01 5.70286300e-01 5.76913000e-01\n",
      " 5.52754400e-01 5.61735150e-01 5.52500000e-01 5.23800200e-01\n",
      " 5.11056840e-01 5.11732600e-01 4.92525460e-01 4.73373200e-01\n",
      " 4.57444160e-01 4.53428800e-01 4.19270130e-01 3.87709920e-01\n",
      " 3.87221520e-01 3.49848450e-01 3.16229370e-01 3.13858700e-01\n",
      " 2.80085700e-01 2.61263000e-01 2.30250820e-01 1.98457850e-01\n",
      " 1.53500440e-01 1.36026740e-01 1.08726785e-01 8.95344000e-02\n",
      " 6.58975300e-02 5.09539300e-02 3.69604570e-02 2.88708470e-02\n",
      " 1.54857090e-02 1.99594010e-02 2.33170990e-02 3.26487760e-02\n",
      " 5.89796340e-02 6.33707600e-02 9.20634640e-02 1.24182590e-01\n",
      " 1.63985540e-01 1.81501220e-01 2.16830660e-01 2.57668080e-01\n",
      " 2.86428720e-01 3.21613600e-01 3.65077380e-01 3.85984180e-01\n",
      " 4.33254400e-01 4.36655340e-01 4.60312520e-01 4.99771740e-01\n",
      " 5.03849100e-01 5.48682200e-01 5.58029060e-01 5.62947630e-01\n",
      " 5.99234340e-01 5.96399550e-01 6.04513000e-01 6.19093400e-01\n",
      " 6.38402700e-01 6.64816900e-01 6.56996000e-01 6.66098600e-01\n",
      " 6.69130500e-01 6.70661600e-01 6.80202360e-01 6.92821600e-01\n",
      " 6.96852400e-01 7.02015160e-01 7.00507460e-01 7.00250800e-01\n",
      " 7.11669300e-01 6.96838260e-01 7.08974360e-01 7.19114100e-01\n",
      " 7.18034700e-01 7.00589540e-01 7.05873250e-01 6.92893500e-01\n",
      " 7.14911160e-01 6.85250640e-01 6.82136830e-01 6.81311400e-01\n",
      " 6.78019200e-01 6.67259900e-01 6.78185700e-01 6.52875660e-01\n",
      " 6.34932940e-01 6.36031400e-01 6.16502100e-01 5.91461400e-01\n",
      " 5.74673350e-01 5.57246200e-01 5.42328200e-01 5.19422200e-01\n",
      " 5.03134850e-01 4.81939820e-01 4.45872100e-01 4.17206170e-01\n",
      " 4.05306970e-01 3.55970500e-01 3.27808440e-01 2.89738060e-01\n",
      " 2.44837760e-01 2.16494500e-01 1.69062380e-01 1.23260050e-01\n",
      " 1.03297760e-01 6.77379500e-02 3.89807700e-02 2.52380610e-02\n",
      " 2.59922780e-02 1.38827340e-02 1.90851740e-02 6.68724550e-02\n",
      " 7.21453900e-02 1.14929430e-01 1.77696590e-01 2.11153720e-01\n",
      " 2.55038900e-01 2.95599580e-01 3.21243700e-01 3.74151170e-01\n",
      " 3.91486200e-01 4.27665320e-01 4.61769700e-01 4.75576340e-01\n",
      " 4.78055980e-01 5.16503040e-01 5.30934450e-01 5.23902500e-01\n",
      " 5.51259300e-01 5.65235300e-01 5.67701600e-01 5.70858800e-01\n",
      " 5.76418300e-01 5.75021860e-01 6.01967200e-01 5.79546750e-01\n",
      " 5.81157900e-01 5.93576100e-01 5.84070600e-01 6.04394850e-01\n",
      " 5.87139800e-01 5.93731460e-01 5.91678200e-01 5.63344300e-01\n",
      " 5.69886800e-01 5.46404960e-01 5.43537260e-01 5.42394760e-01\n",
      " 5.42762940e-01 5.26218060e-01 4.89471520e-01 4.72608000e-01\n",
      " 4.59845570e-01 4.39476280e-01 4.24489440e-01 4.16756120e-01\n",
      " 4.11724180e-01 3.81418440e-01 3.60050380e-01 3.37973600e-01\n",
      " 3.20442830e-01 2.97488420e-01 2.85940900e-01 2.82688900e-01\n",
      " 2.78886770e-01 2.60735480e-01 2.64526520e-01 2.38374640e-01\n",
      " 2.46523140e-01 2.54422630e-01 2.63443470e-01 2.77559100e-01\n",
      " 3.05792480e-01 3.04755750e-01 3.47745950e-01 3.42683080e-01\n",
      " 3.59969050e-01 3.90264000e-01 4.21746500e-01 4.33448700e-01\n",
      " 4.50429620e-01 4.94950400e-01 4.90516330e-01 5.15429500e-01\n",
      " 5.46570300e-01 5.64438460e-01 5.68110800e-01 5.71491600e-01\n",
      " 5.81447660e-01 5.84012000e-01 6.05881900e-01 5.98874870e-01\n",
      " 5.97313170e-01 5.95610300e-01]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YJTUCIIAt01D"
   },
   "source": [
    "* 데이터를 분석하여 모델에 학습할 수 있는 형태로 정리합니다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "awmkQxq8sWsG",
    "ExecuteTime": {
     "start_time": "2024-01-09T05:41:50.644984Z"
    }
   },
   "source": [
    "train = train_d[:,4:] # 729000, 230 4번째 데이터부터 가져온다.\n",
    "label = train_d[:,:4]\n",
    "\n",
    "t_train = test_d[:,4:] # 81000, 230개 4번째 까지 데이터를 가져온다.\n",
    "t_label = test_d[:,:4]"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "u0Cb4BQPKqVs",
    "ExecuteTime": {
     "start_time": "2024-01-09T05:41:50.645341Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "32137641-c298-4191-b2df-13c523140e05"
   },
   "source": [
    "batch_size = 256\n",
    "\n",
    "# for train\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train, label))\n",
    "train_dataset = train_dataset.shuffle(10000).repeat().batch(batch_size=batch_size)\n",
    "print(train_dataset)\n",
    "\n",
    "# for test\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((t_train, t_label))\n",
    "test_dataset = test_dataset.batch(batch_size=batch_size)\n",
    "print(test_dataset)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 226), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.float64, name=None))>\n",
      "<_BatchDataset element_spec=(TensorSpec(shape=(None, 226), dtype=tf.float64, name=None), TensorSpec(shape=(None, 4), dtype=tf.float64, name=None))>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YsJ2qMl3Bryb"
   },
   "source": [
    "### 모델 구성\n",
    "* 현재 가장 간단한 모델로 구성되어 있습니다.\n",
    "* 데이터셋 자체를 가장 잘 학습할 수 있는 모델을 구현해 학습을 진행합니다."
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "from tensorflow.keras import layers, regularizers, models\n",
    "import tensorflow as tf\n",
    "\n",
    "# 클래스버젼 - Seperable Conv2D\n",
    "class ResBlock(tf.keras.Model):\n",
    "    def __init__(self, num_filter, stride=1, kernel_size=3, l2_reg=1e-4, dim = None):\n",
    "        super(ResBlock, self).__init__()\n",
    "        self.num_filter = num_filter\n",
    "        self.dim = dim\n",
    "        # print(self.dim,self.num_filter)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(num_filter, kernel_size, strides=stride, padding='same',\n",
    "                                   kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                   kernel_regularizer=regularizers.l2(0.001))\n",
    "        self.se_conv1 = layers.SeparableConv2D(num_filter, kernel_size, padding='same',\n",
    "                                               depthwise_initializer=tf.keras.initializers.he_normal(),\n",
    "                                               pointwise_initializer=tf.keras.initializers.he_normal(),\n",
    "                                               depthwise_regularizer=regularizers.l2(0.001),\n",
    "                                               pointwise_regularizer=regularizers.l2(0.001))\n",
    "        self.se_sonv2 = layers.SeparableConv2D(num_filter, kernel_size, padding='same',\n",
    "                                               depthwise_initializer=tf.keras.initializers.he_normal(),\n",
    "                                               pointwise_initializer=tf.keras.initializers.he_normal(),\n",
    "                                               depthwise_regularizer=regularizers.l2(0.001),\n",
    "                                               pointwise_regularizer=regularizers.l2(0.001))\n",
    "        self.con_short = layers.Conv2D(num_filter, 1, strides=2, padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.bn_short = layers.BatchNormalization()\n",
    "        self.LSTM = tf.keras.layers.LSTM(dim*dim)\n",
    "        self.LSTM2 = tf.keras.layers.LSTM(dim*dim)\n",
    "        # self.con1d_1 = layers.Conv2D()\n",
    "\n",
    "    def call(self, input, stride=1, dim=None):\n",
    "        self.dim = dim\n",
    "        shortcut = input\n",
    "        x = self.conv1(input)\n",
    "\n",
    "        x = self.bn1(x)\n",
    "        x = layers.Activation('relu')(x)\n",
    "\n",
    "\n",
    "        print(\"변환하기전:\",x.shape, dim, self.num_filter,stride)\n",
    "        RNN_x = layers.Reshape(target_shape=(-1, dim * dim * self.num_filter))(x) # 컨볼루션을 쓰기위한 변환 (64,4) -> CNN1D또는 RNN 사용가능 256,1도 가능\n",
    "        print(\"변환후:\",RNN_x.shape)\n",
    "        RNN_x = self.LSTM(RNN_x,return_sequences=True)\n",
    "        RNN_x = self.LSTM2(RNN_x,return_sequences=False)\n",
    "\n",
    "        print(\"LSTM후:\",RNN_x.shape)\n",
    "        RNN_x = layers.Reshape(target_shape=(dim,dim,1))(RNN_x)  # RNN_x 리쉐이프\n",
    "        print(\"재변환후:\",RNN_x.shape)\n",
    "        C1D_x = RNN_x\n",
    "\n",
    "\n",
    "        x = self.se_conv1(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.se_sonv2(x)\n",
    "        x = self.bn3(x)\n",
    "\n",
    "        # 입력과 출력의 맞도록 숏컷을 조절\n",
    "        if shortcut.shape[-1] != self.num_filter or stride != 1:\n",
    "            shortcut = self.con_short(shortcut)\n",
    "            shortcut = self.bn_short(shortcut)\n",
    "\n",
    "        x = layers.Add()([x, shortcut])\n",
    "        # print(\"add후:\",x.shape)\n",
    "        x = layers.Activation('relu')(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class ResNet28(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(ResNet28, self).__init__()\n",
    "        self.dim = None  # dim 초기화\n",
    "\n",
    "        self.conv1 = layers.Conv2D(64, 7, strides=2,\n",
    "                                   kernel_initializer=tf.keras.initializers.he_normal(),\n",
    "                                   padding='same')\n",
    "        self.bn1 = layers.BatchNormalization()\n",
    "        self.bn2 = layers.BatchNormalization()\n",
    "        self.bn3 = layers.BatchNormalization()\n",
    "        self.relu1 = layers.ReLU()\n",
    "        self.relu2 = layers.ReLU()\n",
    "\n",
    "        self.blocks = [\n",
    "            ResBlock(64, stride=1, dim = 8),\n",
    "            ResBlock(128, stride=2, dim = 4),\n",
    "            ResBlock(256, stride=2, dim = 2),\n",
    "            ResBlock(256, stride=1, dim = 2),\n",
    "            ResBlock(512, stride=2, dim = 1)\n",
    "        ]\n",
    "\n",
    "        self.avg_pool = layers.GlobalAveragePooling2D()\n",
    "        self.dropout = layers.Dropout(0.5)\n",
    "        self.out = layers.Dense(4)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        x = layers.Dense(16 * 16 * 1)(inputs)\n",
    "        x = layers.Reshape(target_shape=(16, 16, 1))(x)  # 컨볼루션을 쓰기위한 변환 (64,4) -> CNN1D또는 RNN 사용가능 256,1도 가능\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu1(x)  # 8x8*64\n",
    "\n",
    "\n",
    "        x = self.blocks[0](x,dim=8)\n",
    "        x = self.blocks[1](x,dim=4)\n",
    "        x = self.blocks[2](x,dim =2)\n",
    "        x = self.blocks[3](x,dim =2)\n",
    "        x = self.blocks[4](x,dim =1)\n",
    "        x = self.avg_pool(x)\n",
    "        x = layers.Dense(1000)(x)\n",
    "        # x =  x = layers.Reshape(target_shape=(1))(x)\n",
    "        # x = layers.LSTM(64)(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.out(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "# Specify input shape and number of classes\n",
    "input_tensor = layers.Input(shape=(226,))  # Example input shape for image classification\n",
    "\n",
    "# Build ResNet model\n",
    "Res = ResNet28()\n",
    "output_tensor = Res.call(input_tensor)\n",
    "model = tf.keras.Model(inputs=input_tensor, outputs=output_tensor)\n",
    "\n",
    "# Display model summary\n",
    "model.summary()\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 725
    },
    "id": "j5z-Mwys0HJK",
    "outputId": "571d04b1-5e3d-4b41-f6f0-66aa6bf1a669"
   },
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "변환하기전: (None, 8, 8, 64) 8 64 1\n",
      "변환후: (None, 1, 4096)\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "Exception encountered when calling layer \"res_block_85\" (type ResBlock).\n\nin user code:\n\n    File \"<ipython-input-38-76154f98e10c>\", line 46, in call  *\n        RNN_x = self.LSTM(RNN_x,return_sequences=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_rnn.py\", line 556, in __call__  **\n        return super().__call__(inputs, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: LSTM.call() got an unexpected keyword argument 'return_sequences'\n\n\nCall arguments received by layer \"res_block_85\" (type ResBlock):\n  • input=tf.Tensor(shape=(None, 8, 8, 64), dtype=float32)\n  • stride=1\n  • dim=8",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-38-76154f98e10c>\u001B[0m in \u001B[0;36m<cell line: 127>\u001B[0;34m()\u001B[0m\n\u001B[1;32m    125\u001B[0m \u001B[0;31m# Build ResNet model\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    126\u001B[0m \u001B[0mRes\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mResNet28\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 127\u001B[0;31m \u001B[0moutput_tensor\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mRes\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcall\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    128\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mtf\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mkeras\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mModel\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0minputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0minput_tensor\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0moutputs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0moutput_tensor\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    129\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-38-76154f98e10c>\u001B[0m in \u001B[0;36mcall\u001B[0;34m(self, inputs)\u001B[0m\n\u001B[1;32m    103\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    104\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 105\u001B[0;31m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m0\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m8\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    106\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m4\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    107\u001B[0m         \u001B[0mx\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mblocks\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mdim\u001B[0m \u001B[0;34m=\u001B[0m\u001B[0;36m2\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     68\u001B[0m             \u001B[0;31m# To get the full stack trace, call:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     69\u001B[0m             \u001B[0;31m# `tf.debugging.disable_traceback_filtering()`\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 70\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mwith_traceback\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mfiltered_tb\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     71\u001B[0m         \u001B[0;32mfinally\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     72\u001B[0m             \u001B[0;32mdel\u001B[0m \u001B[0mfiltered_tb\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/tmp/__autograph_generated_filel7y6c_wo.py\u001B[0m in \u001B[0;36mtf__call\u001B[0;34m(self, input, stride, dim)\u001B[0m\n\u001B[1;32m     16\u001B[0m                 \u001B[0mRNN_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlayers\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mReshape\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtarget_shape\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m-\u001B[0m\u001B[0;36m1\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mdim\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m*\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnum_filter\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mx\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m                 \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'변환후:'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRNN_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m                 \u001B[0mRNN_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLSTM\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRNN_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreturn_sequences\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mTrue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m                 \u001B[0mRNN_x\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mconverted_call\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mLSTM2\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m(\u001B[0m\u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRNN_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mdict\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mreturn_sequences\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;32mFalse\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mfscope\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m                 \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mprint\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m'LSTM후:'\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mag__\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mld\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mRNN_x\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mshape\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTypeError\u001B[0m: Exception encountered when calling layer \"res_block_85\" (type ResBlock).\n\nin user code:\n\n    File \"<ipython-input-38-76154f98e10c>\", line 46, in call  *\n        RNN_x = self.LSTM(RNN_x,return_sequences=True)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/base_rnn.py\", line 556, in __call__  **\n        return super().__call__(inputs, **kwargs)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n\n    TypeError: LSTM.call() got an unexpected keyword argument 'return_sequences'\n\n\nCall arguments received by layer \"res_block_85\" (type ResBlock):\n  • input=tf.Tensor(shape=(None, 8, 8, 64), dtype=float32)\n  • stride=1\n  • dim=8"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "FaxFpBbxyUzv"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # 수직연산\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_tensor = layers.Input(shape=(226,))\n",
    "\n",
    "# # 목표 출력의 형태가 (batch_size, 4)인 경우에 맞춤\n",
    "# # target_shape = (16, 16, 4)\n",
    "\n",
    "# x = layers.Dense(8 * 8 * 4, activation='relu')(input_tensor)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x)\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(-1, 16 * 16 * 64))(x)\n",
    "# x = layers.LSTM(256)(x)\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x)\n",
    "\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)  # 목표 데이터 형태에 맞게 조정\n",
    "\n",
    "# model = models.Model(input_tensor, output_tensor)\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "id": "llyyseW9Pjtz"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # 컨벌루션 하고 병렬연산\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_tensor = layers.Input(shape=(226,))\n",
    "\n",
    "# # 목표 출력의 형태가 (batch_size, 4)인 경우에 맞춤\n",
    "# # target_shape = (16, 16, 4)\n",
    "\n",
    "# x_input = layers.Dense(8 * 8 * 4, activation='relu')(input_tensor)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x_input)\n",
    "# x_bi = layers.Conv2D(64, 3, padding='same',strides =2)(x)\n",
    "# # 8 * 8* 64 사이즈가 됨\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x_bi)\n",
    "\n",
    "\n",
    "# # 8* 8*64 사이즈를 계산해봄\n",
    "\n",
    "# x2 = layers.Reshape(target_shape=(-1, 8 * 8*64))(x_bi)\n",
    "# x2 = layers.LSTM(8*8*64)(x2)\n",
    "# x2 = layers.Reshape(target_shape=(8, 8, 64))(x2)\n",
    "\n",
    "# x = layers.add([x,x2])\n",
    "\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)  # 목표 데이터 형태에 맞게 조정\n",
    "\n",
    "# model = models.Model(input_tensor, output_tensor)\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "id": "mvbX3yprabj1"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # 컨벌루션 하고 병렬연산  - 작동하지만 사이즈가 너무 커짐\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_tensor = layers.Input(shape=(226,))\n",
    "\n",
    "# # 목표 출력의 형태가 (batch_size, 4)인 경우에 맞춤\n",
    "# # target_shape = (16, 16, 4)\n",
    "\n",
    "# x_input = layers.Dense(8 * 8 * 4, activation='relu')(input_tensor)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x_input)\n",
    "# x_bi = layers.Conv2D(64, 3, padding='same',strides =2)(x)\n",
    "# # 8 * 8* 64 사이즈가 됨\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x_bi)\n",
    "\n",
    "\n",
    "# # 8* 8*64 사이즈를 계산해봄\n",
    "\n",
    "# x2 = layers.Reshape(target_shape=(-1, 8 * 8*64))(x_bi)\n",
    "# x2 = layers.LSTM(8*8*64)(x2)\n",
    "# x2 = layers.Reshape(target_shape=(8, 8, 64))(x2)\n",
    "\n",
    "# x = layers.add([x,x2])\n",
    "\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)  # 목표 데이터 형태에 맞게 조정\n",
    "\n",
    "# model = models.Model(input_tensor, output_tensor)\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "id": "vqLh5Q0Ygpmi"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # 컨벌루션 하고 병렬연산\n",
    "\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_tensor = layers.Input(shape=(226,))\n",
    "\n",
    "# # 목표 출력의 형태가 (batch_size, 4)인 경우에 맞춤\n",
    "# # target_shape = (16, 16, 4)\n",
    "\n",
    "# x_input = layers.Dense(8 * 8 * 4, activation='relu')(input_tensor)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x_input)\n",
    "# x_bi = layers.Conv2D(64, 3, padding='same',strides =2)(x)\n",
    "# # 8 * 8* 64 사이즈가 됨\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x_bi)\n",
    "\n",
    "\n",
    "# # 8* 8*64 사이즈를 계산해봄\n",
    "\n",
    "# x2 = layers.Reshape(target_shape=(-1, 8 * 8*64))(x_bi)\n",
    "# x2 = layers.LSTM(8*8*64)(x2)\n",
    "# x2 = layers.Reshape(target_shape=(8, 8, 64))(x2)\n",
    "\n",
    "# x = layers.add([x,x2])\n",
    "\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)  # 목표 데이터 형태에 맞게 조정\n",
    "\n",
    "# model = models.Model(input_tensor, output_tensor)\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "id": "-IxAf9ROabuK"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # 컨벌루션 하고 병렬연산  - 사이즈 조절해서 add\n",
    "# from tensorflow.keras import layers, models\n",
    "\n",
    "# input_tensor = layers.Input(shape=(226,))\n",
    "\n",
    "# # 목표 출력의 형태가 (batch_size, 4)인 경우에 맞춤\n",
    "# # target_shape = (16, 16, 4)\n",
    "\n",
    "# x_input = layers.Dense(8 * 8 * 4, activation='relu')(input_tensor)\n",
    "\n",
    "# x = layers.Reshape(target_shape=(16, 16, 1))(x_input)\n",
    "# x_bi = layers.Conv2D(64, 3, padding='same',strides =2)(x)\n",
    "# # 8 * 8* 64 사이즈가 됨\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x_bi)\n",
    "\n",
    "\n",
    "# # 8* 8*64 사이즈를 계산해봄\n",
    "\n",
    "# x2 = layers.Reshape(target_shape=(-1, 8 * 8*64))(x_bi)\n",
    "# x2 = layers.LSTM(64)(x2) # 여기서 사이즈를 줄이면 됨\n",
    "# x2 = layers.Reshape(target_shape=(8, 8, 1))(x2)\n",
    "\n",
    "# x = layers.add([x,x2])\n",
    "\n",
    "\n",
    "# x = layers.Conv2D(64, 3, padding='same')(x)\n",
    "# x = layers.Flatten()(x)\n",
    "# x = layers.Dense(64, activation='relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)  # 목표 데이터 형태에 맞게 조정\n",
    "\n",
    "# model = models.Model(input_tensor, output_tensor)\n",
    "# model.summary()\n"
   ],
   "metadata": {
    "id": "KPGQ7dPlJrVf"
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "zzo9y_5eryuq"
   },
   "source": [
    "# input_tensor = layers.Input(shape=(226,))\n",
    "# # CNN1D, CNN2D, RNN 세가지를 사용해서 모델링\n",
    "\n",
    "# # 226에서 256으로 확장\n",
    "# x = layers.Dense(8*8*4, activation = 'relu')(input_tensor)\n",
    "\n",
    "# CNN_x = layers.Reshape(target_shape=(8,8,4))(x) # 컨볼루션을 쓰기위한 변환 (64,4) -> CNN1D또는 RNN 사용가능 256,1도 가능\n",
    "# RNN_x = layers.Reshape(target_shape=(256,1))(x)\n",
    "# Dense_x = RNN_x\n",
    "\n",
    "\n",
    "# x = tf.add([x, x_skip]) # batch, 128 + 226\n",
    "\n",
    "\n",
    "# x = layers.Dense(16,\n",
    "#                  kernel_initializer=tf.keras.initializers.HeUniform())(x)\n",
    "# x = layers.BatchNormalization()(x)\n",
    "# x = layers.Activation('relu')(x)\n",
    "\n",
    "# output_tensor = layers.Dense(4)(x)\n",
    "\n",
    "# model = tf.keras.Model(input_tensor, output_tensor)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a0OODMx4Btb5"
   },
   "source": [
    "### 모델 학습\n",
    "* 4개층의 박막의 두께를 예측하는 모델을 학습해봅시다."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YlhAzzfCLDQ0"
   },
   "source": [
    "# the save point\n",
    "if use_colab:\n",
    "    checkpoint_dir ='./drive/My Drive/train_ckpt/semiconductor/exp1'\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "else:\n",
    "    checkpoint_dir = 'semiconductor/exp1'\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "XaTHvzqjuCQS"
   },
   "source": [
    "model.compile(loss='mae', #mse\n",
    "              optimizer='adam',\n",
    "              metrics=['mae']) #mse"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "QUUO_VcoLJEg",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 691
    },
    "outputId": "afaffbf2-2e1a-46b6-c55c-da2af8be709e"
   },
   "source": [
    "history = model.fit(train_dataset,\n",
    "                    steps_per_epoch=len(train) / batch_size, # train data의 길이 // batch 길이\n",
    "                    epochs=100,\n",
    "                    validation_data=test_dataset,\n",
    "                    validation_steps=len(t_train) / batch_size)"
   ],
   "execution_count": null,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/100\n",
      "2847/2847 [==============================] - 144s 46ms/step - loss: 45.1224 - mae: 43.0011 - val_loss: 24.4495 - val_mae: 22.3852\n",
      "Epoch 2/100\n",
      "2847/2847 [==============================] - 129s 45ms/step - loss: 19.1239 - mae: 16.9415 - val_loss: 14.4015 - val_mae: 12.1665\n",
      "Epoch 3/100\n",
      "2847/2847 [==============================] - 127s 45ms/step - loss: 15.9719 - mae: 13.7223 - val_loss: 11.9006 - val_mae: 9.6540\n",
      "Epoch 4/100\n",
      "2847/2847 [==============================] - 125s 44ms/step - loss: 14.8461 - mae: 12.6107 - val_loss: 11.5326 - val_mae: 9.3103\n",
      "Epoch 5/100\n",
      "2847/2847 [==============================] - 125s 44ms/step - loss: 14.0892 - mae: 11.8947 - val_loss: 10.8097 - val_mae: 8.6468\n",
      "Epoch 6/100\n",
      "2847/2847 [==============================] - 127s 44ms/step - loss: 13.7291 - mae: 11.5750 - val_loss: 9.9873 - val_mae: 7.8578\n",
      "Epoch 7/100\n",
      "2847/2847 [==============================] - 127s 45ms/step - loss: 13.3597 - mae: 11.2578 - val_loss: 9.0205 - val_mae: 6.9487\n",
      "Epoch 8/100\n",
      "2847/2847 [==============================] - 127s 45ms/step - loss: 13.0244 - mae: 10.9859 - val_loss: 8.4199 - val_mae: 6.3988\n",
      "Epoch 9/100\n",
      "1606/2847 [===============>..............] - ETA: 55s - loss: 12.7746 - mae: 10.7754"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-22-ba8eaa36b220>\u001B[0m in \u001B[0;36m<cell line: 1>\u001B[0;34m()\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m history = model.fit(train_dataset,\n\u001B[0m\u001B[1;32m      2\u001B[0m                     \u001B[0msteps_per_epoch\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlen\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m/\u001B[0m \u001B[0mbatch_size\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;31m# train data의 길이 // batch 길이\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      3\u001B[0m                     \u001B[0mepochs\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0;36m100\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      4\u001B[0m                     \u001B[0mvalidation_data\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mtest_dataset\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      5\u001B[0m                     validation_steps=len(t_train) / batch_size)\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/utils/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     63\u001B[0m         \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     64\u001B[0m         \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 65\u001B[0;31m             \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     66\u001B[0m         \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     67\u001B[0m             \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py\u001B[0m in \u001B[0;36mfit\u001B[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[1;32m   1796\u001B[0m                 \u001B[0mcallbacks\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mon_epoch_begin\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mepoch\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1797\u001B[0m                 \u001B[0;32mwith\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcatch_stop_iteration\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1798\u001B[0;31m                     \u001B[0;32mfor\u001B[0m \u001B[0mstep\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0msteps\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1799\u001B[0m                         with tf.profiler.experimental.Trace(\n\u001B[1;32m   1800\u001B[0m                             \u001B[0;34m\"train\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/keras/src/engine/data_adapter.py\u001B[0m in \u001B[0;36msteps\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1409\u001B[0m             \u001B[0;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_insufficient_data\u001B[0m\u001B[0;34m:\u001B[0m  \u001B[0;31m# Set by `catch_stop_iteration`.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1410\u001B[0m                 \u001B[0;32mbreak\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1411\u001B[0;31m             \u001B[0moriginal_spe\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m_steps_per_execution\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitem\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1412\u001B[0m             can_run_full_execution = (\n\u001B[1;32m   1413\u001B[0m                 \u001B[0moriginal_spe\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m1\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mnumpy\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    687\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    688\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0mcontext\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mexecuting_eagerly\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 689\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mread_value\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    690\u001B[0m     raise NotImplementedError(\n\u001B[1;32m    691\u001B[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/resource_variable_ops.py\u001B[0m in \u001B[0;36mread_value\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    840\u001B[0m     \u001B[0;31m# Return an identity so it can get placed on whatever device the context\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    841\u001B[0m     \u001B[0;31m# specifies instead of the device where the variable is.\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 842\u001B[0;31m     \u001B[0;32mreturn\u001B[0m \u001B[0marray_ops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0midentity\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mvalue\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    843\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    844\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mread_value_no_copy\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/ops/weak_tensor_ops.py\u001B[0m in \u001B[0;36mwrapper\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m     86\u001B[0m   \u001B[0;32mdef\u001B[0m \u001B[0mwrapper\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     87\u001B[0m     \u001B[0;32mif\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mops\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mis_auto_dtype_conversion_enabled\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 88\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mop\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     89\u001B[0m     \u001B[0mbound_arguments\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0msignature\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mbind\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     90\u001B[0m     \u001B[0mbound_arguments\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mapply_defaults\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/traceback_utils.py\u001B[0m in \u001B[0;36merror_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m    148\u001B[0m     \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    149\u001B[0m     \u001B[0;32mtry\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 150\u001B[0;31m       \u001B[0;32mreturn\u001B[0m \u001B[0mfn\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m*\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m**\u001B[0m\u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    151\u001B[0m     \u001B[0;32mexcept\u001B[0m \u001B[0mException\u001B[0m \u001B[0;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    152\u001B[0m       \u001B[0mfiltered_tb\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0m_process_traceback_frames\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0me\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0m__traceback__\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m/usr/local/lib/python3.10/dist-packages/tensorflow/python/util/dispatch.py\u001B[0m in \u001B[0;36mop_dispatch_handler\u001B[0;34m(*args, **kwargs)\u001B[0m\n\u001B[1;32m   1252\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0miterable_params\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0;32mNone\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1253\u001B[0m           \u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mreplace_iterable_params\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0miterable_params\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m-> 1254\u001B[0;31m         \u001B[0mresult\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mapi_dispatcher\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mDispatch\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0margs\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mkwargs\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m   1255\u001B[0m         \u001B[0;32mif\u001B[0m \u001B[0mresult\u001B[0m \u001B[0;32mis\u001B[0m \u001B[0;32mnot\u001B[0m \u001B[0mNotImplemented\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m   1256\u001B[0m           \u001B[0;32mreturn\u001B[0m \u001B[0mresult\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Hcx7cdQgLWau"
   },
   "source": [
    "# np.save(\"file/path.npy\", history.numpy())\n",
    "# history = np.load(\"histoy.npy\", allow_pickle=True)\n",
    "\n",
    "loss=history.history['mae'] # mse\n",
    "val_loss=history.history['val_mae'] # val_mse\n",
    "\n",
    "epochs_range = range(len(loss))\n",
    "\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(epochs_range, loss, label='Training MAE') # MSE\n",
    "plt.plot(epochs_range, val_loss, label='Validation MAE') # MSE\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation MAE') # MSE\n",
    "plt.show()"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SIPmAVP1u9nX"
   },
   "source": [
    "### 모델 평가\n",
    "* Mean absolute error 를 이용해 모델이 정확히 예측하는지를 확인"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "VqsdquFJuKUv"
   },
   "source": [
    "# model.load_weights(checkpoint_dir)\n",
    "results = model.evaluate(test_dataset)\n",
    "print(\"MAE :\", results[0]) # MAE"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "1mWFZphNupHX"
   },
   "source": [],
   "execution_count": null,
   "outputs": []
  }
 ]
}
