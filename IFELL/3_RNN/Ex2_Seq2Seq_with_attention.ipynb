{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dXnewO5K2P8v"
   },
   "source": [
    "# Sequence to Sequence with attention\n",
    "\n",
    "### simple neural machine translation training\n",
    "\n",
    "* sequence to sequence\n",
    "  \n",
    "### Reference\n",
    "* [Sequence to Sequence Learning with Neural Networks](https://arxiv.org/abs/1409.3215)\n",
    "* [Effective Approaches to Attention-based Neural Machine Translation](https://arxiv.org/abs/1508.04025)\n",
    "* [Neural Machine Translation with Attention from Tensorflow](https://github.com/tensorflow/tensorflow/blob/master/tensorflow/contrib/eager/python/examples/nmt_with_attention/nmt_with_attention.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tnxXKDjq3jEL",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:26:38.085284Z",
     "start_time": "2024-01-08T06:26:38.014064Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.10.0\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from pprint import pprint\n",
    "import numpy as np\n",
    "import os\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1v0QRtYP2P8x",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:26:39.717118Z",
     "start_time": "2024-01-08T06:26:39.701623Z"
    }
   },
   "outputs": [],
   "source": [
    "sources = [['I', 'feel', 'hungry'],\n",
    "     ['tensorflow', 'is', 'very', 'difficult'],\n",
    "     ['tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning'],\n",
    "     ['tensorflow', 'is', 'very', 'fast', 'changing']]\n",
    "targets = [['나는', '배가', '고프다'],\n",
    "           ['텐서플로우는', '매우', '어렵다'],\n",
    "           ['텐서플로우는', '딥러닝을', '위한', '프레임워크이다'],\n",
    "           ['텐서플로우는', '매우', '빠르게', '변화한다']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "9Lnxjebz2P8x",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:31:45.428651Z",
     "start_time": "2024-01-08T06:31:45.397920Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'feel', 'hungry', 'tensorflow', 'is', 'very', 'difficult', 'tensorflow', 'is', 'a', 'framework', 'for', 'deep', 'learning', 'tensorflow', 'is', 'very', 'fast', 'changing']\n",
      "['<pad>', 'I', 'a', 'changing', 'deep', 'difficult', 'fast', 'feel', 'for', 'framework', 'hungry', 'is', 'learning', 'tensorflow', 'very']\n",
      "{'<pad>': 0,\n",
      " 'I': 1,\n",
      " 'a': 2,\n",
      " 'changing': 3,\n",
      " 'deep': 4,\n",
      " 'difficult': 5,\n",
      " 'fast': 6,\n",
      " 'feel': 7,\n",
      " 'for': 8,\n",
      " 'framework': 9,\n",
      " 'hungry': 10,\n",
      " 'is': 11,\n",
      " 'learning': 12,\n",
      " 'tensorflow': 13,\n",
      " 'very': 14}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for sources\n",
    "s_vocab = list(set(sum(sources, [])))\n",
    "s_vocab.sort()\n",
    "s_vocab = ['<pad>'] + s_vocab\n",
    "source2idx = {word : idx for idx, word in enumerate(s_vocab)}\n",
    "idx2source = {idx : word for idx, word in enumerate(s_vocab)}\n",
    "\n",
    "print(sum(sources,[]))\n",
    "print(s_vocab)\n",
    "pprint(source2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "PLEkSFg62P8y",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:11:58.308061Z",
     "start_time": "2024-01-08T06:11:58.291912Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'<bos>': 1,\n",
      " '<eos>': 2,\n",
      " '<pad>': 0,\n",
      " '고프다': 3,\n",
      " '나는': 4,\n",
      " '딥러닝을': 5,\n",
      " '매우': 6,\n",
      " '배가': 7,\n",
      " '변화한다': 8,\n",
      " '빠르게': 9,\n",
      " '어렵다': 10,\n",
      " '위한': 11,\n",
      " '텐서플로우는': 12,\n",
      " '프레임워크이다': 13}\n"
     ]
    }
   ],
   "source": [
    "# vocabulary for targets\n",
    "t_vocab = list(set(sum(targets, [])))\n",
    "t_vocab.sort()\n",
    "t_vocab = ['<pad>', '<bos>', '<eos>'] + t_vocab\n",
    "target2idx = {word : idx for idx, word in enumerate(t_vocab)}\n",
    "idx2target = {idx : word for idx, word in enumerate(t_vocab)}\n",
    "\n",
    "pprint(target2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LlbM-VVI2P8y",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:12:00.187535Z",
     "start_time": "2024-01-08T06:12:00.151802Z"
    }
   },
   "outputs": [],
   "source": [
    "def preprocess(sequences, max_len, dic, mode = 'source'):\n",
    "    assert mode in ['source', 'target'], 'source와 target 중에 선택해주세요.'\n",
    "    \"\"\"\n",
    "     시퀀스 데이터를 전처리하는 함수\n",
    "    \n",
    "     Parameters:\n",
    "     - sequences: 입력 시퀀스 데이터\n",
    "     - max_len: 패딩 후의 최대 길이\n",
    "     - dic: 토큰을 정수로 매핑하는 딕셔너리\n",
    "     - mode: 'source' 또는 'target' 중 하나 선택\n",
    "    \n",
    "     Returns:\n",
    "     - 'source' 모드일 경우:\n",
    "         - s_len: 각 문장의 길이를 담은 리스트\n",
    "         - s_input: 패딩된 인코더 입력 시퀀스\n",
    "    \n",
    "     - 'target' 모드일 경우:\n",
    "         - t_len: 각 디코더 입력 시퀀스의 길이를 담은 리스트\n",
    "         - t_input: 패딩된 디코더 입력 시퀀스\n",
    "         - t_output: 패딩된 디코더 출력 시퀀스\n",
    "     \"\"\"\n",
    "    if mode == 'source':\n",
    "        #  # Source 모드 전처리 (인코더 입력)\n",
    "        s_input = list(map(lambda sentence : [dic.get(token) for token in sentence], sequences))\n",
    "        # 각 문장의 길이를 계산하여 리스트로 저장\n",
    "        # map(함수,인자) 따라서 함수를 sequences에 적용해서 중복업는 인덱스를가져옴 dic.get은 인덱스를 가져오는 함수\n",
    "        s_len = list(map(lambda sentence : len(sentence), s_input))\n",
    "        # 패딩 적용\n",
    "        s_input = pad_sequences(sequences = s_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "        # truncating 정해진 길이보다길면 뒤를 자른다\n",
    "        return s_len, s_input\n",
    "\n",
    "    elif mode == 'target':\n",
    "        # Target 모드 전처리 (디코더 입력 및 출력)\n",
    "        # 디코더 입력에는 '<bos>' (문장의 시작)를 추가하고, '<eos>' (문장의 끝)를 추가한 후에 토큰을 딕셔너리에서 매핑된 정수로 변환\n",
    "\n",
    "        t_input = list(map(lambda sentence : ['<bos>'] + sentence + ['<eos>'], sequences))\n",
    "        t_input = list(map(lambda sentence : [dic.get(token) for token in sentence], t_input))\n",
    "        # 각 디코더 입력 시퀀스의 길이를 계산하여 리스트로 저장    \n",
    "        t_len = list(map(lambda sentence : len(sentence), t_input))\n",
    "        # 패딩 적용\n",
    "        t_input = pad_sequences(sequences = t_input, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "\n",
    "        # 디코더 출력에는 '<eos>'를 추가한 후에 토큰을 딕셔너리에서 매핑된 정수로 변환\n",
    "        t_output = list(map(lambda sentence : sentence + ['<eos>'], sequences))\n",
    "        t_output = list(map(lambda sentence : [dic.get(token) for token in sentence], t_output))\n",
    "        t_output = pad_sequences(sequences = t_output, maxlen = max_len, padding = 'post', truncating = 'post')\n",
    "\n",
    "        return t_len, t_input, t_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "w5WK1IpO2P8y",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:12:02.288173Z",
     "start_time": "2024-01-08T06:12:02.274400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3, 4, 7, 5] [[ 1  7 10  0  0  0  0  0  0  0]\n",
      " [13 11 14  5  0  0  0  0  0  0]\n",
      " [13 11  2  9  8  4 12  0  0  0]\n",
      " [13 11 14  6  3  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for source\n",
    "s_max_len = 10\n",
    "s_len, s_input = preprocess(sequences = sources,\n",
    "                            max_len = s_max_len, dic = source2idx, mode = 'source')\n",
    "print(s_len, s_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "hTTAxTQC2P8y",
    "ExecuteTime": {
     "end_time": "2024-01-08T06:12:03.034525Z",
     "start_time": "2024-01-08T06:12:03.023392Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 5, 6, 6] [[ 1  4  7  3  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  6 10  2  0  0  0  0  0  0  0]\n",
      " [ 1 12  5 11 13  2  0  0  0  0  0  0]\n",
      " [ 1 12  6  9  8  2  0  0  0  0  0  0]] [[ 4  7  3  2  0  0  0  0  0  0  0  0]\n",
      " [12  6 10  2  0  0  0  0  0  0  0  0]\n",
      " [12  5 11 13  2  0  0  0  0  0  0  0]\n",
      " [12  6  9  8  2  0  0  0  0  0  0  0]]\n"
     ]
    }
   ],
   "source": [
    "# preprocessing for target\n",
    "t_max_len = 12\n",
    "t_len, t_input, t_output = preprocess(sequences = targets,\n",
    "                                      max_len = t_max_len, dic = target2idx, mode = 'target')\n",
    "print(t_len, t_input, t_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RaNOUELB2P8y"
   },
   "source": [
    "# hyper-param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50FP3fp12P8y"
   },
   "outputs": [],
   "source": [
    "# hyper-parameters\n",
    "epochs = 100\n",
    "batch_size = 4\n",
    "learning_rate = .005\n",
    "total_step = epochs / batch_size\n",
    "buffer_size = 100\n",
    "n_batch = buffer_size//batch_size\n",
    "embedding_dim = 32\n",
    "units = 128\n",
    "\n",
    "# input\n",
    "data = tf.data.Dataset.from_tensor_slices((s_len, s_input, t_len, t_input, t_output))\n",
    "data = data.shuffle(buffer_size = buffer_size)\n",
    "data = data.batch(batch_size = batch_size)\n",
    "# s_mb_len, s_mb_input, t_mb_len, t_mb_input, t_mb_output = iterator.get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZ3XMGuB2P8y"
   },
   "outputs": [],
   "source": [
    "def gru(units):\n",
    "    return tf.keras.layers.GRU(units,\n",
    "                               return_sequences=True,\n",
    "                               return_state=True,\n",
    "                               recurrent_activation='sigmoid',\n",
    "                               recurrent_initializer='glorot_uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_rmrOclB2P8y"
   },
   "outputs": [],
   "source": [
    "class Encoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, enc_units, batch_sz):\n",
    "        \"\"\"\n",
    "        Encoder 클래스 초기화\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: 어휘 사전 크기\n",
    "        - embedding_dim: 임베딩 차원\n",
    "        - enc_units: GRU 유닛 수\n",
    "        - batch_sz: 배치 크기\n",
    "        \"\"\"\n",
    "        super(Encoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.enc_units = enc_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.enc_units)\n",
    "\n",
    "    def call(self, x, hidden):\n",
    "        \"\"\"\n",
    "        Encoder의 호출 메서드\n",
    "\n",
    "        Parameters:\n",
    "        - x: 입력 시퀀스\n",
    "        - hidden: 초기 은닉 상태\n",
    "\n",
    "        Returns:\n",
    "        - output: GRU의 출력\n",
    "        - state: GRU의 상태\n",
    "        output: 각 시간 단계(time step)에서의 GRU 레이어의 출력을 나타냅니다. 시퀀스에 대한 정보\n",
    "        state: GRU 레이어의 최종 상태. 시퀀스 전체를 처리한 후의 은닉 상태입니다. 이는 다음 시간 단계의 초기 은닉 상태로 사용됩니다.\n",
    "        \"\"\"\n",
    "        x = self.embedding(x)\n",
    "        output, state = self.gru(x, initial_state=hidden)\n",
    "        # print(\"state: {}\".format(state.shape))\n",
    "        # print(\"output: {}\".format(state.shape))\n",
    "\n",
    "        return output, state\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        \"\"\"\n",
    "        초기 은닉 상태를 0으로 초기화하는 메서드\n",
    "\n",
    "        Returns:\n",
    "        - 초기화된 은닉 상태\n",
    "        \"\"\"\n",
    "        return tf.zeros((self.batch_sz, self.enc_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbZuThiK2P8z"
   },
   "outputs": [],
   "source": [
    "class Decoder(tf.keras.Model):\n",
    "    def __init__(self, vocab_size, embedding_dim, dec_units, batch_sz):\n",
    "        \"\"\"\n",
    "        Decoder 클래스 초기화\n",
    "\n",
    "        Parameters:\n",
    "        - vocab_size: 어휘 사전 크기\n",
    "        - embedding_dim: 임베딩 차원\n",
    "        - dec_units: GRU 유닛 수\n",
    "        - batch_sz: 배치 크기\n",
    "        \"\"\"\n",
    "        super(Decoder, self).__init__()\n",
    "        self.batch_sz = batch_sz\n",
    "        self.dec_units = dec_units\n",
    "        self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
    "        self.gru = gru(self.dec_units)\n",
    "        self.fc = tf.keras.layers.Dense(vocab_size)\n",
    "\n",
    "        # 어텐션을 위한 가중치 설정\n",
    "        self.W1 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.W2 = tf.keras.layers.Dense(self.dec_units)\n",
    "        self.V = tf.keras.layers.Dense(1)\n",
    "\n",
    "    def call(self, x, hidden, enc_output):\n",
    "        \"\"\"\n",
    "        Decoder의 호출 메서드\n",
    "\n",
    "        Parameters:\n",
    "        - x: 입력 시퀀스\n",
    "        - hidden: 초기 은닉 상태\n",
    "        - enc_output: 인코더의 출력\n",
    "\n",
    "        Returns:\n",
    "        - x: 디코더 출력\n",
    "        - state: 디코더의 상태\n",
    "        - attention_weights: 어텐션 가중치\n",
    "        \"\"\"\n",
    "        # enc_output shape == (batch_size, max_length, hidden_size)\n",
    "\n",
    "        # hidden shape == (batch_size, hidden size)\n",
    "        # hidden_with_time_axis shape == (batch_size, 1, hidden size)\n",
    "        # attention score 계산을 위해 차원 추가\n",
    "        hidden_with_time_axis = tf.expand_dims(hidden, 1)\n",
    "        # hidden을 확장해서 shape를 맞추기 위함\n",
    "\n",
    "        # score 계산: score = FC(tanh(FC(EO) + FC(H)))\n",
    "        # score shape == (batch_size, max_length, 1)\n",
    "        score = self.V(tf.nn.tanh(self.W1(enc_output) + self.W2(hidden_with_time_axis)))\n",
    "        # 아웃풋과 히든을 Dense로 묶어서 스코어를 계산\n",
    "        # attention weights 계산: softmax(score, axis=1)\n",
    "        # attention_weights shape == (batch_size, max_length, 1)\n",
    "        attention_weights = tf.nn.softmax(score, axis=1)\n",
    "        # 가중치를 계산\n",
    "        # context_vector 계산: context_vector = sum(attention weights * EO, axis=1)\n",
    "        # context_vector shape == (batch_size, hidden_size)\n",
    "        context_vector = attention_weights * enc_output\n",
    "        # 결과는 element-wise 곱셈이 적용된다.\n",
    "        # [[[0.2, 0.4, 0.6], [1.2, 1.5, 1.8], [0.7, 0.8, 0.9], [4.0, 4.4, 4.8]],  # 첫 번째 문장의 context_vector\n",
    "        #  [[1.3, 1.4, 1.5], [6.4, 6.8, 7.2], [3.8, 4.0, 4.2], [6.6, 6.9, 7.2]]]  # 두 번째 문장의 context_vector\n",
    "\n",
    "        # 여기서 각각의 가중치가 적용됨.\n",
    "        context_vector = tf.reduce_sum(context_vector, axis=1)\n",
    "        # 결과는 axis=1을 따라 각 문장에 대한 합이 계산된다.\n",
    "        # [[6.1, 7.1, 8.1],  # 첫 번째 문장의 context_vector\n",
    "        #  [18.1, 18.1, 18.6]]  # 두 번째 문장의 context_vector\n",
    "\n",
    "        # x shape after passing through embedding == (batch_size, 1, embedding_dim)\n",
    "        x = self.embedding(x)\n",
    "\n",
    "        # x shape after concatenation == (batch_size, 1, embedding_dim + hidden_size)\n",
    "        x = tf.concat([tf.expand_dims(context_vector, 1), x], axis=-1)\n",
    "\n",
    "        # concatenated vector를 GRU에 전달\n",
    "        output, state = self.gru(x)\n",
    "\n",
    "        # output shape == (batch_size * 1, hidden_size)\n",
    "        output = tf.reshape(output, (-1, output.shape[2]))\n",
    "\n",
    "        # output shape == (batch_size * 1, vocab)\n",
    "        x = self.fc(output)\n",
    "\n",
    "        return x, state, attention_weights\n",
    "\n",
    "    def initialize_hidden_state(self):\n",
    "        \"\"\"\n",
    "        초기 은닉 상태를 0으로 초기화하는 메서드\n",
    "\n",
    "        Returns:\n",
    "        - 초기화된 은닉 상태\n",
    "        \"\"\"\n",
    "        return tf.zeros((self.batch_sz, self.dec_units))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t03ZrnyG2P8z"
   },
   "outputs": [],
   "source": [
    "# Encoder와 Decoder 인스턴스 생성\n",
    "encoder = Encoder(len(source2idx), embedding_dim, units, batch_size)\n",
    "decoder = Decoder(len(target2idx), embedding_dim, units, batch_size)\n",
    "\n",
    "# 손실 함수 정의\n",
    "def loss_function(real, pred):\n",
    "    \"\"\"\n",
    "    손실 함수 정의\n",
    "\n",
    "    Parameters:\n",
    "    - real: 실제 값\n",
    "    - pred: 예측 값\n",
    "\n",
    "    Returns:\n",
    "    - 손실 값\n",
    "    \"\"\"\n",
    "    # 패딩된 부분에 대한 마스크 생성\n",
    "    mask = 1 - np.equal(real, 0)\n",
    "    # 0인 부분은 1이 되므로 패딩된 부분은 손실에 영향을 끼치지 않게 0인부분은 1로 만듬\n",
    "    # sparse_softmax_cross_entropy_with_logits를 이용한 손실 계산\n",
    "    loss_ = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=real, logits=pred) * mask\n",
    "    return tf.reduce_mean(loss_)\n",
    "\n",
    "# 옵티마이저 생성\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "\n",
    "# 체크포인트 생성 (Object-based saving)\n",
    "checkpoint_dir = './data_out/training_checkpoints'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, 'ckpt')\n",
    "checkpoint = tf.train.Checkpoint(optimizer=optimizer,\n",
    "                                 encoder=encoder,\n",
    "                                 decoder=decoder)\n",
    "\n",
    "# TensorBoard를 위한 로그 디렉토리 생성 및 작성기(writer) 생성\n",
    "summary_writer = tf.summary.create_file_writer(logdir=checkpoint_dir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pRIrxz4Y2P8z"
   },
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    # 전체데이타에 대해\n",
    "    # 초기 은닉 상태 초기화\n",
    "    hidden = encoder.initialize_hidden_state()\n",
    "    total_loss = 0\n",
    "\n",
    "    # 각미니배치에 대해 - 데이타를 불러옴\n",
    "    for i, (s_len, s_input, t_len, t_input, t_output) in enumerate(data):\n",
    "        loss = 0\n",
    "        # 그래디언트 계산을 위한 테이프 생성\n",
    "        with tf.GradientTape() as tape:\n",
    "            # 인코더에 소스 문장을 전달하여 출력 및 은닉 상태 획득\n",
    "            enc_output, enc_hidden = encoder(s_input, hidden)\n",
    "\n",
    "            # 디코더의 초기 은닉 상태 설정\n",
    "            dec_hidden = enc_hidden\n",
    "\n",
    "            # 디코더의 입력으로 시작 토큰('<bos>')을 추가\n",
    "            dec_input = tf.expand_dims([target2idx['<bos>']] * batch_size, 1)\n",
    "            \n",
    "            #[target2idx['<bos>']] * batch_size: <bos>(시작 토큰)에 해당하는 인덱스를 batch_size만큼 복제한 리스트를 생성합니다.\n",
    "            # 따라서 이 부분은 [<bos>, <bos>, ..., <bos>]와 같은 형태가 됩니다\n",
    "            #리스트를 1차원에서 2차원으로 차원을 확장합니다. 이렇게 하면 모양이 (batch_size, 1)인 텐서가 됩니다.\n",
    "\n",
    "             #Teacher Forcing 방법을 사용하여 디코더를 학습\n",
    "            for t in range(1, t_input.shape[1]): # t_input.shape[1]은 문장의 길이 (단어수)에서 -1만큼 첫부분만 뺌\n",
    "                # 디코더에 현재 입력과 은닉 상태 전달하여 예측값 획득\n",
    "                # 예측값, 어텐션 가중치\n",
    "                predictions, dec_hidden, _ = decoder(dec_input, dec_hidden, enc_output)\n",
    "                \n",
    "                # 손실 계산\n",
    "                loss += loss_function(t_input[:, t], predictions)\n",
    "\n",
    "                # 다음 입력으로는 현재 타임 스텝의 타겟 사용 (Teacher Forcing)\n",
    "                dec_input = tf.expand_dims(t_input[:, t], 1)\n",
    "\n",
    "        # 배치 손실 계산\n",
    "        batch_loss = (loss / int(t_input.shape[1]))\n",
    "\n",
    "        # 전체 손실 누적\n",
    "        total_loss += batch_loss\n",
    "\n",
    "        # 모든 모델 변수에 대한 그래디언트 계산\n",
    "        variables = encoder.variables + decoder.variables\n",
    "        gradient = tape.gradient(loss, variables)\n",
    "\n",
    "        # 그래디언트 업데이트\n",
    "        optimizer.apply_gradients(zip(gradient, variables))\n",
    "\n",
    "    # 일정 주기로 모델 저장 및 현재 손실 출력\n",
    "    if epoch % 10 == 0:\n",
    "        print('Epoch {} Loss {:.4f} Batch Loss {:.4f}'.format(epoch,\n",
    "                                                              total_loss / n_batch,\n",
    "                                                              batch_loss.numpy()))\n",
    "        checkpoint.save(file_prefix=checkpoint_prefix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dY09e0Vn2P8z"
   },
   "outputs": [],
   "source": [
    "def evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    attention_plot = np.zeros((max_length_targ, max_length_inp))\n",
    "\n",
    "#     sentence = preprocess_sentence(sentence)\n",
    "\n",
    "    inputs = [inp_lang[i] for i in sentence.split(' ')]\n",
    "    inputs = tf.keras.preprocessing.sequence.pad_sequences([inputs], maxlen=max_length_inp, padding='post')\n",
    "    inputs = tf.convert_to_tensor(inputs)\n",
    "\n",
    "    result = ''\n",
    "\n",
    "    hidden = [tf.zeros((1, units))]\n",
    "    enc_out, enc_hidden = encoder(inputs, hidden)\n",
    "\n",
    "    dec_hidden = enc_hidden\n",
    "    dec_input = tf.expand_dims([targ_lang['<bos>']], 0)\n",
    "\n",
    "    for t in range(max_length_targ):\n",
    "        predictions, dec_hidden, attention_weights = decoder(dec_input, dec_hidden, enc_out)\n",
    "\n",
    "        # storing the attention weigths to plot later on\n",
    "        attention_weights = tf.reshape(attention_weights, (-1, ))\n",
    "        attention_plot[t] = attention_weights.numpy()\n",
    "\n",
    "        predicted_id = tf.argmax(predictions[0]).numpy()\n",
    "\n",
    "        result += idx2target[predicted_id] + ' '\n",
    "\n",
    "        if idx2target.get(predicted_id) == '<eos>':\n",
    "            return result, sentence, attention_plot\n",
    "\n",
    "        # the predicted ID is fed back into the model\n",
    "        dec_input = tf.expand_dims([predicted_id], 0)\n",
    "\n",
    "    return result, sentence, attention_plot\n",
    "\n",
    "# result, sentence, attention_plot = evaluate(sentence, encoder, decoder, source2idx, target2idx,\n",
    "#                                             s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8uG8QrbY2P8z"
   },
   "outputs": [],
   "source": [
    "# function for plotting the attention weights\n",
    "def plot_attention(attention, sentence, predicted_sentence):\n",
    "    fig = plt.figure(figsize=(10,10))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    ax.matshow(attention, cmap='viridis')\n",
    "\n",
    "    fontdict = {'fontsize': 14}\n",
    "\n",
    "    ax.set_xticklabels([''] + sentence, fontdict=fontdict, rotation=90)\n",
    "    ax.set_yticklabels([''] + predicted_sentence, fontdict=fontdict)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_pxpnDnT2P8z"
   },
   "outputs": [],
   "source": [
    "def translate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ):\n",
    "    result, sentence, attention_plot = evaluate(sentence, encoder, decoder, inp_lang, targ_lang, max_length_inp, max_length_targ)\n",
    "\n",
    "    print('Input: {}'.format(sentence))\n",
    "    print('Predicted translation: {}'.format(result))\n",
    "\n",
    "    attention_plot = attention_plot[:len(result.split(' ')), :len(sentence.split(' '))]\n",
    "    plot_attention(attention_plot, sentence.split(' '), result.split(' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mT957h5F2P8z"
   },
   "outputs": [],
   "source": [
    "#restore checkpoint\n",
    "\n",
    "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "id": "nmr1javJ2P80"
   },
   "outputs": [],
   "source": [
    "sentence = 'I feel hungry'\n",
    "# sentence = 'tensorflow is a framework for deep learning'\n",
    "\n",
    "translate(sentence, encoder, decoder, source2idx, target2idx, s_max_len, t_max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XMvrLfbm2P80"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "private_outputs": true,
   "provenance": [
    {
     "file_id": "1C4fpM7_7IL8ZzF7Gc5abywqQjeQNS2-U",
     "timestamp": 1527858391290
    },
    {
     "file_id": "1pExo6aUuw0S6MISFWoinfJv0Ftm9V4qv",
     "timestamp": 1527776041613
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
