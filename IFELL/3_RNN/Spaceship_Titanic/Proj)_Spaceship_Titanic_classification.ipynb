{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Spaceship Titanic with DL\n",
    "### 배경\n",
    "* 우주의 미스터리를 풀기 위해 데이터 과학 기술이 필요한 2912년에 오신 것을 환영합니다. 4광년 떨어진 곳에서 전송을 받았는데 상태가 좋지 않습니다.\n",
    "\n",
    "* 우주선 타이타닉은 한 달 전에 발사된 성간 여객선이었습니다. 약 13,000명의 승객을 태운 이 선박은 우리 태양계에서 가까운 별을 도는 새로 거주 가능한 세 개의 외계 행성으로 이민자들을 수송하는 첫 항해를 시작했습니다.\n",
    "\n",
    "* 첫 번째 목적지인 55 Cancri E로 가는 도중 Alpha Centauri를 돌던 중 부주의한 우주선 Titanic이 먼지 구름 속에 숨겨진 시공간 변칙과 충돌했습니다. 안타깝게도 1000년 전의 이름과 비슷한 운명을 맞이했습니다. 배는 온전했지만 승객의 거의 절반이 다른 차원으로 이동했습니다!\n",
    "\n",
    "### 데이터 정보\n",
    "* *PassengerId*\n",
    "    - 각 승객의 고유 ID. 각 Id는 승객이 함께 여행하는 그룹을 나타내고 그룹 내의 번호를 나타내는 형식을 취합니다 . 그룹의 사람들은 종종 가족 구성원이지만 항상 그런 것은 아닙니다.\n",
    "\n",
    "* *HomePlanet*\n",
    "    - 승객이 출발한 행성으로, 일반적으로 승객이 거주하는 행성입니다.\n",
    "\n",
    "* *CryoSleep*\n",
    "    - 승객이 항해 기간 동안 냉동 수면 선택했는지 여부를 나타냅니다. cryosleep의 승객은 객실에 갇혀 있습니다.\n",
    "\n",
    "* *Cabin*\n",
    "    - 승객이 머무르는 캐빈 번호. 형식을 취합니다 deck/num/side. 여기 에서 Port 또는 Starboard 가 side될 수 있습니다.\n",
    "\n",
    "* *Destination*\n",
    "    - 승객이 내릴 행성.\n",
    "\n",
    "* *Age*\n",
    "    - 승객의 나이.\n",
    "\n",
    "* *VIP*\n",
    "    - 승객이 항해 중 특별 VIP 서비스 비용을 지불했는지 여부.\n",
    "\n",
    "* *RoomService, FoodCourt, ShoppingMall, Spa, VRDeck*\n",
    "    - 승객이 Spaceship Titanic 의 다양한 고급 편의 시설 각각에 대해 청구한 금액입니다.\n",
    "\n",
    "* *Name*\n",
    "    - 승객의 성과 이름.\n",
    "\n",
    "* *Transported*\n",
    "    - 승객이 다른 차원으로 이동했는지 여부. 정답 데이터입니다."
   ],
   "metadata": {
    "id": "HkdCZ8yVq5Ya"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## import library"
   ],
   "metadata": {
    "id": "RX01utZISK6r"
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "Q8rWBE5W_YKL",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.142902300Z",
     "start_time": "2024-01-08T15:13:09.027088500Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "metadata": {
    "id": "XVte5KnxKmae",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.161479300Z",
     "start_time": "2024-01-08T15:13:09.145929100Z"
    }
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data Load\n",
    "### Read CSV files wit pandas"
   ],
   "metadata": {
    "id": "cf6id6YUq8ie"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train_data = pd.read_csv(\"spaceship_titanic_train_data.csv\")\n",
    "train_labels = pd.read_csv(\"spaceship_titanic_train_labels.csv\")\n",
    "\n",
    "test_data = pd.read_csv(\"spaceship_titanic_test_data.csv\")\n",
    "test_labels = pd.read_csv(\"spaceship_titanic_test_labels.csv\")\n",
    "\n",
    "train = pd.concat([train_data, train_labels], axis=1)\n",
    "test = pd.concat([test_data, test_labels], axis=1)"
   ],
   "metadata": {
    "id": "QqQ-lH0jArMP",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.205225700Z",
     "start_time": "2024-01-08T15:13:09.164994600Z"
    }
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Preprocessing\n",
    "* 결측치 제거 후 데이터 로더에 연결"
   ],
   "metadata": {
    "id": "hyXdPwEYq-2m"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "train = train.fillna(method='bfill')\n",
    "test = test.fillna(method='bfill')"
   ],
   "metadata": {
    "id": "eH2xjgpaDDny",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.226280700Z",
     "start_time": "2024-01-08T15:13:09.200707900Z"
    }
   },
   "execution_count": 32,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Soma\\temp\\ipykernel_14248\\1631429711.py:1: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  train = train.fillna(method='bfill')\n",
      "F:\\Soma\\temp\\ipykernel_14248\\1631429711.py:2: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  test = test.fillna(method='bfill')\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "train.dtypes"
   ],
   "metadata": {
    "id": "nybFLD29Eclv",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.264385400Z",
     "start_time": "2024-01-08T15:13:09.217254800Z"
    }
   },
   "execution_count": 33,
   "outputs": [
    {
     "data": {
      "text/plain": "PassengerId      object\nHomePlanet       object\nCryoSleep          bool\nCabin            object\nDestination      object\nAge             float64\nVIP                bool\nRoomService     float64\nFoodCourt       float64\nShoppingMall    float64\nSpa             float64\nVRDeck          float64\nName             object\nTransported        bool\ndtype: object"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# 일부 dtype은 tensor로 변경 불가\n",
    "train['HomePlanet'] = train['HomePlanet'].astype('category')\n",
    "train['CryoSleep'] = train['CryoSleep'].map({True: 1, False: 0})\n",
    "train['VIP'] = train['VIP'].astype('string')\n",
    "train['Transported'] = train['Transported'].astype('int')\n",
    "\n",
    "test['HomePlanet'] = test['HomePlanet'].astype('category')\n",
    "test['CryoSleep'] = test['CryoSleep'].map({True: 1, False: 0})\n",
    "test['VIP'] = test['VIP'].astype('string')\n",
    "test['Transported'] = test['Transported'].astype('int')"
   ],
   "metadata": {
    "id": "fw7o34_HGrNw",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.279760600Z",
     "start_time": "2024-01-08T15:13:09.232793500Z"
    }
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train"
   ],
   "metadata": {
    "id": "3wGlcJLVHQI5",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.309083900Z",
     "start_time": "2024-01-08T15:13:09.265391600Z"
    }
   },
   "execution_count": 35,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId HomePlanet  CryoSleep     Cabin    Destination   Age    VIP  \\\n0        2513_01      Earth          0   F/575/P    TRAPPIST-1e  28.0  False   \n1        2774_02      Earth          0   F/575/P    TRAPPIST-1e  17.0  False   \n2        8862_04     Europa          1   C/329/S    55 Cancri e  28.0  False   \n3        8736_02       Mars          0  F/1800/P    TRAPPIST-1e  20.0  False   \n4        0539_02     Europa          1    C/18/P    55 Cancri e  36.0  False   \n...          ...        ...        ...       ...            ...   ...    ...   \n6949     6076_01      Earth          0   G/988/S    TRAPPIST-1e  18.0  False   \n6950     5537_01       Mars          0  F/1063/S    TRAPPIST-1e  50.0  False   \n6951     5756_06      Earth          0  F/1194/P  PSO J318.5-22  22.0  False   \n6952     0925_01       Mars          0   F/191/P    TRAPPIST-1e  34.0  False   \n6953     7775_01     Europa          0   C/253/P    55 Cancri e  28.0  False   \n\n      RoomService  FoodCourt  ShoppingMall    Spa  VRDeck                Name  \\\n0             0.0       55.0           0.0  656.0     0.0      Loree Mathison   \n1             0.0     1195.0          31.0    0.0     0.0   Crisey Mcbriddley   \n2             0.0        0.0           0.0    0.0     0.0      Alramix Myling   \n3             0.0        2.0         289.0  976.0     0.0           Tros Pota   \n4             0.0        0.0           0.0    0.0     0.0      Achyon Nalanet   \n...           ...        ...           ...    ...     ...                 ...   \n6949         14.0        2.0         144.0  610.0     0.0        Therry Cames   \n6950        690.0        0.0          30.0  762.0   428.0         Herms Bancy   \n6951        158.0        0.0         476.0    0.0    26.0    Karena Briggston   \n6952        379.0        0.0        1626.0    0.0     0.0          Skix Kraie   \n6953          7.0      489.0           0.0    4.0  6027.0  Alraium Disivering   \n\n      Transported  \n0               0  \n1               0  \n2               1  \n3               1  \n4               1  \n...           ...  \n6949            1  \n6950            0  \n6951            0  \n6952            0  \n6953            0  \n\n[6954 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2513_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>F/575/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>28.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>55.0</td>\n      <td>0.0</td>\n      <td>656.0</td>\n      <td>0.0</td>\n      <td>Loree Mathison</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2774_02</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>F/575/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>17.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>1195.0</td>\n      <td>31.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Crisey Mcbriddley</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8862_04</td>\n      <td>Europa</td>\n      <td>1</td>\n      <td>C/329/S</td>\n      <td>55 Cancri e</td>\n      <td>28.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Alramix Myling</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>8736_02</td>\n      <td>Mars</td>\n      <td>0</td>\n      <td>F/1800/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>20.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>289.0</td>\n      <td>976.0</td>\n      <td>0.0</td>\n      <td>Tros Pota</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0539_02</td>\n      <td>Europa</td>\n      <td>1</td>\n      <td>C/18/P</td>\n      <td>55 Cancri e</td>\n      <td>36.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Achyon Nalanet</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>6949</th>\n      <td>6076_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>G/988/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>18.0</td>\n      <td>False</td>\n      <td>14.0</td>\n      <td>2.0</td>\n      <td>144.0</td>\n      <td>610.0</td>\n      <td>0.0</td>\n      <td>Therry Cames</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6950</th>\n      <td>5537_01</td>\n      <td>Mars</td>\n      <td>0</td>\n      <td>F/1063/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>50.0</td>\n      <td>False</td>\n      <td>690.0</td>\n      <td>0.0</td>\n      <td>30.0</td>\n      <td>762.0</td>\n      <td>428.0</td>\n      <td>Herms Bancy</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6951</th>\n      <td>5756_06</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>F/1194/P</td>\n      <td>PSO J318.5-22</td>\n      <td>22.0</td>\n      <td>False</td>\n      <td>158.0</td>\n      <td>0.0</td>\n      <td>476.0</td>\n      <td>0.0</td>\n      <td>26.0</td>\n      <td>Karena Briggston</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6952</th>\n      <td>0925_01</td>\n      <td>Mars</td>\n      <td>0</td>\n      <td>F/191/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>34.0</td>\n      <td>False</td>\n      <td>379.0</td>\n      <td>0.0</td>\n      <td>1626.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Skix Kraie</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>6953</th>\n      <td>7775_01</td>\n      <td>Europa</td>\n      <td>0</td>\n      <td>C/253/P</td>\n      <td>55 Cancri e</td>\n      <td>28.0</td>\n      <td>False</td>\n      <td>7.0</td>\n      <td>489.0</td>\n      <td>0.0</td>\n      <td>4.0</td>\n      <td>6027.0</td>\n      <td>Alraium Disivering</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>6954 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test"
   ],
   "metadata": {
    "id": "C0ezeuYr2d-F",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.376018300Z",
     "start_time": "2024-01-08T15:13:09.321748200Z"
    }
   },
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "     PassengerId HomePlanet  CryoSleep     Cabin  Destination   Age    VIP  \\\n0        0337_02       Mars          0    F/63/S  TRAPPIST-1e  19.0  False   \n1        2891_01      Earth          0   G/460/S  TRAPPIST-1e  18.0  False   \n2        8998_01      Earth          1  G/1449/S  TRAPPIST-1e  41.0  False   \n3        1771_01      Earth          0   G/291/P  TRAPPIST-1e  35.0  False   \n4        9034_02     Europa          1   D/288/P  TRAPPIST-1e  43.0  False   \n...          ...        ...        ...       ...          ...   ...    ...   \n1734     7656_01      Earth          1  G/1244/S  TRAPPIST-1e  16.0  False   \n1735     3437_02      Earth          1   G/553/S  TRAPPIST-1e   0.0  False   \n1736     1384_01      Earth          0   E/105/S  TRAPPIST-1e  17.0  False   \n1737     6300_01       Mars          1  F/1303/P  TRAPPIST-1e  42.0  False   \n1738     6442_01      Earth          0  G/1045/S  TRAPPIST-1e  17.0  False   \n\n      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck  \\\n0           417.0      349.0         634.0     3.0  1057.0   \n1             4.0      904.0           0.0     0.0     1.0   \n2             0.0        0.0           0.0     0.0     0.0   \n3             0.0      338.0         436.0     0.0     0.0   \n4             0.0        0.0           0.0     0.0     0.0   \n...           ...        ...           ...     ...     ...   \n1734          0.0        0.0           0.0     0.0     0.0   \n1735          0.0        0.0           0.0     0.0     0.0   \n1736         21.0        0.0         690.0   260.0     5.0   \n1737          0.0        0.0           0.0     0.0     0.0   \n1738          0.0        0.0           0.0  1806.0     0.0   \n\n                    Name  Transported  \n0            Weros Perle            1  \n1     Gleney Ortinericey            0  \n2         Gerry Englence            0  \n3         Antone Cardner            1  \n4        Errairk Crakete            1  \n...                  ...          ...  \n1734       Moniey Belley            0  \n1735         Carly Pager            1  \n1736       Violan Mayods            0  \n1737          Risps Pure            1  \n1738  Camiet Gainebergan            0  \n\n[1739 rows x 14 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>HomePlanet</th>\n      <th>CryoSleep</th>\n      <th>Cabin</th>\n      <th>Destination</th>\n      <th>Age</th>\n      <th>VIP</th>\n      <th>RoomService</th>\n      <th>FoodCourt</th>\n      <th>ShoppingMall</th>\n      <th>Spa</th>\n      <th>VRDeck</th>\n      <th>Name</th>\n      <th>Transported</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0337_02</td>\n      <td>Mars</td>\n      <td>0</td>\n      <td>F/63/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>19.0</td>\n      <td>False</td>\n      <td>417.0</td>\n      <td>349.0</td>\n      <td>634.0</td>\n      <td>3.0</td>\n      <td>1057.0</td>\n      <td>Weros Perle</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2891_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>G/460/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>18.0</td>\n      <td>False</td>\n      <td>4.0</td>\n      <td>904.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>Gleney Ortinericey</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8998_01</td>\n      <td>Earth</td>\n      <td>1</td>\n      <td>G/1449/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>41.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Gerry Englence</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1771_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>G/291/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>35.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>338.0</td>\n      <td>436.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Antone Cardner</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>9034_02</td>\n      <td>Europa</td>\n      <td>1</td>\n      <td>D/288/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>43.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Errairk Crakete</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>1734</th>\n      <td>7656_01</td>\n      <td>Earth</td>\n      <td>1</td>\n      <td>G/1244/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>16.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Moniey Belley</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1735</th>\n      <td>3437_02</td>\n      <td>Earth</td>\n      <td>1</td>\n      <td>G/553/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Carly Pager</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1736</th>\n      <td>1384_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>E/105/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>17.0</td>\n      <td>False</td>\n      <td>21.0</td>\n      <td>0.0</td>\n      <td>690.0</td>\n      <td>260.0</td>\n      <td>5.0</td>\n      <td>Violan Mayods</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1737</th>\n      <td>6300_01</td>\n      <td>Mars</td>\n      <td>1</td>\n      <td>F/1303/P</td>\n      <td>TRAPPIST-1e</td>\n      <td>42.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>Risps Pure</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1738</th>\n      <td>6442_01</td>\n      <td>Earth</td>\n      <td>0</td>\n      <td>G/1045/S</td>\n      <td>TRAPPIST-1e</td>\n      <td>17.0</td>\n      <td>False</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1806.0</td>\n      <td>0.0</td>\n      <td>Camiet Gainebergan</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>1739 rows × 14 columns</p>\n</div>"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Loader"
   ],
   "metadata": {
    "id": "wzJVBgxt5GDD"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "batch_size = 32\n",
    "\n",
    "def df_to_dataset(dataframe, label_name=\"Transported\", shuffle=True, batch_size=batch_size):\n",
    "    dataframe = dataframe.copy()\n",
    "    labels = dataframe.pop(label_name)\n",
    "    ds = tf.data.Dataset.from_tensor_slices((dict(dataframe), labels))\n",
    "    if shuffle:\n",
    "        ds = ds.shuffle(buffer_size=len(dataframe))\n",
    "        ds = ds.repeat()\n",
    "    ds = ds.batch(batch_size)\n",
    "\n",
    "    return ds\n"
   ],
   "metadata": {
    "id": "syVaa2MM5IxY",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.415479900Z",
     "start_time": "2024-01-08T15:13:09.340843100Z"
    }
   },
   "execution_count": 37,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "train_ds = df_to_dataset(train)\n",
    "train_ds"
   ],
   "metadata": {
    "id": "TFkgW_5QDgLu",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.506395Z",
     "start_time": "2024-01-08T15:13:09.359479200Z"
    }
   },
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=({'PassengerId': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'HomePlanet': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'CryoSleep': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Cabin': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Destination': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'VIP': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'RoomService': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'FoodCourt': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'ShoppingMall': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Spa': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'VRDeck': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "test_ds = df_to_dataset(test, shuffle=False)\n",
    "test_ds"
   ],
   "metadata": {
    "id": "jsWFWYz2MyNs",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.550736100Z",
     "start_time": "2024-01-08T15:13:09.429428400Z"
    }
   },
   "execution_count": 39,
   "outputs": [
    {
     "data": {
      "text/plain": "<BatchDataset element_spec=({'PassengerId': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'HomePlanet': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'CryoSleep': TensorSpec(shape=(None,), dtype=tf.int64, name=None), 'Cabin': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Destination': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'Age': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'VIP': TensorSpec(shape=(None,), dtype=tf.string, name=None), 'RoomService': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'FoodCourt': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'ShoppingMall': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Spa': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'VRDeck': TensorSpec(shape=(None,), dtype=tf.float64, name=None), 'Name': TensorSpec(shape=(None,), dtype=tf.string, name=None)}, TensorSpec(shape=(None,), dtype=tf.int32, name=None))>"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# for t, l in train_ds:\n",
    "#   print(t, l)\n",
    "#   break\n",
    "\n",
    "for t, l in test_ds:\n",
    "  print(t, l)\n",
    "  break\n"
   ],
   "metadata": {
    "id": "_BsMfFicHZQE",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.609464100Z",
     "start_time": "2024-01-08T15:13:09.529678400Z"
    }
   },
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'PassengerId': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'0337_02', b'2891_01', b'8998_01', b'1771_01', b'9034_02',\n",
      "       b'3706_02', b'3614_01', b'3476_04', b'1210_01', b'1289_01',\n",
      "       b'1555_01', b'2861_01', b'0618_01', b'1406_01', b'5188_01',\n",
      "       b'6511_03', b'0680_01', b'9132_02', b'8098_04', b'1399_01',\n",
      "       b'8306_03', b'6482_02', b'8429_01', b'8865_01', b'3564_01',\n",
      "       b'0237_01', b'8078_01', b'3533_01', b'0011_01', b'9103_01',\n",
      "       b'5303_02', b'3959_01'], dtype=object)>, 'HomePlanet': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Mars', b'Earth', b'Earth', b'Earth', b'Europa', b'Mars',\n",
      "       b'Earth', b'Earth', b'Earth', b'Earth', b'Europa', b'Earth',\n",
      "       b'Earth', b'Mars', b'Earth', b'Earth', b'Earth', b'Mars',\n",
      "       b'Europa', b'Earth', b'Earth', b'Mars', b'Earth', b'Earth',\n",
      "       b'Earth', b'Europa', b'Earth', b'Mars', b'Earth', b'Earth',\n",
      "       b'Earth', b'Earth'], dtype=object)>, 'CryoSleep': <tf.Tensor: shape=(32,), dtype=int64, numpy=\n",
      "array([0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=int64)>, 'Cabin': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'F/63/S', b'G/460/S', b'G/1449/S', b'G/291/P', b'D/288/P',\n",
      "       b'F/770/P', b'F/749/P', b'G/571/P', b'G/179/P', b'G/195/S',\n",
      "       b'A/18/S', b'F/547/S', b'G/95/P', b'E/106/S', b'G/838/P',\n",
      "       b'G/1055/P', b'G/105/P', b'F/1871/P', b'B/269/P', b'F/272/S',\n",
      "       b'G/1351/P', b'F/1237/S', b'G/1351/S', b'F/1826/P', b'G/582/P',\n",
      "       b'B/11/P', b'F/1667/P', b'E/211/P', b'F/2/P', b'G/1479/P',\n",
      "       b'G/857/P', b'G/646/P'], dtype=object)>, 'Destination': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e',\n",
      "       b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e',\n",
      "       b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e',\n",
      "       b'55 Cancri e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'55 Cancri e',\n",
      "       b'PSO J318.5-22', b'TRAPPIST-1e', b'55 Cancri e', b'TRAPPIST-1e',\n",
      "       b'TRAPPIST-1e', b'TRAPPIST-1e', b'55 Cancri e', b'TRAPPIST-1e',\n",
      "       b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e',\n",
      "       b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e', b'TRAPPIST-1e'],\n",
      "      dtype=object)>, 'Age': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([19., 18., 41., 35., 43., 18., 20., 24., 45.,  8., 45., 17., 21.,\n",
      "       17., 34.,  0., 45., 28., 26., 28., 41.,  1., 23., 24., 24., 42.,\n",
      "       19., 18., 28., 25.,  7., 21.])>, 'VIP': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'False', b'False', b'False', b'False', b'False', b'False',\n",
      "       b'False', b'False', b'False', b'False', b'False', b'False',\n",
      "       b'False', b'False', b'False', b'False', b'False', b'False',\n",
      "       b'False', b'False', b'False', b'False', b'False', b'False',\n",
      "       b'False', b'False', b'False', b'False', b'False', b'False',\n",
      "       b'False', b'False'], dtype=object)>, 'RoomService': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([4.170e+02, 4.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.310e+02,\n",
      "       2.000e+00, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 5.000e+00,\n",
      "       0.000e+00, 3.600e+01, 0.000e+00, 0.000e+00, 0.000e+00, 1.789e+03,\n",
      "       0.000e+00, 0.000e+00, 8.360e+02, 0.000e+00, 0.000e+00, 1.210e+02,\n",
      "       0.000e+00, 0.000e+00, 0.000e+00, 1.749e+03, 8.000e+00, 3.402e+03,\n",
      "       0.000e+00, 0.000e+00])>, 'FoodCourt': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([3.4900e+02, 9.0400e+02, 0.0000e+00, 3.3800e+02, 0.0000e+00,\n",
      "       0.0000e+00, 0.0000e+00, 4.6700e+02, 0.0000e+00, 0.0000e+00,\n",
      "       1.3890e+03, 7.5600e+02, 0.0000e+00, 0.0000e+00, 1.6000e+02,\n",
      "       0.0000e+00, 0.0000e+00, 1.6000e+01, 1.1598e+04, 0.0000e+00,\n",
      "       0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+01, 0.0000e+00,\n",
      "       0.0000e+00, 0.0000e+00, 5.0000e+01, 9.7400e+02, 2.4490e+03,\n",
      "       0.0000e+00, 8.0000e+01])>, 'ShoppingMall': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([ 634.,    0.,    0.,  436.,    0.,  980.,    7.,    4.,    0.,\n",
      "          0.,    0.,    0.,  908., 1013.,    0.,    0.,    0.,    3.,\n",
      "          0.,  529.,    0.,    0.,    0.,  341.,    0.,    0.,  134.,\n",
      "        280.,   12.,   28.,    0.,  255.])>, 'Spa': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([3.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 1.000e+00,\n",
      "       2.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 2.987e+03, 0.000e+00,\n",
      "       4.900e+01, 0.000e+00, 6.110e+02, 0.000e+00, 0.000e+00, 1.000e+01,\n",
      "       3.000e+00, 5.600e+02, 0.000e+00, 0.000e+00, 0.000e+00, 3.070e+02,\n",
      "       0.000e+00, 0.000e+00, 1.931e+03, 2.000e+00, 2.000e+00, 2.590e+02,\n",
      "       0.000e+00, 0.000e+00])>, 'VRDeck': <tf.Tensor: shape=(32,), dtype=float64, numpy=\n",
      "array([1.057e+03, 1.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "       5.470e+02, 3.410e+02, 0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00,\n",
      "       0.000e+00, 0.000e+00, 4.400e+01, 0.000e+00, 0.000e+00, 1.000e+00,\n",
      "       3.860e+02, 6.000e+01, 4.900e+01, 0.000e+00, 0.000e+00, 4.700e+01,\n",
      "       0.000e+00, 0.000e+00, 0.000e+00, 0.000e+00, 7.000e+00, 1.970e+02,\n",
      "       0.000e+00, 5.190e+03])>, 'Name': <tf.Tensor: shape=(32,), dtype=string, numpy=\n",
      "array([b'Weros Perle', b'Gleney Ortinericey', b'Gerry Englence',\n",
      "       b'Antone Cardner', b'Errairk Crakete', b'Honda Kidie',\n",
      "       b'Eduard Quinnerry', b'Bonne Burksson', b'Helean Brooker',\n",
      "       b'Idace Fultz', b'Alcorix Spistory', b'Evaley Marson',\n",
      "       b'Philda Yorkland', b'Muffs Gres', b'Chesty Bootez',\n",
      "       b'Thelix Gainney', b'Garyan Garnes', b'Pil Ancy',\n",
      "       b'Hasim Mosteraked', b'Hellia Popelase', b'Bonya Hardonald',\n",
      "       b'Dow Letie', b'Briney Donson', b'Bettie Sancockett',\n",
      "       b'Leene Kaufmaneyes', b'Weias Aginge', b'Colle Davispinoz',\n",
      "       b'Coakey Buthe', b'Elle Bertsontry', b'Sadine Mcdanield',\n",
      "       b'Loree Hoffergess', b'Leahy Sullones'], dtype=object)>} tf.Tensor([1 0 0 1 1 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 0 1 1 0 0 1 0 0 1 0 1 0], shape=(32,), dtype=int32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "list(set(train['VIP']))"
   ],
   "metadata": {
    "id": "uxI24vNhyxB2",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:09.613976100Z",
     "start_time": "2024-01-08T15:13:09.560760700Z"
    }
   },
   "execution_count": 41,
   "outputs": [
    {
     "data": {
      "text/plain": "['True', 'False']"
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preprocessing with layers"
   ],
   "metadata": {
    "id": "TaxlpWcarA9M"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "inputs = {\n",
    "  'CryoSleep': tf.keras.Input(shape=(), dtype='int64'),\n",
    "  'HomePlanet': tf.keras.Input(shape=(), dtype='string'),\n",
    "  'RoomService': tf.keras.Input(shape=(), dtype='float64'),\n",
    "  'FoodCourt': tf.keras.Input(shape=(), dtype='float64'),\n",
    "  'ShoppingMall': tf.keras.Input(shape=(), dtype='float64'),\n",
    "  'Spa': tf.keras.Input(shape=(), dtype='float64'),\n",
    "  'VRDeck': tf.keras.Input(shape=(), dtype='float64'),\n",
    "  'VIP': tf.keras.Input(shape=(), dtype='string'),\n",
    "  'Cabin': tf.keras.Input(shape=(), dtype='string'),\n",
    "  'Destination':tf.keras.Input(shape=(), dtype='string'),\n",
    "  'Age': tf.keras.Input(shape=(), dtype='float64')\n",
    "}\n",
    "\n",
    "split_text = tf.strings.split(inputs['Cabin'], sep=\"/\")\n",
    "\n",
    "# Convert index to one-hot; e.g. [2] -> [0,1].\n",
    "type_output = tf.keras.layers.CategoryEncoding(num_tokens=2, output_mode='one_hot')(inputs['CryoSleep'])\n",
    "print(type_output.shape)\n",
    "dense_type = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(type_output)\n",
    "dense_type = tf.keras.layers.BatchNormalization()(dense_type)\n",
    "dense_type =tf.keras.layers.Activation('relu')(dense_type)\n",
    "print(dense_type.shape)\n",
    "\n",
    "vip = tf.keras.layers.StringLookup(vocabulary=[\"True\", \"False\"], num_oov_indices=0, output_mode='one_hot')(inputs['VIP'])\n",
    "print(vip.shape)\n",
    "\n",
    "# Convert size strings to indices; e.g. ['small'] -> [1].\n",
    "size_output = tf.keras.layers.StringLookup(vocabulary=list(set(train['HomePlanet'])))(inputs['HomePlanet'])\n",
    "size_output = tf.keras.layers.Reshape([-1])(size_output)\n",
    "size_output = tf.keras.layers.Lambda(lambda x: tf.cast(x, dtype=tf.float64))(size_output)\n",
    "# print(size_output.shape)\n",
    "dense_size = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(size_output)\n",
    "dense_size =tf.keras.layers.BatchNormalization()(size_output)\n",
    "dense_size =tf.keras.layers.Activation('relu')(size_output)\n",
    "# print(dense_size.shape)\n",
    "\n",
    "# Normalize the numeric inputs; e.g. [2.0] -> [0.0].\n",
    "weight_output = tf.keras.layers.Normalization(\n",
    "      axis=None, mean=2.0, variance=1.0)(inputs['RoomService'])\n",
    "weight_output = tf.keras.layers.Reshape([-1])(weight_output)\n",
    "print(weight_output.shape)\n",
    "dense_weight = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(weight_output)\n",
    "dense_weight =tf.keras.layers.BatchNormalization()(weight_output)\n",
    "dense_weight =tf.keras.layers.Activation('relu')(weight_output)\n",
    "#foodCourt\n",
    "food_weight_output = tf.keras.layers.Normalization(\n",
    "      axis=None, mean=2.0, variance=1.0)(inputs['FoodCourt'])\n",
    "food_weight_output = tf.keras.layers.Reshape([-1])(food_weight_output)\n",
    "print(food_weight_output.shape)\n",
    "food_weight_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(food_weight_output)\n",
    "food_weight_output = tf.keras.layers.BatchNormalization()(food_weight_output)\n",
    "food_weight_output = tf.keras.layers.Activation('relu')(food_weight_output)\n",
    "# ShoppingMall\n",
    "shopping_output = tf.keras.layers.Normalization(\n",
    "      axis=None, mean=2.0, variance=1.0)(inputs['ShoppingMall'])\n",
    "shopping_output = tf.keras.layers.Reshape([-1])(shopping_output)\n",
    "print(food_weight_output.shape)\n",
    "shopping_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(shopping_output)\n",
    "shopping_output = tf.keras.layers.BatchNormalization()(shopping_output)\n",
    "shopping_output = tf.keras.layers.Activation('relu')(shopping_output)\n",
    "#Spa\n",
    "sha_output = tf.keras.layers.Normalization(\n",
    "      axis=None, mean=2.0, variance=1.0)(inputs['Spa'])\n",
    "sha_output = tf.keras.layers.Reshape([-1])(sha_output)\n",
    "print(food_weight_output.shape)\n",
    "sha_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(sha_output)\n",
    "sha_output = tf.keras.layers.BatchNormalization()(sha_output)\n",
    "sha_output = tf.keras.layers.Activation('relu')(sha_output)\n",
    "#VRDeck\n",
    "vr_output = tf.keras.layers.Normalization(\n",
    "      axis=None, mean=2.0, variance=1.0)(inputs['VRDeck'])\n",
    "vr_output = tf.keras.layers.Reshape([-1])(vr_output)\n",
    "print(food_weight_output.shape)\n",
    "vr_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(vr_output)\n",
    "vr_output = tf.keras.layers.BatchNormalization()(vr_output)\n",
    "vr_output = tf.keras.layers.Activation('relu')(vr_output)\n",
    "\n",
    "# 캐빈 데이터를 분할합니다\n",
    "cabin_split = tf.strings.split(inputs['Cabin'], \"/\")\n",
    "\n",
    "# 마지막 요소만 선택합니다\n",
    "cabin_first = cabin_split.to_tensor()[:, 0]\n",
    "cabin_last = cabin_split.to_tensor()[:, -1]\n",
    "\n",
    "# StringLookup 레이어를 사용하여 one-hot 인코딩을 수행합니다\n",
    "# cabin_first = tf.keras.layers.StringLookup(vocabulary=[\"C\",\"D\",\"E\",\"F\",\"G\"], num_oov_indices=1, output_mode='one_hot')(cabin_first)\n",
    "# cabin_first = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(cabin_first)\n",
    "# cabin_first = tf.keras.layers.BatchNormalization()(cabin_first)\n",
    "# cabin_first = tf.keras.layers.Activation('relu')(cabin_first)\n",
    "\n",
    "cabin_output = tf.keras.layers.StringLookup(vocabulary=[\"S\", \"P\"], num_oov_indices=1, output_mode='one_hot')(cabin_last)\n",
    "cabin_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(cabin_output)\n",
    "cabin_output = tf.keras.layers.BatchNormalization()(cabin_output)\n",
    "cabin_output = tf.keras.layers.Activation('relu')(cabin_output)\n",
    "\n",
    "# list(set(train['HomePlanet']))\n",
    "string_lookup_layer = tf.keras.layers.StringLookup(vocabulary=list(set(train['HomePlanet'])),num_oov_indices=0,output_mode='one_hot')(inputs['HomePlanet'])\n",
    "string_lookup_layer = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(string_lookup_layer)\n",
    "string_lookup_layer = tf.keras.layers.BatchNormalization()(string_lookup_layer)\n",
    "string_lookup_layer = tf.keras.layers.Activation('relu')(string_lookup_layer)\n",
    "\n",
    "string_destination = tf.keras.layers.StringLookup(vocabulary=list(set(train['Destination'])),num_oov_indices=0,output_mode='one_hot')(inputs['Destination'])\n",
    "string_destination = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(string_destination)\n",
    "string_destination = tf.keras.layers.BatchNormalization()(string_destination)\n",
    "string_destination = tf.keras.layers.Activation('relu')(string_destination)\n",
    "\n",
    "#age\n",
    "age_output = tf.keras.layers.Normalization(axis=None, mean=2.0, variance=1.0)(inputs['Age'])\n",
    "age_output = tf.keras.layers.Reshape([-1])(age_output)\n",
    "print(age_output.shape)\n",
    "age_output = tf.keras.layers.Dense(2,kernel_initializer = 'he_normal')(age_output)\n",
    "age_output =tf.keras.layers.BatchNormalization()(age_output)\n",
    "age_output =tf.keras.layers.Activation('relu')(age_output)\n",
    "\n",
    "\n",
    "# x = tf.concat([dense_type, dense_size, dense_weight, dense_room_service], -1)# batch, 특징 (여기로 합쳐라)\n",
    "x = tf.concat([dense_type, dense_size,age_output, dense_weight,food_weight_output,shopping_output,sha_output,vr_output,cabin_output,string_lookup_layer,string_destination], -1)# batch, 특징 (여기로 합쳐라)\n",
    "# x = tf.concat([dense_type, dense_size,age_output, dense_weight,food_weight_output,shopping_output,sha_output,vr_output,cabin_output,cabin_first,string_lookup_layer,string_destination], -1)# batch, 특징 (여기로 합쳐라)\n",
    "x = tf.keras.layers.Dense(64)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x =tf.keras.layers.Activation('relu')(x)\n",
    "x = tf.keras.layers.Dense(4)(x)\n",
    "x = tf.keras.layers.BatchNormalization()(x)\n",
    "x =tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "outputs = tf.keras.layers.Dense(1)(x) # Sigmoid, BCE loss\n",
    "\n",
    "# outputs = {\n",
    "#   'CryoSleep': type_output,\n",
    "#   'HomePlanet': size_output,\n",
    "#   'RoomService': weight_output,\n",
    "#   'VIP': vip,\n",
    "#   's': split_text\n",
    "# }\n",
    "\n",
    "preprocessing_model = tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "id": "BBg7nmuDQRoq",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.171942Z",
     "start_time": "2024-01-08T15:13:09.630775700Z"
    }
   },
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 2)\n",
      "(None, 2)\n",
      "(None, 2)\n",
      "(None, 1)\n",
      "(None, 1)\n",
      "(None, 2)\n",
      "(None, 2)\n",
      "(None, 2)\n",
      "(None, 1)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Input and preprocessing Layers"
   ],
   "metadata": {
    "id": "8Bpw541x3jM1"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### String Look Up\n"
   ],
   "metadata": {
    "id": "bqjfuAHe1ap4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "#  tf.strings.split(train['Cabin'], \"/\")[:,-1:].numpy()"
   ],
   "metadata": {
    "id": "bo9ZjeUS4Zd7",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.191574700Z",
     "start_time": "2024-01-08T15:13:10.168660800Z"
    }
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# inputs = {\n",
    "#     'Cabin': tf.keras.Input(shape=(), dtype='string')\n",
    "# }\n",
    "\n",
    "# # 캐빈 데이터를 분할합니다\n",
    "# cabin_split = tf.strings.split(inputs['Cabin'], \"/\")\n",
    "\n",
    "# # 마지막 요소만 선택합니다\n",
    "# cabin_last = cabin_split.to_tensor()[:, -1]\n",
    "\n",
    "# # StringLookup 레이어를 사용하여 one-hot 인코딩을 수행합니다\n",
    "# cabin_output = tf.keras.layers.StringLookup(vocabulary=[\"S\", \"P\"], num_oov_indices=1, output_mode='one_hot')(cabin_last)\n",
    "\n",
    "# outputs = {\n",
    "#     'Cabin': cabin_output\n",
    "# }\n",
    "\n",
    "# model = tf.keras.Model(inputs, outputs)"
   ],
   "metadata": {
    "id": "g6RyJcuK3N8l",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.204110600Z",
     "start_time": "2024-01-08T15:13:10.184049900Z"
    }
   },
   "execution_count": 44,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# for t, l in train_ds:\n",
    "#     pred = model(t)\n",
    "#     print(pred['Cabin'])\n",
    "#     break"
   ],
   "metadata": {
    "id": "KlNhLc1oV6jZ",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.222662300Z",
     "start_time": "2024-01-08T15:13:10.200602100Z"
    }
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# # s = \"F/575/P\"\n",
    "# tf.strings.split(s, sep=\"/\")"
   ],
   "metadata": {
    "id": "6yclqkG2t0F6",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.240720Z",
     "start_time": "2024-01-08T15:13:10.215141500Z"
    }
   },
   "execution_count": 46,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "list(set(train['HomePlanet']))"
   ],
   "metadata": {
    "id": "ldFmPM5qppS_",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.267383400Z",
     "start_time": "2024-01-08T15:13:10.230697Z"
    }
   },
   "execution_count": 47,
   "outputs": [
    {
     "data": {
      "text/plain": "['Europa', 'Mars', 'Earth']"
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "list(set(train['Destination']))"
   ],
   "metadata": {
    "id": "yd2g6RXSeeJN",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.268996300Z",
     "start_time": "2024-01-08T15:13:10.247240Z"
    }
   },
   "execution_count": 48,
   "outputs": [
    {
     "data": {
      "text/plain": "['55 Cancri e', 'PSO J318.5-22', 'TRAPPIST-1e']"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# string_lookup_layer = tf.keras.layers.StringLookup(\n",
    "#     vocabulary=list(set(train['HomePlanet'])),\n",
    "#     num_oov_indices=0,\n",
    "#     output_mode='one_hot')\n",
    "# \"\"\"\n",
    "# int 0, 1, 2 (idx)\n",
    "# one_hot [1, 0, 0]\n",
    "# multi_hot [1, 0, 1] (다중입력)\n",
    "# \"\"\"\n",
    "\n",
    "# string_lookup_layer(list(train['HomePlanet'].to_numpy()))"
   ],
   "metadata": {
    "id": "97laqWerpttW",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.297235500Z",
     "start_time": "2024-01-08T15:13:10.262864700Z"
    }
   },
   "execution_count": 49,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Category Encoding"
   ],
   "metadata": {
    "id": "4dJ64DFR1zSW"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# train['CryoSleep']"
   ],
   "metadata": {
    "id": "o6eeBxJPreSo",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.298740900Z",
     "start_time": "2024-01-08T15:13:10.277785500Z"
    }
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# one_hot_layer = tf.keras.layers.CategoryEncoding(\n",
    "#     num_tokens=2, output_mode='one_hot')\n",
    "# one_hot_layer(list(train['CryoSleep'].to_numpy()))"
   ],
   "metadata": {
    "id": "_cRCuG2rqS52",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.320802800Z",
     "start_time": "2024-01-08T15:13:10.295235700Z"
    }
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Normalization"
   ],
   "metadata": {
    "id": "oAfDEVXz2YcB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "normalization_layer = tf.keras.layers.Normalization(mean=1.0, variance=10.0)\n",
    "\n",
    "# 각 입력 값에서 mean 값을 뺍니다. 예를 들어, 입력이 [1., 2., 3.]라면, 결과는 [-2., -1., 0.]이 됩니다.\n",
    "# 다음으로, 이 결과를 variance의 제곱근 값, 즉 sqrt(2.)로 나눕니다. 따라서 결과는 [-2/sqrt(2), -1/sqrt(2), 0]가 됩니다. (정규화 과정)\n",
    "\n",
    "print(normalization_layer(train['RoomService'][:5]).numpy())\n",
    "print(train['RoomService'][:5].to_numpy())"
   ],
   "metadata": {
    "id": "6M0RBuMPrkri",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.324311500Z",
     "start_time": "2024-01-08T15:13:10.308770500Z"
    }
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.31622776 -0.31622776 -0.31622776 -0.31622776 -0.31622776]\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Train"
   ],
   "metadata": {
    "id": "641_XZTH1REC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import os\n",
    "from os.path import isdir, join\n",
    "use_colab = True\n",
    "assert use_colab in [True, False]\n",
    "if use_colab:\n",
    "    checkpoint_dir ='./drive/MyDrive/train_ckpt/spectrogram/exp1'\n",
    "    if not os.path.isdir(checkpoint_dir):\n",
    "        os.makedirs(checkpoint_dir)\n",
    "else:\n",
    "    checkpoint_dir = 'spectrogram/exp1'"
   ],
   "metadata": {
    "id": "HhUzj8pJfpCN",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.357680500Z",
     "start_time": "2024-01-08T15:13:10.325319600Z"
    }
   },
   "execution_count": 53,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_dir,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 monitor='val_loss',\n",
    "                                                 mode='auto',\n",
    "                                                 save_best_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "early_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=20,\n",
    "                                                     monitor='val_loss',\n",
    "                                                     restore_best_weights=True,\n",
    "\n",
    "                                                     verbose=1)\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss',  # 관찰할 지표\n",
    "                              factor=0.2,  # 학습률을 줄이는 비율\n",
    "                              patience=4,  # 몇 번의 에포크 동안 감소하지 않아야 하는지\n",
    "                              min_lr=1e-9)"
   ],
   "metadata": {
    "id": "Vszc9FpAeOVT",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.359809200Z",
     "start_time": "2024-01-08T15:13:10.341882300Z"
    }
   },
   "execution_count": 54,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessing_model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ],
   "metadata": {
    "id": "7RX-QT0Dz0U_",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:13:10.378625500Z",
     "start_time": "2024-01-08T15:13:10.358680800Z"
    }
   },
   "execution_count": 55,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "max_epochs = 150\n",
    "\n",
    "history = preprocessing_model.fit(train_ds,\n",
    "                                  epochs=max_epochs,\n",
    "                                  steps_per_epoch=len(train) // batch_size,\n",
    "                                  callbacks=[cp_callback,early_stopping_cb,reduce_lr],\n",
    "                                  validation_data=test_ds,\n",
    "                                  validation_steps=len(test) // batch_size)"
   ],
   "metadata": {
    "id": "rEk1FAnxexWO",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:17:20.454896800Z",
     "start_time": "2024-01-08T15:13:10.373022500Z"
    }
   },
   "execution_count": 56,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\keras\\engine\\functional.py:637: UserWarning: Input dict contained keys ['PassengerId', 'Name'] which did not match any model input. They will be ignored by the model.\n",
      "  inputs = self._flatten_to_reference_inputs(inputs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "215/217 [============================>.] - ETA: 0s - loss: 0.6516 - accuracy: 0.4955\n",
      "Epoch 1: val_loss improved from inf to 0.64554, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 7s 21ms/step - loss: 0.6514 - accuracy: 0.4967 - val_loss: 0.6455 - val_accuracy: 0.4942 - lr: 0.0010\n",
      "Epoch 2/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.5769 - accuracy: 0.6396\n",
      "Epoch 2: val_loss did not improve from 0.64554\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.5769 - accuracy: 0.6404 - val_loss: 0.6718 - val_accuracy: 0.4942 - lr: 0.0010\n",
      "Epoch 3/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.5056 - accuracy: 0.7452\n",
      "Epoch 3: val_loss improved from 0.64554 to 0.62602, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.5058 - accuracy: 0.7447 - val_loss: 0.6260 - val_accuracy: 0.4965 - lr: 0.0010\n",
      "Epoch 4/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4918 - accuracy: 0.7503\n",
      "Epoch 4: val_loss improved from 0.62602 to 0.53644, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4916 - accuracy: 0.7509 - val_loss: 0.5364 - val_accuracy: 0.6892 - lr: 0.0010\n",
      "Epoch 5/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4893 - accuracy: 0.7524\n",
      "Epoch 5: val_loss improved from 0.53644 to 0.52425, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4893 - accuracy: 0.7524 - val_loss: 0.5242 - val_accuracy: 0.6927 - lr: 0.0010\n",
      "Epoch 6/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4844 - accuracy: 0.7519\n",
      "Epoch 6: val_loss did not improve from 0.52425\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4847 - accuracy: 0.7514 - val_loss: 0.5524 - val_accuracy: 0.7020 - lr: 0.0010\n",
      "Epoch 7/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4800 - accuracy: 0.7594\n",
      "Epoch 7: val_loss improved from 0.52425 to 0.50946, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4799 - accuracy: 0.7596 - val_loss: 0.5095 - val_accuracy: 0.7263 - lr: 0.0010\n",
      "Epoch 8/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4838 - accuracy: 0.7628\n",
      "Epoch 8: val_loss improved from 0.50946 to 0.50899, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4838 - accuracy: 0.7628 - val_loss: 0.5090 - val_accuracy: 0.7303 - lr: 0.0010\n",
      "Epoch 9/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4780 - accuracy: 0.7560\n",
      "Epoch 9: val_loss did not improve from 0.50899\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4778 - accuracy: 0.7563 - val_loss: 0.5317 - val_accuracy: 0.6985 - lr: 0.0010\n",
      "Epoch 10/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4771 - accuracy: 0.7653\n",
      "Epoch 10: val_loss did not improve from 0.50899\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4762 - accuracy: 0.7658 - val_loss: 0.5296 - val_accuracy: 0.6997 - lr: 0.0010\n",
      "Epoch 11/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4747 - accuracy: 0.7552\n",
      "Epoch 11: val_loss improved from 0.50899 to 0.49662, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4748 - accuracy: 0.7552 - val_loss: 0.4966 - val_accuracy: 0.7251 - lr: 0.0010\n",
      "Epoch 12/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4726 - accuracy: 0.7610\n",
      "Epoch 12: val_loss did not improve from 0.49662\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4719 - accuracy: 0.7612 - val_loss: 0.5060 - val_accuracy: 0.7037 - lr: 0.0010\n",
      "Epoch 13/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4760 - accuracy: 0.7512\n",
      "Epoch 13: val_loss did not improve from 0.49662\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4767 - accuracy: 0.7512 - val_loss: 0.5031 - val_accuracy: 0.7257 - lr: 0.0010\n",
      "Epoch 14/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4711 - accuracy: 0.7624\n",
      "Epoch 14: val_loss did not improve from 0.49662\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4711 - accuracy: 0.7624 - val_loss: 0.6175 - val_accuracy: 0.6499 - lr: 0.0010\n",
      "Epoch 15/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4751 - accuracy: 0.7543\n",
      "Epoch 15: val_loss did not improve from 0.49662\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4747 - accuracy: 0.7542 - val_loss: 0.5057 - val_accuracy: 0.7049 - lr: 0.0010\n",
      "Epoch 16/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4647 - accuracy: 0.7514\n",
      "Epoch 16: val_loss improved from 0.49662 to 0.49168, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4643 - accuracy: 0.7516 - val_loss: 0.4917 - val_accuracy: 0.7043 - lr: 2.0000e-04\n",
      "Epoch 17/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4607 - accuracy: 0.7580\n",
      "Epoch 17: val_loss improved from 0.49168 to 0.48486, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4599 - accuracy: 0.7575 - val_loss: 0.4849 - val_accuracy: 0.7066 - lr: 2.0000e-04\n",
      "Epoch 18/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4673 - accuracy: 0.7615\n",
      "Epoch 18: val_loss did not improve from 0.48486\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4673 - accuracy: 0.7615 - val_loss: 0.4914 - val_accuracy: 0.7060 - lr: 2.0000e-04\n",
      "Epoch 19/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4662 - accuracy: 0.7572\n",
      "Epoch 19: val_loss improved from 0.48486 to 0.48285, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4657 - accuracy: 0.7579 - val_loss: 0.4828 - val_accuracy: 0.7182 - lr: 2.0000e-04\n",
      "Epoch 20/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4632 - accuracy: 0.7600\n",
      "Epoch 20: val_loss did not improve from 0.48285\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4633 - accuracy: 0.7599 - val_loss: 0.4834 - val_accuracy: 0.7216 - lr: 2.0000e-04\n",
      "Epoch 21/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4667 - accuracy: 0.7571\n",
      "Epoch 21: val_loss did not improve from 0.48285\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4667 - accuracy: 0.7571 - val_loss: 0.4830 - val_accuracy: 0.7106 - lr: 2.0000e-04\n",
      "Epoch 22/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4614 - accuracy: 0.7593\n",
      "Epoch 22: val_loss improved from 0.48285 to 0.48278, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4616 - accuracy: 0.7594 - val_loss: 0.4828 - val_accuracy: 0.7274 - lr: 2.0000e-04\n",
      "Epoch 23/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4670 - accuracy: 0.7569\n",
      "Epoch 23: val_loss improved from 0.48278 to 0.48087, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4682 - accuracy: 0.7571 - val_loss: 0.4809 - val_accuracy: 0.7257 - lr: 2.0000e-04\n",
      "Epoch 24/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4663 - accuracy: 0.7546\n",
      "Epoch 24: val_loss improved from 0.48087 to 0.47948, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 18ms/step - loss: 0.4660 - accuracy: 0.7548 - val_loss: 0.4795 - val_accuracy: 0.7459 - lr: 2.0000e-04\n",
      "Epoch 25/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4590 - accuracy: 0.7615\n",
      "Epoch 25: val_loss did not improve from 0.47948\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4582 - accuracy: 0.7615 - val_loss: 0.4809 - val_accuracy: 0.7211 - lr: 2.0000e-04\n",
      "Epoch 26/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4665 - accuracy: 0.7535\n",
      "Epoch 26: val_loss improved from 0.47948 to 0.47691, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4667 - accuracy: 0.7530 - val_loss: 0.4769 - val_accuracy: 0.7216 - lr: 2.0000e-04\n",
      "Epoch 27/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4664 - accuracy: 0.7527\n",
      "Epoch 27: val_loss did not improve from 0.47691\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4662 - accuracy: 0.7530 - val_loss: 0.4773 - val_accuracy: 0.7361 - lr: 2.0000e-04\n",
      "Epoch 28/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4680 - accuracy: 0.7543\n",
      "Epoch 28: val_loss did not improve from 0.47691\n",
      "217/217 [==============================] - 3s 16ms/step - loss: 0.4680 - accuracy: 0.7543 - val_loss: 0.4778 - val_accuracy: 0.7135 - lr: 2.0000e-04\n",
      "Epoch 29/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4627 - accuracy: 0.7536\n",
      "Epoch 29: val_loss did not improve from 0.47691\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4625 - accuracy: 0.7533 - val_loss: 0.4828 - val_accuracy: 0.7228 - lr: 2.0000e-04\n",
      "Epoch 30/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.7545\n",
      "Epoch 30: val_loss did not improve from 0.47691\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4628 - accuracy: 0.7545 - val_loss: 0.4788 - val_accuracy: 0.7141 - lr: 2.0000e-04\n",
      "Epoch 31/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4625 - accuracy: 0.7566\n",
      "Epoch 31: val_loss improved from 0.47691 to 0.47485, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 19ms/step - loss: 0.4623 - accuracy: 0.7566 - val_loss: 0.4748 - val_accuracy: 0.7141 - lr: 4.0000e-05\n",
      "Epoch 32/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4586 - accuracy: 0.7585\n",
      "Epoch 32: val_loss did not improve from 0.47485\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4595 - accuracy: 0.7581 - val_loss: 0.4749 - val_accuracy: 0.7216 - lr: 4.0000e-05\n",
      "Epoch 33/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7581\n",
      "Epoch 33: val_loss did not improve from 0.47485\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4597 - accuracy: 0.7579 - val_loss: 0.4751 - val_accuracy: 0.7216 - lr: 4.0000e-05\n",
      "Epoch 34/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4642 - accuracy: 0.7621\n",
      "Epoch 34: val_loss did not improve from 0.47485\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4640 - accuracy: 0.7624 - val_loss: 0.4753 - val_accuracy: 0.7332 - lr: 4.0000e-05\n",
      "Epoch 35/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4659 - accuracy: 0.7555\n",
      "Epoch 35: val_loss did not improve from 0.47485\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4655 - accuracy: 0.7560 - val_loss: 0.4775 - val_accuracy: 0.7211 - lr: 4.0000e-05\n",
      "Epoch 36/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4609 - accuracy: 0.7616\n",
      "Epoch 36: val_loss improved from 0.47485 to 0.47436, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4609 - accuracy: 0.7614 - val_loss: 0.4744 - val_accuracy: 0.7321 - lr: 8.0000e-06\n",
      "Epoch 37/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4588 - accuracy: 0.7638\n",
      "Epoch 37: val_loss did not improve from 0.47436\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4588 - accuracy: 0.7638 - val_loss: 0.4747 - val_accuracy: 0.7332 - lr: 8.0000e-06\n",
      "Epoch 38/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4645 - accuracy: 0.7550\n",
      "Epoch 38: val_loss did not improve from 0.47436\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4645 - accuracy: 0.7550 - val_loss: 0.4749 - val_accuracy: 0.7332 - lr: 8.0000e-06\n",
      "Epoch 39/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.7605\n",
      "Epoch 39: val_loss improved from 0.47436 to 0.47428, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4638 - accuracy: 0.7605 - val_loss: 0.4743 - val_accuracy: 0.7332 - lr: 8.0000e-06\n",
      "Epoch 40/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4565 - accuracy: 0.7663\n",
      "Epoch 40: val_loss improved from 0.47428 to 0.47395, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4563 - accuracy: 0.7664 - val_loss: 0.4740 - val_accuracy: 0.7338 - lr: 8.0000e-06\n",
      "Epoch 41/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4626 - accuracy: 0.7627\n",
      "Epoch 41: val_loss did not improve from 0.47395\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4619 - accuracy: 0.7631 - val_loss: 0.4749 - val_accuracy: 0.7240 - lr: 8.0000e-06\n",
      "Epoch 42/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4649 - accuracy: 0.7567\n",
      "Epoch 42: val_loss did not improve from 0.47395\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4655 - accuracy: 0.7563 - val_loss: 0.4750 - val_accuracy: 0.7332 - lr: 8.0000e-06\n",
      "Epoch 43/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4654 - accuracy: 0.7612\n",
      "Epoch 43: val_loss did not improve from 0.47395\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4646 - accuracy: 0.7622 - val_loss: 0.4741 - val_accuracy: 0.7326 - lr: 8.0000e-06\n",
      "Epoch 44/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4618 - accuracy: 0.7639\n",
      "Epoch 44: val_loss did not improve from 0.47395\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4606 - accuracy: 0.7651 - val_loss: 0.4755 - val_accuracy: 0.7234 - lr: 8.0000e-06\n",
      "Epoch 45/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.7684\n",
      "Epoch 45: val_loss did not improve from 0.47395\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4577 - accuracy: 0.7680 - val_loss: 0.4748 - val_accuracy: 0.7332 - lr: 1.6000e-06\n",
      "Epoch 46/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4650 - accuracy: 0.7588\n",
      "Epoch 46: val_loss improved from 0.47395 to 0.47372, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4647 - accuracy: 0.7591 - val_loss: 0.4737 - val_accuracy: 0.7332 - lr: 1.6000e-06\n",
      "Epoch 47/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4586 - accuracy: 0.7624\n",
      "Epoch 47: val_loss did not improve from 0.47372\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4580 - accuracy: 0.7624 - val_loss: 0.4739 - val_accuracy: 0.7344 - lr: 1.6000e-06\n",
      "Epoch 48/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4627 - accuracy: 0.7602\n",
      "Epoch 48: val_loss improved from 0.47372 to 0.47337, saving model to ./drive/MyDrive/train_ckpt/spectrogram\\exp1\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4627 - accuracy: 0.7602 - val_loss: 0.4734 - val_accuracy: 0.7321 - lr: 1.6000e-06\n",
      "Epoch 49/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4656 - accuracy: 0.7581\n",
      "Epoch 49: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 3s 16ms/step - loss: 0.4644 - accuracy: 0.7588 - val_loss: 0.4750 - val_accuracy: 0.7326 - lr: 1.6000e-06\n",
      "Epoch 50/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4566 - accuracy: 0.7598\n",
      "Epoch 50: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4575 - accuracy: 0.7594 - val_loss: 0.4744 - val_accuracy: 0.7338 - lr: 1.6000e-06\n",
      "Epoch 51/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4584 - accuracy: 0.7589\n",
      "Epoch 51: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4576 - accuracy: 0.7594 - val_loss: 0.4746 - val_accuracy: 0.7344 - lr: 1.6000e-06\n",
      "Epoch 52/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4589 - accuracy: 0.7629\n",
      "Epoch 52: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4586 - accuracy: 0.7634 - val_loss: 0.4746 - val_accuracy: 0.7338 - lr: 1.6000e-06\n",
      "Epoch 53/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.7615\n",
      "Epoch 53: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4582 - accuracy: 0.7615 - val_loss: 0.4755 - val_accuracy: 0.7228 - lr: 3.2000e-07\n",
      "Epoch 54/150\n",
      "215/217 [============================>.] - ETA: 0s - loss: 0.4609 - accuracy: 0.7590\n",
      "Epoch 54: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4610 - accuracy: 0.7586 - val_loss: 0.4762 - val_accuracy: 0.7222 - lr: 3.2000e-07\n",
      "Epoch 55/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4573 - accuracy: 0.7595\n",
      "Epoch 55: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4574 - accuracy: 0.7596 - val_loss: 0.4761 - val_accuracy: 0.7234 - lr: 3.2000e-07\n",
      "Epoch 56/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4692 - accuracy: 0.7539\n",
      "Epoch 56: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4692 - accuracy: 0.7539 - val_loss: 0.4749 - val_accuracy: 0.7338 - lr: 3.2000e-07\n",
      "Epoch 57/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4604 - accuracy: 0.7618\n",
      "Epoch 57: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4604 - accuracy: 0.7618 - val_loss: 0.4742 - val_accuracy: 0.7338 - lr: 6.4000e-08\n",
      "Epoch 58/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4638 - accuracy: 0.7612\n",
      "Epoch 58: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4638 - accuracy: 0.7612 - val_loss: 0.4754 - val_accuracy: 0.7234 - lr: 6.4000e-08\n",
      "Epoch 59/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4628 - accuracy: 0.7559\n",
      "Epoch 59: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4630 - accuracy: 0.7559 - val_loss: 0.4752 - val_accuracy: 0.7240 - lr: 6.4000e-08\n",
      "Epoch 60/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4574 - accuracy: 0.7659\n",
      "Epoch 60: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4576 - accuracy: 0.7653 - val_loss: 0.4749 - val_accuracy: 0.7234 - lr: 6.4000e-08\n",
      "Epoch 61/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.7608\n",
      "Epoch 61: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4622 - accuracy: 0.7609 - val_loss: 0.4739 - val_accuracy: 0.7326 - lr: 1.2800e-08\n",
      "Epoch 62/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4554 - accuracy: 0.7591\n",
      "Epoch 62: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4554 - accuracy: 0.7591 - val_loss: 0.4760 - val_accuracy: 0.7245 - lr: 1.2800e-08\n",
      "Epoch 63/150\n",
      "214/217 [============================>.] - ETA: 0s - loss: 0.4634 - accuracy: 0.7586\n",
      "Epoch 63: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4630 - accuracy: 0.7594 - val_loss: 0.4749 - val_accuracy: 0.7344 - lr: 1.2800e-08\n",
      "Epoch 64/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4601 - accuracy: 0.7641\n",
      "Epoch 64: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4601 - accuracy: 0.7641 - val_loss: 0.4754 - val_accuracy: 0.7234 - lr: 1.2800e-08\n",
      "Epoch 65/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4639 - accuracy: 0.7545\n",
      "Epoch 65: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4635 - accuracy: 0.7552 - val_loss: 0.4750 - val_accuracy: 0.7234 - lr: 2.5600e-09\n",
      "Epoch 66/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4620 - accuracy: 0.7606\n",
      "Epoch 66: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 4s 16ms/step - loss: 0.4611 - accuracy: 0.7611 - val_loss: 0.4751 - val_accuracy: 0.7240 - lr: 2.5600e-09\n",
      "Epoch 67/150\n",
      "217/217 [==============================] - ETA: 0s - loss: 0.4582 - accuracy: 0.7625\n",
      "Epoch 67: val_loss did not improve from 0.47337\n",
      "217/217 [==============================] - 3s 16ms/step - loss: 0.4582 - accuracy: 0.7625 - val_loss: 0.4749 - val_accuracy: 0.7240 - lr: 2.5600e-09\n",
      "Epoch 68/150\n",
      "216/217 [============================>.] - ETA: 0s - loss: 0.4667 - accuracy: 0.7575\n",
      "Epoch 68: val_loss did not improve from 0.47337\n",
      "Restoring model weights from the end of the best epoch: 48.\n",
      "217/217 [==============================] - 4s 17ms/step - loss: 0.4665 - accuracy: 0.7578 - val_loss: 0.4754 - val_accuracy: 0.7234 - lr: 2.5600e-09\n",
      "Epoch 68: early stopping\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "t_trfaVvwTdA",
    "ExecuteTime": {
     "end_time": "2024-01-08T15:17:20.470493200Z",
     "start_time": "2024-01-08T15:17:20.454896800Z"
    }
   },
   "execution_count": 56,
   "outputs": []
  }
 ]
}
