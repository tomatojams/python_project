{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0507a4b",
   "metadata": {
    "id": "a0507a4b"
   },
   "source": [
    "## Use case\n",
    "\n",
    "Tagging은 다음과 같은 클래스로 문서에 라벨을 붙이는 것을 의미합니다::\n",
    "\n",
    "- sentiment 감정\n",
    "- language 언어\n",
    "- style (formal, informal etc.) 언어의 스타일\n",
    "- covered topics 다루는 주제들\n",
    "- political tendency 정치 경향성\n",
    "\n",
    "## Overview\n",
    "\n",
    "Tagging has a few components:\n",
    "\n",
    "* `function`: 추출과 마찬가지로, 태깅은 모델이 문서를 태깅하는 방법을 지정하는 함수를 사용합니다.\n",
    "* `schema`: 문서를 태깅하는 방법을 정의합니다.\n",
    "\n",
    "## Quickstart\n",
    "\n",
    "LangChain에서 OpenAI 함수를 사용하여 태깅을 어떻게 할 수 있는지에 대한 매우 간단한 예를 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5cbb6f",
   "metadata": {
    "id": "dc5cbb6f",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010867164,
     "user_tz": -540,
     "elapsed": 15436,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "b99e64dd-4338-4416-ac7f-9eed235d6033"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.0.348-py3-none-any.whl (2.0 MB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m2.0/2.0 MB\u001B[0m \u001B[31m17.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting openai\n",
      "  Downloading openai-1.3.7-py3-none-any.whl (221 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m221.4/221.4 kB\u001B[0m \u001B[31m25.5 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.23)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.1)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.6.3-py3-none-any.whl (28 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Collecting langchain-core<0.1,>=0.0.12 (from langchain)\n",
      "  Downloading langchain_core-0.0.12-py3-none-any.whl (181 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m181.5/181.5 kB\u001B[0m \u001B[31m25.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting langsmith<0.1.0,>=0.0.63 (from langchain)\n",
      "  Downloading langsmith-0.0.69-py3-none-any.whl (48 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m48.2/48.2 kB\u001B[0m \u001B[31m7.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
      "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
      "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
      "Collecting httpx<1,>=0.23.0 (from openai)\n",
      "  Downloading httpx-0.25.2-py3-none-any.whl (74 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m75.0/75.0 kB\u001B[0m \u001B[31m12.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.0)\n",
      "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.3)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.6)\n",
      "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.2.0)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.20.1-py3-none-any.whl (49 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m49.4/49.4 kB\u001B[0m \u001B[31m8.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.11.17)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
      "  Downloading httpcore-1.0.2-py3-none-any.whl (76 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m76.9/76.9 kB\u001B[0m \u001B[31m12.1 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m58.3/58.3 kB\u001B[0m \u001B[31m9.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hCollecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
      "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.1,>=0.0.12->langchain) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, jsonpointer, h11, typing-inspect, langsmith, jsonpatch, httpcore, langchain-core, httpx, dataclasses-json, openai, langchain\n",
      "\u001B[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "llmx 0.0.15a0 requires cohere, which is not installed.\n",
      "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001B[0m\u001B[31m\n",
      "\u001B[0mSuccessfully installed dataclasses-json-0.6.3 h11-0.14.0 httpcore-1.0.2 httpx-0.25.2 jsonpatch-1.33 jsonpointer-2.4 langchain-0.0.348 langchain-core-0.0.12 langsmith-0.0.69 marshmallow-3.20.1 mypy-extensions-1.0.0 openai-1.3.7 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()\n",
    "#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"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FG9scPxQgYoC",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010869244,
     "user_tz": -540,
     "elapsed": 2090,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "cf2d653d-92a3-4a7b-c7a2-65d535685c7f",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:33.145217600Z",
     "start_time": "2024-02-10T18:10:31.164046Z"
    }
   },
   "id": "FG9scPxQgYoC",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bafb496a",
   "metadata": {
    "id": "bafb496a",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:39.213731100Z",
     "start_time": "2024-02-10T18:10:37.397483900Z"
    }
   },
   "outputs": [],
   "source": [
    "from langchain.chains import create_tagging_chain, create_tagging_chain_pydantic\n",
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ca3f93",
   "metadata": {
    "id": "b8ca3f93"
   },
   "source": [
    "우리는 스키마에서 예상되는 유형과 함께 몇 가지 속성을 지정합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "39f3ce3e",
   "metadata": {
    "id": "39f3ce3e",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:39.650692300Z",
     "start_time": "2024-02-10T18:10:39.216732800Z"
    }
   },
   "outputs": [],
   "source": [
    "# Schema\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\"},\n",
    "        \"aggressiveness\": {\"type\": \"integer\"},\n",
    "        \"language\": {\"type\": \"string\"},\n",
    "    }\n",
    "}\n",
    "\n",
    "# LLM\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "chain = create_tagging_chain(schema, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5509b6a6",
   "metadata": {
    "id": "5509b6a6",
    "outputId": "2a081df9-6192-46ee-a3b5-fe9fd691ee1e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010873153,
     "user_tz": -540,
     "elapsed": 1367,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:41.389813700Z",
     "start_time": "2024-02-10T18:10:40.739348400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!',\n 'text': {'sentiment': 'positive', 'language': 'Spanish'}}"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9154474c",
   "metadata": {
    "id": "9154474c",
    "outputId": "e542f78f-29b7-45ed-e7cd-e00732a7eb49",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010874055,
     "user_tz": -540,
     "elapsed": 904,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:42.735476200Z",
     "start_time": "2024-02-10T18:10:42.194602300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Estoy muy enojado con vos! Te voy a dar tu merecido!',\n 'text': {'sentiment': 'enojado', 'aggressiveness': 1, 'language': 'es'}}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d921bb53",
   "metadata": {
    "id": "d921bb53"
   },
   "source": [
    "예제에서 볼 수 있듯이, 우리가 원하는 것을 정확하게 해석합니다.\n",
    "\n",
    "예를 들어 다른 언어로 된 감정 표현을 얻을 수 있도록 결과가 다양합니다.\n",
    "\n",
    "다음 섹션에서 이러한 결과를 제어하는 방법을 살펴보겠습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb2f83",
   "metadata": {
    "id": "bebb2f83"
   },
   "source": [
    "## Finer control\n",
    "\n",
    "스키마를 신중하게 정의하면 모델의 출력을 더 세밀하게 제어할 수 있습니다.\n",
    "\n",
    "구체적으로, 각 속성의\n",
    "\n",
    "- 각 속성에 대해 가능한 값\n",
    "- 모델이 속성을 이해하도록 하기 위한 설명\n",
    "- 반환해야 하는 필수 속성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ef0b9a",
   "metadata": {
    "id": "69ef0b9a"
   },
   "source": [
    "다음은 앞서 언급한 각 측면을 제어하기 위해 `_enum_`, `_description_` 및 `_required_`를 사용하는 방법의 예시입니다:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a5f7961",
   "metadata": {
    "id": "6a5f7961",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:49.997775Z",
     "start_time": "2024-02-10T18:10:49.980607700Z"
    }
   },
   "outputs": [],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"aggressiveness\": {\n",
    "            \"type\": \"integer\",\n",
    "            \"enum\": [1, 2, 3, 4, 5],\n",
    "            \"description\": \"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        },\n",
    "        \"language\": {\n",
    "            \"type\": \"string\",\n",
    "            \"enum\": [\"spanish\", \"english\", \"french\", \"german\", \"italian\"],\n",
    "        },\n",
    "    },\n",
    "    \"required\": [\"language\", \"aggressiveness\"],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5a5881f",
   "metadata": {
    "id": "e5a5881f",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:51.737657600Z",
     "start_time": "2024-02-10T18:10:51.708347500Z"
    }
   },
   "outputs": [],
   "source": [
    "chain = create_tagging_chain(schema, llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ded2332",
   "metadata": {
    "id": "5ded2332"
   },
   "source": [
    "이제 답변이 훨씬 더 좋아졌습니다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d9b9d53d",
   "metadata": {
    "id": "d9b9d53d",
    "outputId": "b68c9347-4418-4095-8f11-c3fa5113c4a6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010875076,
     "user_tz": -540,
     "elapsed": 1023,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:10:58.339493900Z",
     "start_time": "2024-02-10T18:10:56.947631200Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": "{'aggressiveness': '3', 'language': 'spanish'}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy increiblemente contento de haberte conocido! Creo que seremos muy buenos amigos!\"\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1c12fa00",
   "metadata": {
    "id": "1c12fa00",
    "outputId": "3b40c02e-188f-4db2-d011-60ca79c69dc0",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010875930,
     "user_tz": -540,
     "elapsed": 856,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:11:02.508937700Z",
     "start_time": "2024-02-10T18:11:01.388336900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'aggressiveness': '5', 'language': 'spanish'}"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0bdfcb05",
   "metadata": {
    "id": "0bdfcb05",
    "outputId": "2595228d-9be3-45f4-beee-0f44e7353eec",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010876959,
     "user_tz": -540,
     "elapsed": 1031,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:11:03.782038100Z",
     "start_time": "2024-02-10T18:11:03.185491400Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'aggressiveness': '3', 'language': 'english'}"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp = \"Weather is ok here, I can go outside without much more than a coat\"\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68ad17e",
   "metadata": {
    "id": "e68ad17e"
   },
   "source": [
    "## Pydantic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5970ec",
   "metadata": {
    "id": "2f5970ec"
   },
   "source": [
    "또한 Pydantic 스키마를 사용하여 필요한 속성 및 유형을 지정할 수도 있습니다.\n",
    "\n",
    "열거형` 또는 `설명`과 같은 다른 인수를 각 필드에 보낼 수도 있습니다.\n",
    "\n",
    "이렇게 하면 파이썬에서 순전히 파이썬 타입으로 새 클래스나 함수를 만들 때와 같은 방식으로 스키마를 지정할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bf1f367e",
   "metadata": {
    "id": "bf1f367e",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:11:06.496332200Z",
     "start_time": "2024-02-10T18:11:06.482877500Z"
    }
   },
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "83a2e826",
   "metadata": {
    "id": "83a2e826",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:00.886424500Z",
     "start_time": "2024-02-10T18:12:00.767586900Z"
    }
   },
   "outputs": [],
   "source": [
    "class Tags(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    aggressiveness: int = Field(\n",
    "        ...,\n",
    "        description=\"describes how aggressive the statement is, the higher the number the more aggressive\",\n",
    "        enum=[1, 2, 3, 4, 5],\n",
    "    )\n",
    "    language: str = Field(\n",
    "        ..., enum=[\"spanish\", \"english\", \"french\", \"german\", \"italian\"]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# !pip show langchain"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:01.950262900Z",
     "start_time": "2024-02-10T18:12:01.933612600Z"
    }
   },
   "id": "58a9dd1efa67ed64",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e404892",
   "metadata": {
    "id": "6e404892",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:02.621741800Z",
     "start_time": "2024-02-10T18:12:02.574822Z"
    }
   },
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[17], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_tagging_chain_pydantic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain\\chains\\openai_functions\\tagging.py:81\u001B[0m, in \u001B[0;36mcreate_tagging_chain_pydantic\u001B[1;34m(pydantic_schema, llm, prompt, **kwargs)\u001B[0m\n\u001B[0;32m     79\u001B[0m function \u001B[38;5;241m=\u001B[39m _get_tagging_function(openai_schema)\n\u001B[0;32m     80\u001B[0m prompt \u001B[38;5;241m=\u001B[39m prompt \u001B[38;5;129;01mor\u001B[39;00m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(_TAGGING_TEMPLATE)\n\u001B[1;32m---> 81\u001B[0m output_parser \u001B[38;5;241m=\u001B[39m \u001B[43mPydanticOutputFunctionsParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpydantic_schema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpydantic_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m llm_kwargs \u001B[38;5;241m=\u001B[39m get_llm_kwargs(function)\n\u001B[0;32m     83\u001B[0m chain \u001B[38;5;241m=\u001B[39m LLMChain(\n\u001B[0;32m     84\u001B[0m     llm\u001B[38;5;241m=\u001B[39mllm,\n\u001B[0;32m     85\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     89\u001B[0m )\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[0;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[1;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[1;31mValidationError\u001B[0m: 2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ],
   "source": [
    "chain = create_tagging_chain_pydantic(Tags, llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b5fc43c4",
   "metadata": {
    "id": "b5fc43c4",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:23.713789Z",
     "start_time": "2024-02-10T18:12:22.532741700Z"
    }
   },
   "outputs": [],
   "source": [
    "inp = \"Estoy muy enojado con vos! Te voy a dar tu merecido!\"\n",
    "res = chain.run(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5074bcc3",
   "metadata": {
    "id": "5074bcc3",
    "outputId": "49264d62-fb32-427b-88fc-2d039b4c58f6",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010878017,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:24.250166700Z",
     "start_time": "2024-02-10T18:12:24.219746300Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'aggressiveness': '5', 'language': 'spanish'}"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 연습문제\n",
    "### 1. 스키마 정의\n",
    "* 특정 태깅 요구에 맞게 스키마를 맞춤화하는 방법을 이해합니다.\n",
    "\n",
    "\n",
    "```\n",
    "1. 스키마 개념 이해: 스키마가 태깅 시스템에서 어떻게 사용되는지 이해합니다. 스키마는 문서의 특정 속성을 정의하며, 이를 통해 모델이 어떤 정보를 추출하고 태깅할지 결정합니다.\n",
    "\n",
    "2. 속성 선택: 유머, 격식, 주제 관련성 등의 속성을 선택합니다. 각 속성이 문서에 어떻게 나타날 수 있는지 생각해 봅니다.\n",
    "\n",
    "3. 스키마 정의: 선택한 속성을 바탕으로 JSON 형식의 스키마를 작성합니다.\n",
    "예를 들어, humor는 \"none\", \"some\", \"a lot\"과 같이, 격식은 \"informal\", \"neutral\", \"formal\"과 같이, 주제 관련성은 주제 목록을 포함하도록 할 수 있습니다.\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "ihjuCS3zJdg6"
   },
   "id": "ihjuCS3zJdg6"
  },
  {
   "cell_type": "code",
   "source": [
    "# 새로운 스키마 정의\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"humor\": {\"type\": \"string\", \"enum\": [\"none\", \"some\", \"a lot\"]},\n",
    "        \"formality\": {\"type\": \"string\", \"enum\": [\"informal\", \"neutral\", \"formal\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 언어 모델 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "# 태깅 체인 생성\n",
    "chain = create_tagging_chain(schema, llm)\n",
    "\n",
    "# 태깅을 위한 입력 문서\n",
    "inputs = [\n",
    "    \"This is a very formal document discussing scientific research.\",\n",
    "    \"Hey there! Just chilling and having fun with AI.\"\n",
    "]\n",
    "\n",
    "# 각 입력에 대해 태깅 실행\n",
    "for inp in inputs:\n",
    "    result = chain.run(inp)\n",
    "    print(f\"Input: {inp}\\nTagged Output: {result}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Gg_fpbiJfUc",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010879963,
     "user_tz": -540,
     "elapsed": 1949,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "520a9af7-329a-4028-af46-00ec064f6e94",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:32.565531200Z",
     "start_time": "2024-02-10T18:12:30.551661Z"
    }
   },
   "id": "3Gg_fpbiJfUc",
   "execution_count": 20,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: This is a very formal document discussing scientific research.\n",
      "Tagged Output: {'formality': 'formal'}\n",
      "Input: Hey there! Just chilling and having fun with AI.\n",
      "Tagged Output: {'humor': 'some', 'formality': 'informal'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#pydantic\n",
    "class Tags(BaseModel):\n",
    "    humor: str = Field(..., enum=[\"none\", \"some\", \"a lot\"])\n",
    "    formality: str = Field(..., enum=[\"informal\", \"neutral\", \"formal\"])\n",
    "\n",
    "# 언어 모델 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "# 태깅 체인 생성\n",
    "chain = create_tagging_chain_pydantic(Tags, llm)\n",
    "\n",
    "# 태깅을 위한 입력 문서\n",
    "inputs = [\n",
    "    \"This is a very formal document discussing scientific research.\",\n",
    "    \"Hey there! Just chilling and having fun with AI.\"\n",
    "]\n",
    "\n",
    "# 각 입력에 대해 태깅 실행\n",
    "for inp in inputs:\n",
    "    result = chain.run(inp)\n",
    "    print(f\"Input: {inp}\\nTagged Output: {inp}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dqGnzHGYwVAZ",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702010955304,
     "user_tz": -540,
     "elapsed": 2564,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "2814cb47-6746-40bb-b354-777b0016ca5d",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:12:49.357172800Z",
     "start_time": "2024-02-10T18:12:48.899645600Z"
    }
   },
   "id": "dqGnzHGYwVAZ",
   "execution_count": 21,
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 10\u001B[0m\n\u001B[0;32m      7\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOpenAI(temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo-0613\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m      9\u001B[0m \u001B[38;5;66;03m# 태깅 체인 생성\u001B[39;00m\n\u001B[1;32m---> 10\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_tagging_chain_pydantic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m \u001B[38;5;66;03m# 태깅을 위한 입력 문서\u001B[39;00m\n\u001B[0;32m     13\u001B[0m inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     14\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is a very formal document discussing scientific research.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     15\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mHey there! Just chilling and having fun with AI.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     16\u001B[0m ]\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain\\chains\\openai_functions\\tagging.py:81\u001B[0m, in \u001B[0;36mcreate_tagging_chain_pydantic\u001B[1;34m(pydantic_schema, llm, prompt, **kwargs)\u001B[0m\n\u001B[0;32m     79\u001B[0m function \u001B[38;5;241m=\u001B[39m _get_tagging_function(openai_schema)\n\u001B[0;32m     80\u001B[0m prompt \u001B[38;5;241m=\u001B[39m prompt \u001B[38;5;129;01mor\u001B[39;00m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(_TAGGING_TEMPLATE)\n\u001B[1;32m---> 81\u001B[0m output_parser \u001B[38;5;241m=\u001B[39m \u001B[43mPydanticOutputFunctionsParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpydantic_schema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpydantic_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m llm_kwargs \u001B[38;5;241m=\u001B[39m get_llm_kwargs(function)\n\u001B[0;32m     83\u001B[0m chain \u001B[38;5;241m=\u001B[39m LLMChain(\n\u001B[0;32m     84\u001B[0m     llm\u001B[38;5;241m=\u001B[39mllm,\n\u001B[0;32m     85\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     89\u001B[0m )\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[0;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[1;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[1;31mValidationError\u001B[0m: 2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 입력처리\n",
    "* 다양한 입력에 대해 태깅 모델의 출력을 처리하고 해석하는 연습을 합니다.\n",
    "* 다양한 언어와 스타일로 된 다양한 입력을 생성하고, 이를 태깅 체인을 사용하여 태그를 붙입니다.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "1. 다양한 입력 준비: 서로 다른 언어, 스타일, 주제를 가진 여러 텍스트 문서를 준비합니다.\n",
    "예를 들어, 감성적인 일기, 공식적인 비즈니스 보고서, 비공식적인 대화 등을 포함할 수 있습니다.\n",
    "\n",
    "2. 태깅 체인 설정: 이미 만들어진 태깅 체인을 사용하거나, 필요에 따라 새로운 스키마를 정의하여 태깅 체인을 설정합니다.\n",
    "\n",
    "3. 태깅 실행: 준비한 각 입력에 대해 태깅 체인을 실행합니다. 이때 각 입력에 대해 태그된 결과를 기록합니다.\n",
    "\n",
    "4. 결과 분석: 태깅 결과를 분석하여 모델이 어떻게 다양한 스타일과 언어의 입력을 처리하는지 관찰합니다. 모델이 잘 처리하는 부분과 개선이 필요한 부분을 식별합니다.\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "J-gH07lTLNX7"
   },
   "id": "J-gH07lTLNX7"
  },
  {
   "cell_type": "code",
   "source": [
    "# 태깅을 위한 스키마 (기존에 정의된 스키마 사용)\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"sentiment\": {\"type\": \"string\", \"enum\": [\"happy\", \"neutral\", \"sad\"]},\n",
    "        \"language\": {\"type\": \"string\",\n",
    "                     \"enum\": [\"english\", \"korean\", \"japanese\", \"french\", \"spanish\"]},\n",
    "        \"formality\": {\"type\": \"string\", \"enum\": [\"informal\", \"neutral\", \"formal\"]}\n",
    "    }\n",
    "}\n",
    "\n",
    "# 언어 모델 생성\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "# 태깅 체인 생성\n",
    "chain = create_tagging_chain(schema, llm)\n",
    "\n",
    "# 다양한 언어와 스타일의 입력\n",
    "inputs = [\n",
    "    \"오늘은 정말 기분이 좋아. 친구들과 함께 즐거운 시간을 보냈어.\",\n",
    "    \"This is an official document regarding the financial report of the last quarter.\",\n",
    "    \"Salut! Comment ça va? Je suis très excité pour le match ce soir!\",\n",
    "    \"Gestern war ein anstrengender Tag, aber ich habe viel erreicht.\",\n",
    "    \"¿Cómo se podría mejorar el rendimiento de nuestro equipo?\",\n",
    "    \"忙しい一日だったけど、とても充実していたよ。\"\n",
    "]\n",
    "\n",
    "# 각 입력에 대해 태깅 실행\n",
    "for inp in inputs:\n",
    "    result = chain.run(inp)\n",
    "    print(f\"Input: {inp}\\nTagged Output: {result}\\n\")"
   ],
   "metadata": {
    "id": "FMrm6VjNKE3D",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702011827419,
     "user_tz": -540,
     "elapsed": 5766,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "314dbfa2-4fb0-4aa4-bb20-e19591797212",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:13:07.934201300Z",
     "start_time": "2024-02-10T18:13:02.579077500Z"
    }
   },
   "id": "FMrm6VjNKE3D",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: 오늘은 정말 기분이 좋아. 친구들과 함께 즐거운 시간을 보냈어.\n",
      "Tagged Output: {'sentiment': 'happy', 'language': 'korean'}\n",
      "Input: This is an official document regarding the financial report of the last quarter.\n",
      "Tagged Output: {}\n",
      "Input: Salut! Comment ça va? Je suis très excité pour le match ce soir!\n",
      "Tagged Output: {'sentiment': 'excited', 'formality': 'informal', 'language': 'french'}\n",
      "Input: Gestern war ein anstrengender Tag, aber ich habe viel erreicht.\n",
      "Tagged Output: {'sentiment': 'neutral', 'language': 'german', 'formality': 'neutral'}\n",
      "Input: ¿Cómo se podría mejorar el rendimiento de nuestro equipo?\n",
      "Tagged Output: {'language': 'spanish'}\n",
      "Input: 忙しい一日だったけど、とても充実していたよ。\n",
      "Tagged Output: {'sentiment': 'happy', 'language': 'japanese', 'formality': 'informal'}\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# dydantic class\n",
    "class Tags(BaseModel):\n",
    "    sentiment: str = Field(..., enum=[\"happy\", \"neutral\", \"sad\"])\n",
    "    language: str = Field(..., enum=[\"english\", \"korean\", \"japanese\", \"french\", \"spanish\"])\n",
    "    formality: str = Field(..., enum=[\"informal\", \"neutral\", \"formal\"])\n",
    "\n",
    "\n",
    "# 언어 모델 생성\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo-0613\")\n",
    "\n",
    "# 태깅 체인 생성\n",
    "chain = create_tagging_chain_pydantic(Tags, llm)\n",
    "\n",
    "# 다양한 언어와 스타일의 입력\n",
    "inputs = [\n",
    "    \"오늘은 정말 기분이 좋아. 친구들과 함께 즐거운 시간을 보냈어.\",\n",
    "    \"This is an official document regarding the financial report of the last quarter.\",\n",
    "    \"Salut! Comment ça va? Je suis très excité pour le match ce soir!\",\n",
    "    \"Gestern war ein anstrengender Tag, aber ich habe viel erreicht.\",\n",
    "    \"¿Cómo se podría mejorar el rendimiento de nuestro equipo?\",\n",
    "    \"忙しい一日だったけど、とても充実していたよ。\"\n",
    "]\n",
    "\n",
    "# 각 입력에 대해 태깅 실행\n",
    "for inp in inputs:\n",
    "    result = chain.run(inp)\n",
    "    print(f\"Input: {inp}\\nTagged Output: {result}\\n\")"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5veDfGVsxGch",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1702011898136,
     "user_tz": -540,
     "elapsed": 6414,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "84d94869-031a-4da2-b40b-9b2d2502d58b",
    "ExecuteTime": {
     "end_time": "2024-02-10T18:13:13.789014900Z",
     "start_time": "2024-02-10T18:13:13.259830100Z"
    }
   },
   "id": "5veDfGVsxGch",
   "execution_count": 23,
   "outputs": [
    {
     "ename": "ValidationError",
     "evalue": "2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValidationError\u001B[0m                           Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[23], line 12\u001B[0m\n\u001B[0;32m      9\u001B[0m llm \u001B[38;5;241m=\u001B[39m ChatOpenAI(temperature\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.7\u001B[39m, model\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mgpt-3.5-turbo-0613\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     11\u001B[0m \u001B[38;5;66;03m# 태깅 체인 생성\u001B[39;00m\n\u001B[1;32m---> 12\u001B[0m chain \u001B[38;5;241m=\u001B[39m \u001B[43mcreate_tagging_chain_pydantic\u001B[49m\u001B[43m(\u001B[49m\u001B[43mTags\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mllm\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 다양한 언어와 스타일의 입력\u001B[39;00m\n\u001B[0;32m     15\u001B[0m inputs \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m     16\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m오늘은 정말 기분이 좋아. 친구들과 함께 즐거운 시간을 보냈어.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m     17\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis is an official document regarding the financial report of the last quarter.\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     21\u001B[0m     \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m忙しい一日だったけど、とても充実していたよ。\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     22\u001B[0m ]\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain\\chains\\openai_functions\\tagging.py:81\u001B[0m, in \u001B[0;36mcreate_tagging_chain_pydantic\u001B[1;34m(pydantic_schema, llm, prompt, **kwargs)\u001B[0m\n\u001B[0;32m     79\u001B[0m function \u001B[38;5;241m=\u001B[39m _get_tagging_function(openai_schema)\n\u001B[0;32m     80\u001B[0m prompt \u001B[38;5;241m=\u001B[39m prompt \u001B[38;5;129;01mor\u001B[39;00m ChatPromptTemplate\u001B[38;5;241m.\u001B[39mfrom_template(_TAGGING_TEMPLATE)\n\u001B[1;32m---> 81\u001B[0m output_parser \u001B[38;5;241m=\u001B[39m \u001B[43mPydanticOutputFunctionsParser\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpydantic_schema\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mpydantic_schema\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     82\u001B[0m llm_kwargs \u001B[38;5;241m=\u001B[39m get_llm_kwargs(function)\n\u001B[0;32m     83\u001B[0m chain \u001B[38;5;241m=\u001B[39m LLMChain(\n\u001B[0;32m     84\u001B[0m     llm\u001B[38;5;241m=\u001B[39mllm,\n\u001B[0;32m     85\u001B[0m     prompt\u001B[38;5;241m=\u001B[39mprompt,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m     88\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs,\n\u001B[0;32m     89\u001B[0m )\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\langchain_core\\load\\serializable.py:107\u001B[0m, in \u001B[0;36mSerializable.__init__\u001B[1;34m(self, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs: Any) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 107\u001B[0m     \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)\n\u001B[0;32m    108\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lc_kwargs \u001B[38;5;241m=\u001B[39m kwargs\n",
      "File \u001B[1;32mF:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\pydantic\\v1\\main.py:341\u001B[0m, in \u001B[0;36mBaseModel.__init__\u001B[1;34m(__pydantic_self__, **data)\u001B[0m\n\u001B[0;32m    339\u001B[0m values, fields_set, validation_error \u001B[38;5;241m=\u001B[39m validate_model(__pydantic_self__\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m, data)\n\u001B[0;32m    340\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m validation_error:\n\u001B[1;32m--> 341\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m validation_error\n\u001B[0;32m    342\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m    343\u001B[0m     object_setattr(__pydantic_self__, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__dict__\u001B[39m\u001B[38;5;124m'\u001B[39m, values)\n",
      "\u001B[1;31mValidationError\u001B[0m: 2 validation errors for PydanticOutputFunctionsParser\npydantic_schema\n  subclass of BaseModel expected (type=type_error.subclass; expected_class=BaseModel)\npydantic_schema\n  value is not a valid dict (type=type_error.dict)"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "7V_WU1IIMhdB"
   },
   "id": "7V_WU1IIMhdB",
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/langchain-ai/langchain/blob/master/docs/docs/use_cases/tagging.ipynb",
     "timestamp": 1701661591743
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
