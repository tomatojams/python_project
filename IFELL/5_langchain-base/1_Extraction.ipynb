{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b84edb4e",
   "metadata": {
    "id": "b84edb4e"
   },
   "source": [
    "## Use case\n",
    "\n",
    "Raw LLM 생성에서 구조화된 출력을 얻는 것은 어렵습니다.\n",
    "\n",
    "예를 들어, 특정 스키마로 포맷된 모델 출력이 필요하다고 가정해 보겠습니다:\n",
    "\n",
    "- 데이터베이스에 삽입할 구조화된 행을 추출하는 경우\n",
    "- API 매개변수 추출\n",
    "- 사용자 쿼리의 다른 부분 추출(예: 시맨틱 검색과 키워드 검색)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f474d4",
   "metadata": {
    "id": "97f474d4"
   },
   "source": [
    "## Overview\n",
    "\n",
    "이를 위한 두 가지 주요 접근 방식이 있습니다:\n",
    "\n",
    "- `Functions`: 일부 LLM은 functions를 호출하여 LLM 응답에서 임의의 엔티티를 추출할 수 있습니다.\n",
    "\n",
    "- `Parsing`: 출력 구문 분석기는 LLM 응답을 구조화하는 클래스입니다.\n",
    "\n",
    "일부 LLM만 함수(예: OpenAI)를 지원하며, 파서보다 더 일반적입니다.\n",
    "\n",
    "구문 분석기는 제공된 스키마에 열거된 내용(예: 사람의 특정 속성)을 정확하게 추출합니다.\n",
    "\n",
    "함수는 제공된 스키마 이외의 것(예: 사용자가 요청하지 않은 사람에 대한 속성)을 추론할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25d89f21",
   "metadata": {
    "id": "25d89f21"
   },
   "source": [
    "## Quickstart\n",
    "\n",
    "OpenAI 함수는 추출을 시작하는 한 가지 방법입니다.\n",
    "\n",
    "LLM 출력에서 추출할 속성을 지정하는 스키마를 정의합니다.\n",
    "\n",
    "그런 다음 `create_extraction_chain`을 사용하여 OpenAI 함수 호출을 통해 원하는 스키마를 추출할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f5ec7a3",
   "metadata": {
    "id": "3f5ec7a3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144389736,
     "user_tz": -540,
     "elapsed": 28350,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "f9a3b0c4-ad0f-4391-873e-139d5904c556",
    "ExecuteTime": {
     "end_time": "2024-02-01T01:18:44.722904Z",
     "start_time": "2024-02-01T01:18:42.414695Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (0.1.4)\r\n",
      "Requirement already satisfied: openai in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (1.10.0)\r\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (6.0)\r\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.0.25)\r\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (3.9.1)\r\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (4.0.3)\r\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.6.3)\r\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (1.33)\r\n",
      "Requirement already satisfied: langchain-community<0.1,>=0.0.14 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.0.16)\r\n",
      "Requirement already satisfied: langchain-core<0.2,>=0.1.16 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.1.16)\r\n",
      "Requirement already satisfied: langsmith<0.1,>=0.0.83 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (0.0.83)\r\n",
      "Requirement already satisfied: numpy<2,>=1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (1.23.2)\r\n",
      "Requirement already satisfied: pydantic<3,>=1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.5.3)\r\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (2.31.0)\r\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain) (8.2.3)\r\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (3.5.0)\r\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (1.9.0)\r\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (0.26.0)\r\n",
      "Requirement already satisfied: sniffio in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (1.2.0)\r\n",
      "Requirement already satisfied: tqdm>4 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (4.66.1)\r\n",
      "Requirement already satisfied: typing-extensions<5,>=4.7 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from openai) (4.9.0)\r\n",
      "Requirement already satisfied: attrs>=17.3.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (22.1.0)\r\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\r\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\r\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\r\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\r\n",
      "Requirement already satisfied: idna>=2.8 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from anyio<5,>=3.5.0->openai) (3.4)\r\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.2)\r\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\r\n",
      "Requirement already satisfied: certifi in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\r\n",
      "Requirement already satisfied: httpcore==1.* in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\r\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\r\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\r\n",
      "Requirement already satisfied: packaging<24.0,>=23.2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from langchain-core<0.2,>=0.1.16->langchain) (23.2)\r\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (0.6.0)\r\n",
      "Requirement already satisfied: pydantic-core==2.14.6 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from pydantic<3,>=1->langchain) (2.14.6)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests<3,>=2->langchain) (3.1.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from requests<3,>=2->langchain) (2.1.0)\r\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /Users/soma/anaconda3/envs/tensor2/lib/python3.9/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain openai"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "import getpass\n",
    "import os\n",
    "# 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\n",
    "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8mU8PR67jPR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144394566,
     "user_tz": -540,
     "elapsed": 4845,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "c74caa70-7ef8-4170-99e3-93f12214c92e",
    "ExecuteTime": {
     "end_time": "2024-02-09T06:12:21.996809Z",
     "start_time": "2024-02-09T06:12:19.708577Z"
    }
   },
   "id": "l8mU8PR67jPR",
   "execution_count": 1,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ba4cd2d3e1b28a59"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3e017ba0",
   "metadata": {
    "id": "3e017ba0",
    "outputId": "27b40dd4-7a02-420e-d804-8396e1ff39ed",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144401983,
     "user_tz": -540,
     "elapsed": 7423,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:12:42.094036Z",
     "start_time": "2024-02-09T06:12:38.497169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.',\n 'text': [{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n  {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import create_extraction_chain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Schema\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"height\": {\"type\": \"integer\"},\n",
    "        \"hair_color\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"name\", \"height\"],\n",
    "}\n",
    "\n",
    "# Input\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "\n",
    "# Run chain\n",
    "llm = ChatOpenAI(temperature=0.7, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f7eb826",
   "metadata": {
    "id": "6f7eb826"
   },
   "source": [
    "## Option 1: OpenAI functions\n",
    "\n",
    "### Looking under the hood\n",
    "\n",
    "`create_extraction_chain` 호출할 때 어떤 일이 일어나는지 자세히 살펴봅시다.\n",
    "\n",
    "이 `정보_추출` 함수는 [여기](https://github.com/langchain-ai/langchain/blob/master/libs/langchain/langchain/chains/openai_functions/extraction.py)에 정의되어 있으며 딕셔너리를 반환합니다.\n",
    "\n",
    "\n",
    "모델 출력에서 `dict`를 볼 수 있습니다:\n",
    "```\n",
    " {\n",
    "      \"info\": [\n",
    "        {\n",
    "          \"name\": \"Alex\",\n",
    "          \"height\": 5,\n",
    "          \"hair_color\": \"blonde\"\n",
    "        },\n",
    "        {\n",
    "          \"name\": \"Claudia\",\n",
    "          \"height\": 6,\n",
    "          \"hair_color\": \"brunette\"\n",
    "        }\n",
    "      ]\n",
    "    }\n",
    "```\n",
    "\n",
    "그런 다음 `create_extraction_chain`은 [`JsonKeyOutputFunctionsParser`](https://github.com/langchain-ai/langchain/blob/f81e613086d211327b67b0fb591fd4d5f9a85860/libs/langchain/langchain/chains/openai_functions/extraction.py#L62)를 사용하여 원시 LLM 출력을 파싱합니다.\n",
    "\n",
    "그 결과 위의 체인에서 반환된 JSON 객체 목록이 생성됩니다:\n",
    "```\n",
    "[{'name': 'Alex', 'height': 5, 'hair_color': 'blonde'},\n",
    " {'name': 'Claudia', 'height': 6, 'hair_color': 'brunette'}]\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcb03138",
   "metadata": {
    "id": "dcb03138"
   },
   "source": [
    "### Multiple entity types\n",
    "\n",
    "이를 더 확장할 수 있습니다.\n",
    "\n",
    "개와 사람을 구분하고 싶다고 가정해 봅시다.\n",
    "\n",
    "각 속성에 `person_` 및 `dog_` 접두사를 추가하면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01eae733",
   "metadata": {
    "id": "01eae733",
    "outputId": "0b4524a3-2cf7-4f6f-d4b0-c8476cb18db5",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144408194,
     "user_tz": -540,
     "elapsed": 6216,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:12:59.763931Z",
     "start_time": "2024-02-09T06:12:55.286453Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': \"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nAlex's dog Frosty is a labrador and likes to play hide and seek.\",\n 'text': [{'person_name': 'Alex',\n   'person_height': 5,\n   'person_hair_color': 'blonde',\n   'dog_name': 'Frosty',\n   'dog_breed': 'labrador'},\n  {'person_name': 'Claudia',\n   'person_height': 6,\n   'person_hair_color': 'brunette'}]}"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [\"person_name\", \"person_height\"],\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Alex's dog Frosty is a labrador and likes to play hide and seek.\"\"\"\n",
    "\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f205905c",
   "metadata": {
    "id": "f205905c"
   },
   "source": [
    "### Unrelated entities\n",
    "\n",
    "`필수: []`를 사용하면 모델이 단일 엔티티(사람 또는 개)에 대해 **사람 속성만** 또는  **개 속성만**을 반환하도록 허용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ff4ac7e",
   "metadata": {
    "id": "6ff4ac7e",
    "outputId": "8a78b286-673d-4aee-aa09-8dc119261671",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144415191,
     "user_tz": -540,
     "elapsed": 7003,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:13:14.964842Z",
     "start_time": "2024-02-09T06:13:08.979941Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\\nWillow is a German Shepherd that likes to play with other dogs and can always be found playing with Milo, a border collie that lives close by.',\n 'text': [{'person_name': 'Alex',\n   'person_height': 5,\n   'person_hair_color': 'blonde'},\n  {'person_name': 'Claudia',\n   'person_height': 6,\n   'person_hair_color': 'brunette'},\n  {'dog_name': 'Willow', 'dog_breed': 'German Shepherd'},\n  {'dog_name': 'Milo', 'dog_breed': 'Border Collie'}]}"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "    },\n",
    "    \"required\": [],\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\n",
    "Willow is a German Shepherd that likes to play with other dogs and can always be found playing with Milo, a border collie that lives close by.\"\"\"\n",
    "\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f3b958",
   "metadata": {
    "id": "34f3b958"
   },
   "source": [
    "### Extra information\n",
    "\n",
    "The power of functions (파서만 사용할 때와 비교했을 때) 의미 추출을 수행할 수 있는 능력에 있습니다.\n",
    "\n",
    "특히 '스키마에 명시적으로 열거되지 않은 것을 요청할 수 있다'는 점입니다.\n",
    "\n",
    "개에 대한 지정되지 않은 추가 정보를 원한다고 가정해 봅시다.\n",
    "\n",
    "비정형 추출을 위한 자리 표시자인 `dog_extra_info`를 추가할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "40c7b26f",
   "metadata": {
    "id": "40c7b26f",
    "outputId": "8fdc7ef7-9fe9-4d0d-901e-4bb499ac50c2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144424605,
     "user_tz": -540,
     "elapsed": 9416,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:13:27.610947Z",
     "start_time": "2024-02-09T06:13:20.539506Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "[{'person_name': 'Alex', 'person_height': 5, 'person_hair_color': 'blonde'},\n {'person_name': 'Claudia',\n  'person_height': 6,\n  'person_hair_color': 'brunette'},\n {'dog_name': 'Willow',\n  'dog_breed': 'German Shepherd',\n  'dog_extra_info': 'likes to play with other dogs'},\n {'dog_name': 'Milo',\n  'dog_breed': 'border collie',\n  'dog_extra_info': 'lives close by'}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"person_name\": {\"type\": \"string\"},\n",
    "        \"person_height\": {\"type\": \"integer\"},\n",
    "        \"person_hair_color\": {\"type\": \"string\"},\n",
    "        \"dog_name\": {\"type\": \"string\"},\n",
    "        \"dog_breed\": {\"type\": \"string\"},\n",
    "        \"dog_extra_info\": {\"type\": \"string\"},\n",
    "    },\n",
    "}\n",
    "\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "chain.run(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a949c60",
   "metadata": {
    "id": "3a949c60"
   },
   "source": [
    "이를 통해 개에 대한 추가 정보를 얻을 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf71ddce",
   "metadata": {
    "id": "bf71ddce"
   },
   "source": [
    "### Pydantic\n",
    "\n",
    "Pydantic은 Python용 데이터 유효성 검사 및 설정 관리 라이브러리입니다.\n",
    "\n",
    "이 라이브러리를 사용하면 객체를 인스턴스화할 때 자동으로 유효성이 검사되는 속성을 가진 데이터 클래스를 만들 수 있습니다.\n",
    "\n",
    "유형으로 주석이 달린 속성을 가진 클래스를 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d36a743b",
   "metadata": {
    "id": "d36a743b",
    "outputId": "6f187478-c7da-4b4b-90b6-9b4fcb201538",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144429483,
     "user_tz": -540,
     "elapsed": 4898,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:13:46.090257Z",
     "start_time": "2024-02-09T06:13:41.974134Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "{'input': 'Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.',\n 'text': [Properties(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None),\n  Properties(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)]}"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from langchain.chains import create_extraction_chain_pydantic\n",
    "from langchain.pydantic_v1 import BaseModel\n",
    "\n",
    "\n",
    "# Pydantic data class\n",
    "class Properties(BaseModel):\n",
    "    person_name: str\n",
    "    person_height: int\n",
    "    person_hair_color: str\n",
    "    dog_breed: Optional[str]\n",
    "    dog_name: Optional[str]\n",
    "\n",
    "\n",
    "# Extraction\n",
    "chain = create_extraction_chain_pydantic(pydantic_schema=Properties, llm=llm)\n",
    "\n",
    "# Run\n",
    "inp = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "chain.invoke(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a0351a",
   "metadata": {
    "id": "07a0351a"
   },
   "source": [
    "trace에서 볼 수 있듯이, 위와 같이 Pydantic 스키마와 함께 `information_extraction` 함수를 사용합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbd9f121",
   "metadata": {
    "id": "cbd9f121"
   },
   "source": [
    "## 옵션 2: 파싱\n",
    "\n",
    "출력 구문 분석기는 언어 모델 응답을 구조화하는 데 도움이 되는 클래스입니다.\n",
    "\n",
    "위에 표시된 것처럼 `create_extraction_chain`에서 OpenAI 함수 호출의 출력을 구문 분석하는 데 사용됩니다.\n",
    "\n",
    "하지만 함수와 독립적으로 사용할 수도 있습니다.\n",
    "\n",
    "### Pydantic\n",
    "\n",
    "위와 마찬가지로 Pydantic 데이터 클래스를 기반으로 한 세대를 파싱해 보겠습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "64650362",
   "metadata": {
    "id": "64650362",
    "outputId": "33d9f2c8-0c99-41a0-ca7a-00a4948c743b",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144431765,
     "user_tz": -540,
     "elapsed": 2288,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:16:41.917494Z",
     "start_time": "2024-02-09T06:16:39.754583Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "People(people=[Person(person_name='Alex', person_height=5, person_hair_color='blonde', dog_breed=None, dog_name=None), Person(person_name='Claudia', person_height=6, person_hair_color='brunette', dog_breed=None, dog_name=None)])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Optional, Sequence\n",
    "# from langchain_openai import OpenAI\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    ")\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "class Person(BaseModel):\n",
    "    person_name: str\n",
    "    person_height: int\n",
    "    person_hair_color: str\n",
    "    dog_breed: Optional[str]\n",
    "    dog_name: Optional[str]\n",
    "\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Identifying information about all people in a text.\"\"\"\n",
    "\n",
    "    people: Sequence[Person]\n",
    "\n",
    "\n",
    "# Run\n",
    "query = \"\"\"Alex is 5 feet tall. Claudia is 1 feet taller Alex and jumps higher than him. Claudia is a brunette and Alex is blonde.\"\"\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "# print(parser.get_format_instructions())\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=query)\n",
    "# print(_input)\n",
    "model = OpenAI(temperature=0)\n",
    "output = model(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826899df",
   "metadata": {
    "id": "826899df"
   },
   "source": [
    "LLM이 원하는 형식으로 출력하도록하기 위해 투샷 프롬프트를 제공합니다.\n",
    "\n",
    "그리고 조금 더 작업해야 합니다:\n",
    "\n",
    "* `Person`의 여러 인스턴스를 보유하는 클래스를 정의합니다.\n",
    "* LLM의 출력을 Pydantic 클래스로 명시적으로 파싱합니다.\n",
    "\n",
    "다른 경우에도 이와 같은 결과를 볼 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837c350e",
   "metadata": {
    "id": "837c350e",
    "outputId": "a321fdb9-163d-4953-daa5-313b2451ad3e",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144432642,
     "user_tz": -540,
     "elapsed": 882,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "ExecuteTime": {
     "end_time": "2024-02-09T06:16:46.006051Z",
     "start_time": "2024-02-09T06:16:45.794418Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/b4/sv3y8crx3jx6kn5k220bs8bh0000gn/T/ipykernel_52999/3671287728.py:15: PydanticDeprecatedSince20: Pydantic V1 style `@validator` validators are deprecated. You should migrate to Pydantic V2 style `@field_validator` validators, see the migration guide for more details. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.5/migration/\n",
      "  @validator(\"setup\")\n"
     ]
    },
    {
     "ename": "PydanticUserError",
     "evalue": "The `field` and `config` parameters are not available in Pydantic V2, please use the `info` parameter instead.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/validator-field-config-info",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mPydanticUserError\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[12], line 10\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mpydantic\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseModel, Field, validator\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Define your desired data structure.\u001B[39;00m\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mJoke\u001B[39;00m(BaseModel):\n\u001B[1;32m     11\u001B[0m     setup: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m Field(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mquestion to set up a joke\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m     12\u001B[0m     punchline: \u001B[38;5;28mstr\u001B[39m \u001B[38;5;241m=\u001B[39m Field(description\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124manswer to resolve the joke\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/pydantic/_internal/_model_construction.py:134\u001B[0m, in \u001B[0;36mModelMetaclass.__new__\u001B[0;34m(mcs, cls_name, bases, namespace, __pydantic_generic_metadata__, __pydantic_reset_parent_namespace__, _create_model_module, **kwargs)\u001B[0m\n\u001B[1;32m    131\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__pydantic_custom_init__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(\u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;21m__init__\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__pydantic_base_init__\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    132\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__pydantic_post_init__ \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39mmodel_post_init \u001B[38;5;129;01mis\u001B[39;00m BaseModel\u001B[38;5;241m.\u001B[39mmodel_post_init \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmodel_post_init\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m--> 134\u001B[0m \u001B[38;5;28mcls\u001B[39m\u001B[38;5;241m.\u001B[39m__pydantic_decorators__ \u001B[38;5;241m=\u001B[39m \u001B[43mDecoratorInfos\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mcls\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;66;03m# Use the getattr below to grab the __parameters__ from the `typing.Generic` parent class\u001B[39;00m\n\u001B[1;32m    137\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m __pydantic_generic_metadata__:\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/pydantic/_internal/_decorators.py:453\u001B[0m, in \u001B[0;36mDecoratorInfos.build\u001B[0;34m(model_dc)\u001B[0m\n\u001B[1;32m    451\u001B[0m info \u001B[38;5;241m=\u001B[39m var_value\u001B[38;5;241m.\u001B[39mdecorator_info\n\u001B[1;32m    452\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(info, ValidatorDecoratorInfo):\n\u001B[0;32m--> 453\u001B[0m     res\u001B[38;5;241m.\u001B[39mvalidators[var_name] \u001B[38;5;241m=\u001B[39m \u001B[43mDecorator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbuild\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    454\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmodel_dc\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcls_var_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mshim\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mvar_value\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minfo\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minfo\u001B[49m\n\u001B[1;32m    455\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    456\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(info, FieldValidatorDecoratorInfo):\n\u001B[1;32m    457\u001B[0m     res\u001B[38;5;241m.\u001B[39mfield_validators[var_name] \u001B[38;5;241m=\u001B[39m Decorator\u001B[38;5;241m.\u001B[39mbuild(\n\u001B[1;32m    458\u001B[0m         model_dc, cls_var_name\u001B[38;5;241m=\u001B[39mvar_name, shim\u001B[38;5;241m=\u001B[39mvar_value\u001B[38;5;241m.\u001B[39mshim, info\u001B[38;5;241m=\u001B[39minfo\n\u001B[1;32m    459\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/pydantic/_internal/_decorators.py:249\u001B[0m, in \u001B[0;36mDecorator.build\u001B[0;34m(cls_, cls_var_name, shim, info)\u001B[0m\n\u001B[1;32m    247\u001B[0m func \u001B[38;5;241m=\u001B[39m get_attribute_from_bases(cls_, cls_var_name)\n\u001B[1;32m    248\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m shim \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m--> 249\u001B[0m     func \u001B[38;5;241m=\u001B[39m \u001B[43mshim\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfunc\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    250\u001B[0m func \u001B[38;5;241m=\u001B[39m unwrap_wrapped_function(func, unwrap_partial\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[1;32m    251\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mcallable\u001B[39m(func):\n\u001B[1;32m    252\u001B[0m     \u001B[38;5;66;03m# This branch will get hit for classmethod properties\u001B[39;00m\n",
      "File \u001B[0;32m~/anaconda3/envs/tensor2/lib/python3.9/site-packages/pydantic/_internal/_decorators_v1.py:77\u001B[0m, in \u001B[0;36mmake_generic_v1_field_validator\u001B[0;34m(validator)\u001B[0m\n\u001B[1;32m     75\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m param_num, (param_name, parameter) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(sig\u001B[38;5;241m.\u001B[39mparameters\u001B[38;5;241m.\u001B[39mitems()):\n\u001B[1;32m     76\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m can_be_keyword(parameter) \u001B[38;5;129;01mand\u001B[39;00m param_name \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mfield\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mconfig\u001B[39m\u001B[38;5;124m'\u001B[39m):\n\u001B[0;32m---> 77\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m PydanticUserError(\n\u001B[1;32m     78\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe `field` and `config` parameters are not available in Pydantic V2, \u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[1;32m     79\u001B[0m             \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mplease use the `info` parameter instead.\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     80\u001B[0m             code\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mvalidator-field-config-info\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[1;32m     81\u001B[0m         )\n\u001B[1;32m     82\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m parameter\u001B[38;5;241m.\u001B[39mkind \u001B[38;5;129;01mis\u001B[39;00m Parameter\u001B[38;5;241m.\u001B[39mVAR_KEYWORD:\n\u001B[1;32m     83\u001B[0m         needs_values_kw \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mTrue\u001B[39;00m\n",
      "\u001B[0;31mPydanticUserError\u001B[0m: The `field` and `config` parameters are not available in Pydantic V2, please use the `info` parameter instead.\n\nFor further information visit https://errors.pydantic.dev/2.5/u/validator-field-config-info"
     ]
    }
   ],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain.prompts import (\n",
    "    PromptTemplate,\n",
    ")\n",
    "from pydantic import BaseModel, Field, validator\n",
    "\n",
    "\n",
    "# Define your desired data structure.\n",
    "class Joke(BaseModel):\n",
    "    setup: str = Field(description=\"question to set up a joke\")\n",
    "    punchline: str = Field(description=\"answer to resolve the joke\")\n",
    "\n",
    "    # You can add custom validation logic easily with Pydantic.\n",
    "    @validator(\"setup\")\n",
    "    def question_ends_with_question_mark(cls, field):\n",
    "        if field[-1] != \"?\":\n",
    "            raise ValueError(\"Badly formed question!\")\n",
    "        return field\n",
    "\n",
    "\n",
    "# And a query intended to prompt a language model to populate the data structure.\n",
    "joke_query = \"Tell me a joke.\"\n",
    "\n",
    "# Set up a parser + inject instructions into the prompt template.\n",
    "parser = PydanticOutputParser(pydantic_object=Joke)\n",
    "print(parser.get_format_instructions())\n",
    "\n",
    "# Prompt\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the user query.\\n{format_instructions}\\n{query}\\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()},\n",
    ")\n",
    "\n",
    "# Run\n",
    "_input = prompt.format_prompt(query=joke_query)\n",
    "print(_input)\n",
    "model = OpenAI(temperature=0)\n",
    "output = model(_input.to_string())\n",
    "parser.parse(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3601bde",
   "metadata": {
    "id": "d3601bde"
   },
   "source": [
    "보시다시피, 우리가 원래 원했던 스키마를 따르는 `Joke` 클래스의 출력을 얻습니다: `setup`, `punchline`.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## 연습문제\n",
    "\n",
    "### 1. 기본 추출 연습\n",
    "* 주어진 텍스트에서 언급된 사람들의 이름과 나이를 추출하는 파이썬 스크립트를 작성합니다.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "1. 스키마 정의: 사람의 이름과 나이를 추출하기 위한 스키마를 정의합니다. 이 스키마는 이름을 문자열로, 나이를 정수로 갖는 구조를 가집니다.\n",
    "\n",
    "2. 텍스트 입력: 추출할 정보를 포함하는 샘플 텍스트를 준비합니다.\n",
    "\n",
    "3. 추출 체인 생성: langchain 라이브러리를 사용하여 추출 체인을 생성합니다. 이 체인은 입력된 텍스트에서 이름과 나이 정보를 추출합니다.\n",
    "\n",
    "4. 추출 실행 및 결과 확인: 생성된 체인을 실행하여 텍스트에서 정보를 추출하고, 결과를 확인합니다.\n",
    "```\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "_gPL4ONYFgmK"
   },
   "id": "_gPL4ONYFgmK"
  },
  {
   "cell_type": "code",
   "source": [
    "# 스키마 정의\n",
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"name\": {\"type\": \"string\"},\n",
    "        \"age\": {\"type\": \"integer\"}\n",
    "    },\n",
    "    \"required\": [\"name\", \"age\"]\n",
    "}\n",
    "\n",
    "# 텍스트 입력\n",
    "input_text = \"John is 30 years old. Mary is two years younger than John.\"\n",
    "\n",
    "# 추출 체인 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "# 추출 실행\n",
    "result = chain.run(input_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ],
   "metadata": {
    "id": "XUjshGcN-q1q",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706153357950,
     "user_tz": -540,
     "elapsed": 4413,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "d9ebfffc-0c0e-4286-f962-9ba1dd3b6555"
   },
   "id": "XUjshGcN-q1q",
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'name': 'John', 'age': 30}, {'name': 'Mary', 'age': 28}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# from langchain.chains import create_extraction_chain_pydantic\n",
    "\n",
    "class Properties(BaseModel):\n",
    "    name: str\n",
    "    age: int\n",
    "\n",
    "# 텍스트 입력\n",
    "input_text = \"John is 30 years old. Mary is two years younger than John.\"\n",
    "\n",
    "# 추출 체인 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain_pydantic(pydantic_schema=Properties, llm=llm)\n",
    "\n",
    "# 추출 실행\n",
    "result = chain.run(input_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2N_asPJjL6Xi",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706153453969,
     "user_tz": -540,
     "elapsed": 3757,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "82953c8c-d783-46b8-b87e-300013618ba1"
   },
   "id": "2N_asPJjL6Xi",
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[Properties(name='John', age=30), Properties(name='Mary', age=28)]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 2. 복잡한 쿼리 처리\n",
    "* 서술 문단에서 이벤트에 대한 자세한 정보(예: 이벤트 이름, 날짜, 위치, 참가자)를 추출하는 스크립트를 작성합니다.\n",
    "\n",
    "\n",
    "```\n",
    "1. 이벤트 정보 스키마 정의: 이벤트 이름, 날짜, 위치, 참가자 등의 정보를 포함하는 스키마를 정의합니다.\n",
    "\n",
    "2. 텍스트 입력: 추출할 정보를 포함하는 복잡한 서술 문단을 준비합니다\n",
    "\n",
    "3. 추출 체인 생성 및 실행: langchain 라이브러리를 사용하여 추출 체인을 생성하고, 준비된 텍스트에서 정보를 추출합니다.\n",
    "\n",
    "4. 결과 확인 및 분석: 추출된 결과를 확인하고, 스크립트가 복잡한 쿼리를 어떻게 처리하는지 분석합니다.\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "dKYyaq_SGmn5"
   },
   "id": "dKYyaq_SGmn5"
  },
  {
   "cell_type": "code",
   "source": [
    "schema = {\n",
    "    \"properties\": {\n",
    "        \"event_name\": {\"type\": \"string\"},\n",
    "        \"date\": {\"type\": \"string\"}, # 날짜검증이 필요할 수도\n",
    "        \"location\": {\"type\": \"string\"},\n",
    "        \"participants\": {\"type\": \"array\", \"items\":{\"type\": \"string\"}},\n",
    "    },\n",
    "    \"required\": [\"event_name\", \"date\", \"location\"]\n",
    "}\n",
    "\n",
    "# 텍스트 입력\n",
    "input_text = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
    "\n",
    "# 추출 체인 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain(schema, llm)\n",
    "\n",
    "# 추출 실행\n",
    "result = chain.run(input_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VY2y3hinGNLS",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706153632547,
     "user_tz": -540,
     "elapsed": 4748,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "05d7d52c-de87-452b-f449-f0ae54c70098"
   },
   "id": "VY2y3hinGNLS",
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'event_name': 'annual science fair', 'date': 'March 15th', 'location': 'city hall', 'participants': ['Dr. Jane Doe', 'Prof. John Smith']}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Event(BaseModel):\n",
    "    event_name: str\n",
    "    date: str\n",
    "    location: str\n",
    "    participants: list\n",
    "\n",
    "query = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
    "\n",
    "# Set Parser\n",
    "parser = PydanticOutputParser(pydantic_object=Event)\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the query. \\n {format_instructions} \\m {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# run chain\n",
    "_input = prompt.format_prompt(query=query)\n",
    "model = OpenAI(temperature=0)\n",
    "outputs = model(_input.to_string())\n",
    "parser.parse(outputs)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bDPAPiX4VQvT",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706153718265,
     "user_tz": -540,
     "elapsed": 4615,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "8eb3ee0f-e3b7-4f6d-95ef-069b294de0f3"
   },
   "id": "bDPAPiX4VQvT",
   "execution_count": 19,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Event(event_name='Annual Science Fair', date='March 15th', location='City Hall', participants=['Dr. Jane Doe', 'Prof. John Smith'])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "class Event(BaseModel):\n",
    "    name: str\n",
    "    event_name: str\n",
    "    date: str\n",
    "    location: str\n",
    "\n",
    "class People(BaseModel):\n",
    "    \"\"\"Event Participants\"\"\"\n",
    "    participants: Sequence[Event]\n",
    "\n",
    "query = \"The annual science fair, which will be held on March 15th at the city hall, is expected to attract many notable scientists including Dr. Jane Doe and Prof. John Smith.\"\n",
    "\n",
    "# Set Parser\n",
    "parser = PydanticOutputParser(pydantic_object=People)\n",
    "\n",
    "# Prompt template\n",
    "prompt = PromptTemplate(\n",
    "    template=\"Answer the query. \\n {format_instructions} \\m {query} \\n\",\n",
    "    input_variables=[\"query\"],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# run chain\n",
    "_input = prompt.format_prompt(query=query)\n",
    "model = OpenAI(temperature=0)\n",
    "outputs = model(_input.to_string())\n",
    "parser.parse(outputs)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DrnKdmzHWfS7",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706153917948,
     "user_tz": -540,
     "elapsed": 6246,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "d4b60008-706a-425d-9c83-40e0fb054813"
   },
   "id": "DrnKdmzHWfS7",
   "execution_count": 21,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "People(participants=[Event(name='Dr. Jane Doe', event_name='Annual Science Fair', date='March 15th', location='City Hall'), Event(name='Prof. John Smith', event_name='Annual Science Fair', date='March 15th', location='City Hall')])"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 동적 스키마 생성\n",
    "* 사용자 입력에 기반하여 스키마를 자동으로 생성하는 파이썬 스크립트를 작성합니다. 이 스크립트는 사용자가 원하는 정보 유형을 입력하면 해당하는 스키마를 생성하고, 언어 모델을 사용하여 이 스키마에 따라 텍스트에서 정보를 추출합니다.\n",
    "\n",
    "\n",
    "\n",
    "```\n",
    "1. 사용자 입력 처리: 사용자가 추출하고자 하는 정보 유형을 입력할 수 있는 인터페이스를 구현합니다. 예를 들어, 사용자가 \"이름\", \"나이\", \"직업\" 등을 입력할 수 있습니다.\n",
    "\n",
    "2. 동적 스키마 생성: 사용자의 입력을 기반으로 동적으로 스키마를 생성하는 함수를 구현합니다. 이 함수는 사용자가 입력한 정보 유형에 따라 적절한 스키마를 만듭니다.\n",
    "\n",
    "3. 추출 체인 설정 및 실행: 생성된 스키마를 사용하여 langchain 라이브러리의 추출 체인을 설정하고 실행합니다.\n",
    "\n",
    "4. 결과 출력 및 검증: 추출된 결과를 출력하고, 스크립트가 정확하게 사용자 요구 사항에 맞는 스키마를 생성했는지 검증합니다.\n",
    "```\n",
    "\n"
   ],
   "metadata": {
    "id": "WanR5a9WIOi6"
   },
   "id": "WanR5a9WIOi6"
  },
  {
   "cell_type": "code",
   "source": [
    "def create_dynamic_schema(user_inputs):\n",
    "    schema = {\"properties\": {}, \"required\": []}\n",
    "    for input in user_inputs:\n",
    "        # 여기에서 각 입력 유형에 대한 스키마 정의를 추가합니다.\n",
    "        schema[\"properties\"][input] = {\"type\": \"string\"}  # 예시: 모든 필드를 문자열로 처리\n",
    "        schema[\"required\"].append(input)\n",
    "    return schema\n",
    "\n",
    "# 사용자 입력\n",
    "user_inputs = [\"name\", \"age\"]  # 예시: 사용자가 입력한 필드\n",
    "\n",
    "# 스키마 생성\n",
    "dynamic_schema = create_dynamic_schema(user_inputs)\n",
    "\n",
    "# 텍스트 입력\n",
    "input_text = \"John, a 30-year-old engineer, works at Acme Corp.\"\n",
    "\n",
    "# 추출 체인 생성\n",
    "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")\n",
    "chain = create_extraction_chain(dynamic_schema, llm)\n",
    "\n",
    "# 추출 실행\n",
    "result = chain.run(input_text)\n",
    "\n",
    "# 결과 출력\n",
    "print(result)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1mD6pADTHS95",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706154156334,
     "user_tz": -540,
     "elapsed": 4641,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    },
    "outputId": "26aa2392-e98a-495f-a366-063d5b29feb2"
   },
   "id": "1mD6pADTHS95",
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[{'name': 'John', 'age': '30'}, {'name': 'engineer'}, {'name': 'Acme Corp.'}]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "vi5mss-BIJ6b",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1706144450033,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "Junseop So (쏘주형)",
      "userId": "07758510494740838877"
     }
    }
   },
   "id": "vi5mss-BIJ6b",
   "execution_count": 15,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/langchain-ai/langchain/blob/master/docs/docs/use_cases/extraction.ipynb",
     "timestamp": 1701661588526
    }
   ]
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
