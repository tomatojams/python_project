{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"J2uM0kquQgKv"},"source":["### 14주차 실습 - Attention을 이용한 문서 요약 ###\n","출처: 딥 러닝을 이용한 자연어 처리 입문(유원준, 안상준) https://wikidocs.net/72820"]},{"cell_type":"markdown","source":["### 1. 아마존 상품 리뷰 데이터 전처리"],"metadata":{"id":"lHZq0m-BKXVY"}},{"cell_type":"code","metadata":{"id":"T9nRioi9jQuy","executionInfo":{"status":"ok","timestamp":1700045307177,"user_tz":-540,"elapsed":7172,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"35cee1a1-9a0c-43b7-9bcd-0588f314b499"},"source":["import numpy as np\n","import pandas as pd\n","import re\n","import matplotlib.pyplot as plt\n","from bs4 import BeautifulSoup\n","\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","\n","import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","\n","from google.colab import drive\n","drive.mount('/content/drive/')"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"28r4PtVojOjM"},"source":["data = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/TDA/data/Reviews.csv\", nrows=100000)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"SvJCr0tVjSYy","executionInfo":{"status":"ok","timestamp":1700045308564,"user_tz":-540,"elapsed":37,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"542a04d6-947d-47a1-a0a8-cdd218a4b961"},"source":["data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["           Id   ProductId          UserId                      ProfileName  \\\n","0           1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n","1           2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n","2           3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n","3           4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n","4           5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n","...       ...         ...             ...                              ...   \n","99995   99996  B000LQORDE  A2P7HIRYYWVOBD                            Mason   \n","99996   99997  B000LQORDE  A1K0ZH5MQFBA77                       jennilight   \n","99997   99998  B000LQORDE  A29FRN2O7LWINL                          T. Tsai   \n","99998   99999  B000LQORDE   A9Q950IPXJR1D          Lynda \"casual customer\"   \n","99999  100000  B000LQORDE  A19W47CXJJP1MI               Amazonian Consumer   \n","\n","       HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n","0                         1                       1      5  1303862400   \n","1                         0                       0      1  1346976000   \n","2                         1                       1      4  1219017600   \n","3                         3                       3      2  1307923200   \n","4                         0                       0      5  1350777600   \n","...                     ...                     ...    ...         ...   \n","99995                     2                       5      5  1254096000   \n","99996                     2                       5      4  1250985600   \n","99997                     2                       5      5  1237766400   \n","99998                     2                       5      4  1237161600   \n","99999                     2                       5      5  1235088000   \n","\n","                                                 Summary  \\\n","0                                  Good Quality Dog Food   \n","1                                      Not as Advertised   \n","2                                  \"Delight\" says it all   \n","3                                         Cough Medicine   \n","4                                            Great taffy   \n","...                                                  ...   \n","99995                                             yummy!   \n","99996                                  Tastes like More!   \n","99997                                        Great ramen   \n","99998                                            Spicy!!   \n","99999  This spicy noodle cures my cold, upset stomach...   \n","\n","                                                    Text  \n","0      I have bought several of the Vitality canned d...  \n","1      Product arrived labeled as Jumbo Salted Peanut...  \n","2      This is a confection that has been around a fe...  \n","3      If you are looking for the secret ingredient i...  \n","4      Great taffy at a great price.  There was a wid...  \n","...                                                  ...  \n","99995  I just love it and will buy another box when I...  \n","99996  My late father in law used to have a rating sy...  \n","99997  This is my favorite brand of Korean ramen. It ...  \n","99998  I do like these noodles although, to say they ...  \n","99999  I love this noodle and have it once or twice a...  \n","\n","[100000 rows x 10 columns]"],"text/html":["\n","  <div id=\"df-2912d9a6-96e0-4cf8-9aa7-a1b990c9b7f1\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Id</th>\n","      <th>ProductId</th>\n","      <th>UserId</th>\n","      <th>ProfileName</th>\n","      <th>HelpfulnessNumerator</th>\n","      <th>HelpfulnessDenominator</th>\n","      <th>Score</th>\n","      <th>Time</th>\n","      <th>Summary</th>\n","      <th>Text</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>B001E4KFG0</td>\n","      <td>A3SGXH7AUHU8GW</td>\n","      <td>delmartian</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>5</td>\n","      <td>1303862400</td>\n","      <td>Good Quality Dog Food</td>\n","      <td>I have bought several of the Vitality canned d...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>B00813GRG4</td>\n","      <td>A1D87F6ZCVE5NK</td>\n","      <td>dll pa</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1346976000</td>\n","      <td>Not as Advertised</td>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>B000LQOCH0</td>\n","      <td>ABXLMWJIXXAIN</td>\n","      <td>Natalia Corres \"Natalia Corres\"</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>1219017600</td>\n","      <td>\"Delight\" says it all</td>\n","      <td>This is a confection that has been around a fe...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>B000UA0QIQ</td>\n","      <td>A395BORC6FGVXV</td>\n","      <td>Karl</td>\n","      <td>3</td>\n","      <td>3</td>\n","      <td>2</td>\n","      <td>1307923200</td>\n","      <td>Cough Medicine</td>\n","      <td>If you are looking for the secret ingredient i...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>B006K2ZZ7K</td>\n","      <td>A1UQRSCLF8GW1T</td>\n","      <td>Michael D. Bigham \"M. Wassir\"</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>5</td>\n","      <td>1350777600</td>\n","      <td>Great taffy</td>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>99996</td>\n","      <td>B000LQORDE</td>\n","      <td>A2P7HIRYYWVOBD</td>\n","      <td>Mason</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1254096000</td>\n","      <td>yummy!</td>\n","      <td>I just love it and will buy another box when I...</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>99997</td>\n","      <td>B000LQORDE</td>\n","      <td>A1K0ZH5MQFBA77</td>\n","      <td>jennilight</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1250985600</td>\n","      <td>Tastes like More!</td>\n","      <td>My late father in law used to have a rating sy...</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>99998</td>\n","      <td>B000LQORDE</td>\n","      <td>A29FRN2O7LWINL</td>\n","      <td>T. Tsai</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1237766400</td>\n","      <td>Great ramen</td>\n","      <td>This is my favorite brand of Korean ramen. It ...</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>99999</td>\n","      <td>B000LQORDE</td>\n","      <td>A9Q950IPXJR1D</td>\n","      <td>Lynda \"casual customer\"</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>4</td>\n","      <td>1237161600</td>\n","      <td>Spicy!!</td>\n","      <td>I do like these noodles although, to say they ...</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>100000</td>\n","      <td>B000LQORDE</td>\n","      <td>A19W47CXJJP1MI</td>\n","      <td>Amazonian Consumer</td>\n","      <td>2</td>\n","      <td>5</td>\n","      <td>5</td>\n","      <td>1235088000</td>\n","      <td>This spicy noodle cures my cold, upset stomach...</td>\n","      <td>I love this noodle and have it once or twice a...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>100000 rows × 10 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2912d9a6-96e0-4cf8-9aa7-a1b990c9b7f1')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-2912d9a6-96e0-4cf8-9aa7-a1b990c9b7f1 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-2912d9a6-96e0-4cf8-9aa7-a1b990c9b7f1');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-f7e1b240-6709-4d32-ac96-e58e34b2b448\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-f7e1b240-6709-4d32-ac96-e58e34b2b448')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-f7e1b240-6709-4d32-ac96-e58e34b2b448 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"UkghjLsFkKVT","executionInfo":{"status":"ok","timestamp":1700045308565,"user_tz":-540,"elapsed":29,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/","height":597},"outputId":"1c625224-6639-44e9-de22-733847be76ba"},"source":["# 중복, 빈 데이터 제거\n","data = data[['Text','Summary']]\n","data.drop_duplicates(subset=['Text'], inplace=True)\n","data.dropna(axis=0, inplace=True)\n","data"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-4-5b16d2bedd62>:3: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.drop_duplicates(subset=['Text'], inplace=True)\n","<ipython-input-4-5b16d2bedd62>:4: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.dropna(axis=0, inplace=True)\n"]},{"output_type":"execute_result","data":{"text/plain":["                                                    Text  \\\n","0      I have bought several of the Vitality canned d...   \n","1      Product arrived labeled as Jumbo Salted Peanut...   \n","2      This is a confection that has been around a fe...   \n","3      If you are looking for the secret ingredient i...   \n","4      Great taffy at a great price.  There was a wid...   \n","...                                                  ...   \n","99995  I just love it and will buy another box when I...   \n","99996  My late father in law used to have a rating sy...   \n","99997  This is my favorite brand of Korean ramen. It ...   \n","99998  I do like these noodles although, to say they ...   \n","99999  I love this noodle and have it once or twice a...   \n","\n","                                                 Summary  \n","0                                  Good Quality Dog Food  \n","1                                      Not as Advertised  \n","2                                  \"Delight\" says it all  \n","3                                         Cough Medicine  \n","4                                            Great taffy  \n","...                                                  ...  \n","99995                                             yummy!  \n","99996                                  Tastes like More!  \n","99997                                        Great ramen  \n","99998                                            Spicy!!  \n","99999  This spicy noodle cures my cold, upset stomach...  \n","\n","[88425 rows x 2 columns]"],"text/html":["\n","  <div id=\"df-8fb040d4-dad2-4895-9d95-eea2328df894\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Summary</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>I have bought several of the Vitality canned d...</td>\n","      <td>Good Quality Dog Food</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n","      <td>Not as Advertised</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>This is a confection that has been around a fe...</td>\n","      <td>\"Delight\" says it all</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>If you are looking for the secret ingredient i...</td>\n","      <td>Cough Medicine</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Great taffy at a great price.  There was a wid...</td>\n","      <td>Great taffy</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>I just love it and will buy another box when I...</td>\n","      <td>yummy!</td>\n","    </tr>\n","    <tr>\n","      <th>99996</th>\n","      <td>My late father in law used to have a rating sy...</td>\n","      <td>Tastes like More!</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>This is my favorite brand of Korean ramen. It ...</td>\n","      <td>Great ramen</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>I do like these noodles although, to say they ...</td>\n","      <td>Spicy!!</td>\n","    </tr>\n","    <tr>\n","      <th>99999</th>\n","      <td>I love this noodle and have it once or twice a...</td>\n","      <td>This spicy noodle cures my cold, upset stomach...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>88425 rows × 2 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8fb040d4-dad2-4895-9d95-eea2328df894')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-8fb040d4-dad2-4895-9d95-eea2328df894 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-8fb040d4-dad2-4895-9d95-eea2328df894');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-0a4d0096-53a3-4de8-a6e5-4882a07b12ec\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0a4d0096-53a3-4de8-a6e5-4882a07b12ec')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-0a4d0096-53a3-4de8-a6e5-4882a07b12ec button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","metadata":{"id":"KF52m563ke5K"},"source":["# 약어 정의\n","contractions = {\"ain't\": \"is not\", \"aren't\": \"are not\",\"can't\": \"cannot\", \"'cause\": \"because\", \"could've\": \"could have\", \"couldn't\": \"could not\", \"didn't\": \"did not\",  \"doesn't\": \"does not\", \"don't\": \"do not\", \"hadn't\": \"had not\", \"hasn't\": \"has not\", \"haven't\": \"have not\", \"he'd\": \"he would\",\"he'll\": \"he will\", \"he's\": \"he is\", \"how'd\": \"how did\", \"how'd'y\": \"how do you\", \"how'll\": \"how will\", \"how's\": \"how is\", \"I'd\": \"I would\", \"I'd've\": \"I would have\", \"I'll\": \"I will\", \"I'll've\": \"I will have\",\"I'm\": \"I am\", \"I've\": \"I have\", \"i'd\": \"i would\", \"i'd've\": \"i would have\", \"i'll\": \"i will\",  \"i'll've\": \"i will have\",\"i'm\": \"i am\", \"i've\": \"i have\", \"isn't\": \"is not\", \"it'd\": \"it would\", \"it'd've\": \"it would have\", \"it'll\": \"it will\", \"it'll've\": \"it will have\",\"it's\": \"it is\", \"let's\": \"let us\", \"ma'am\": \"madam\", \"mayn't\": \"may not\", \"might've\": \"might have\",\"mightn't\": \"might not\",\"mightn't've\": \"might not have\", \"must've\": \"must have\", \"mustn't\": \"must not\", \"mustn't've\": \"must not have\", \"needn't\": \"need not\", \"needn't've\": \"need not have\",\"o'clock\": \"of the clock\", \"oughtn't\": \"ought not\", \"oughtn't've\": \"ought not have\", \"shan't\": \"shall not\", \"sha'n't\": \"shall not\", \"shan't've\": \"shall not have\", \"she'd\": \"she would\", \"she'd've\": \"she would have\", \"she'll\": \"she will\", \"she'll've\": \"she will have\", \"she's\": \"she is\", \"should've\": \"should have\", \"shouldn't\": \"should not\", \"shouldn't've\": \"should not have\", \"so've\": \"so have\",\"so's\": \"so as\", \"this's\": \"this is\",\"that'd\": \"that would\", \"that'd've\": \"that would have\", \"that's\": \"that is\", \"there'd\": \"there would\", \"there'd've\": \"there would have\", \"there's\": \"there is\", \"here's\": \"here is\",\"they'd\": \"they would\", \"they'd've\": \"they would have\", \"they'll\": \"they will\", \"they'll've\": \"they will have\", \"they're\": \"they are\", \"they've\": \"they have\", \"to've\": \"to have\", \"wasn't\": \"was not\", \"we'd\": \"we would\", \"we'd've\": \"we would have\", \"we'll\": \"we will\", \"we'll've\": \"we will have\", \"we're\": \"we are\", \"we've\": \"we have\", \"weren't\": \"were not\", \"what'll\": \"what will\", \"what'll've\": \"what will have\", \"what're\": \"what are\", \"what's\": \"what is\", \"what've\": \"what have\", \"when's\": \"when is\", \"when've\": \"when have\", \"where'd\": \"where did\", \"where's\": \"where is\", \"where've\": \"where have\", \"who'll\": \"who will\", \"who'll've\": \"who will have\", \"who's\": \"who is\", \"who've\": \"who have\", \"why's\": \"why is\", \"why've\": \"why have\", \"will've\": \"will have\", \"won't\": \"will not\", \"won't've\": \"will not have\", \"would've\": \"would have\", \"wouldn't\": \"would not\", \"wouldn't've\": \"would not have\", \"y'all\": \"you all\", \"y'all'd\": \"you all would\",\"y'all'd've\": \"you all would have\",\"y'all're\": \"you all are\",\"y'all've\": \"you all have\", \"you'd\": \"you would\", \"you'd've\": \"you would have\", \"you'll\": \"you will\", \"you'll've\": \"you will have\", \"you're\": \"you are\", \"you've\": \"you have\"}\n","\n","# NLTK의 불용어\n","stop_words = set(stopwords.words('english'))\n","\n","# 전처리 함수\n","def preprocess_sentence(sentence, remove_stopwords = True):\n","    sentence = sentence.lower() # 텍스트 소문자화\n","    sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n","    sentence = re.sub(r'\\([^)]*\\)', '', sentence) # 괄호로 닫힌 문자열 제거 Ex) my husband (and myself) for => my husband for\n","    sentence = re.sub('\"','', sentence) # 쌍따옴표 \" 제거\n","    sentence = ' '.join([contractions[t] if t in contractions else t for t in sentence.split(\" \")]) # 약어 정규화\n","    sentence = re.sub(r\"'s\\b\",\"\",sentence) # 소유격 제거. Ex) roland's -> roland\n","    sentence = re.sub(\"[^a-zA-Z]\", \" \", sentence) # 영어 외 문자(숫자, 특수문자 등) 공백으로 변환\n","    sentence = re.sub('[m]{2,}', 'mm', sentence) # m이 3개 이상이면 2개로 변경. Ex) ummmmmmm yeah -> umm yeah\n","\n","    # 불용어 제거\n","    if remove_stopwords:\n","        tokens = ' '.join(word for word in sentence.split() if not word in stop_words if len(word) > 1)\n","    else:\n","        tokens = ' '.join(word for word in sentence.split() if len(word) > 1)\n","    return tokens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OX0rUTFIkhHB","executionInfo":{"status":"ok","timestamp":1700045309321,"user_tz":-540,"elapsed":17,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"70232a1d-3120-464d-918a-6ddeaf4aadb8"},"source":["# 전처리 함수 테스트\n","temp_text = 'Everything I bought was great, infact I ordered twice and the third ordered was<br />for my mother and father.'\n","temp_summary = 'Great way to start (or finish) the day!!!'\n","\n","print(preprocess_sentence(temp_text))\n","print(preprocess_sentence(temp_summary, 0))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["everything bought great infact ordered twice third ordered wasfor mother father\n","great way to start the day\n"]}]},{"cell_type":"code","metadata":{"id":"JROWYq2ml9yE","executionInfo":{"status":"ok","timestamp":1700045370966,"user_tz":-540,"elapsed":61657,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"9cf0b67a-f666-4e7e-80c8-835faae29d86"},"source":["# Text 열 전처리\n","clean_text = []\n","for s in data['Text']:\n","    clean_text.append(preprocess_sentence(s))\n","\n","# Summary 열 전처리\n","clean_summary = []\n","for s in data['Summary']:\n","    clean_summary.append(preprocess_sentence(s, 0))\n","\n","data['Text'] = clean_text\n","data['Summary'] = clean_summary\n","\n","# 공백인 샘플 제거\n","data.replace('', np.nan, inplace=True)\n","data.dropna(axis = 0, inplace = True)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["<ipython-input-5-f990953dae01>:10: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n","  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n","<ipython-input-5-f990953dae01>:10: MarkupResemblesLocatorWarning: The input looks more like a URL than markup. You may want to use an HTTP client like requests to get the document behind the URL, and feed that document to Beautiful Soup.\n","  sentence = BeautifulSoup(sentence, \"lxml\").text # <br />, <a href = ...> 등의 html 태그 제거\n","<ipython-input-7-5c7465dd40e2>:11: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Text'] = clean_text\n","<ipython-input-7-5c7465dd40e2>:12: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame.\n","Try using .loc[row_indexer,col_indexer] = value instead\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data['Summary'] = clean_summary\n","<ipython-input-7-5c7465dd40e2>:15: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.replace('', np.nan, inplace=True)\n","<ipython-input-7-5c7465dd40e2>:16: SettingWithCopyWarning: \n","A value is trying to be set on a copy of a slice from a DataFrame\n","\n","See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n","  data.dropna(axis = 0, inplace = True)\n"]}]},{"cell_type":"code","metadata":{"id":"QgF0qr_4mN91","executionInfo":{"status":"ok","timestamp":1700045370966,"user_tz":-540,"elapsed":35,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8e48323c-7f7d-4ed7-daec-fa9302b25b1d"},"source":["# Text와 Summary의 길이 분포\n","text_len = [len(s.split()) for s in data['Text']]\n","summary_len = [len(s.split()) for s in data['Summary']]\n","\n","print('Text의 최소 길이 : {}'.format(np.min(text_len)))\n","print('Text의 최대 길이 : {}'.format(np.max(text_len)))\n","print('Text의 평균 길이 : {}'.format(np.mean(text_len)))\n","print('Summary의 최소 길이 : {}'.format(np.min(summary_len)))\n","print('Summary의 최대 길이 : {}'.format(np.max(summary_len)))\n","print('Summary의 평균 길이 : {}'.format(np.mean(summary_len)))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text의 최소 길이 : 2\n","Text의 최대 길이 : 1235\n","Text의 평균 길이 : 38.792428272310566\n","Summary의 최소 길이 : 1\n","Summary의 최대 길이 : 28\n","Summary의 평균 길이 : 4.010729443721352\n"]}]},{"cell_type":"markdown","metadata":{"id":"Ej-4h6W0jRYr"},"source":["-------------------------------------"]},{"cell_type":"code","metadata":{"id":"-1wehqFWmCjN"},"source":["# Text와 Summary의 평균 길이를 참고하여 아래 임계치보다 긴 데이터는 삭제\n","text_max_len = 50\n","summary_max_len = 8\n","\n","data = data[data['Text'].apply(lambda x: len(x.split()) <= text_max_len)]\n","data = data[data['Summary'].apply(lambda x: len(x.split()) <= summary_max_len)]\n","\n","# Summary에 시작 토큰(sostoken)과 종료 토큰(eostoken)을 추가\n","data['decoder_input'] = data['Summary'].apply(lambda x : 'sostoken '+ x)\n","data['decoder_target'] = data['Summary'].apply(lambda x : x + ' eostoken')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iFuBCYflmHw8","executionInfo":{"status":"ok","timestamp":1700045371622,"user_tz":-540,"elapsed":11,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/","height":423},"outputId":"87dc0eec-a539-4e9c-f20e-50e10a724c19"},"source":["data"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                    Text  \\\n","0      bought several vitality canned dog food produc...   \n","1      product arrived labeled jumbo salted peanuts p...   \n","2      confection around centuries light pillowy citr...   \n","3      looking secret ingredient robitussin believe f...   \n","4      great taffy great price wide assortment yummy ...   \n","...                                                  ...   \n","99993  stuff awesome best flavor boil water drain wat...   \n","99994               love noodle little spicy wife perfct   \n","99995                 love buy another box done last one   \n","99997  favorite brand korean ramen spicy used eating ...   \n","99998  like noodles although say spicy somewhat under...   \n","\n","                     Summary                   decoder_input  \\\n","0      good quality dog food  sostoken good quality dog food   \n","1          not as advertised      sostoken not as advertised   \n","2        delight says it all    sostoken delight says it all   \n","3             cough medicine         sostoken cough medicine   \n","4                great taffy            sostoken great taffy   \n","...                      ...                             ...   \n","99993            great stuff            sostoken great stuff   \n","99994             good stuff             sostoken good stuff   \n","99995                  yummy                  sostoken yummy   \n","99997            great ramen            sostoken great ramen   \n","99998                  spicy                  sostoken spicy   \n","\n","                       decoder_target  \n","0      good quality dog food eostoken  \n","1          not as advertised eostoken  \n","2        delight says it all eostoken  \n","3             cough medicine eostoken  \n","4                great taffy eostoken  \n","...                               ...  \n","99993            great stuff eostoken  \n","99994             good stuff eostoken  \n","99995                  yummy eostoken  \n","99997            great ramen eostoken  \n","99998                  spicy eostoken  \n","\n","[65818 rows x 4 columns]"],"text/html":["\n","  <div id=\"df-3e82000b-b367-47e5-ba7e-932328871951\" class=\"colab-df-container\">\n","    <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Text</th>\n","      <th>Summary</th>\n","      <th>decoder_input</th>\n","      <th>decoder_target</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>bought several vitality canned dog food produc...</td>\n","      <td>good quality dog food</td>\n","      <td>sostoken good quality dog food</td>\n","      <td>good quality dog food eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>product arrived labeled jumbo salted peanuts p...</td>\n","      <td>not as advertised</td>\n","      <td>sostoken not as advertised</td>\n","      <td>not as advertised eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>confection around centuries light pillowy citr...</td>\n","      <td>delight says it all</td>\n","      <td>sostoken delight says it all</td>\n","      <td>delight says it all eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>looking secret ingredient robitussin believe f...</td>\n","      <td>cough medicine</td>\n","      <td>sostoken cough medicine</td>\n","      <td>cough medicine eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>great taffy great price wide assortment yummy ...</td>\n","      <td>great taffy</td>\n","      <td>sostoken great taffy</td>\n","      <td>great taffy eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>99993</th>\n","      <td>stuff awesome best flavor boil water drain wat...</td>\n","      <td>great stuff</td>\n","      <td>sostoken great stuff</td>\n","      <td>great stuff eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>99994</th>\n","      <td>love noodle little spicy wife perfct</td>\n","      <td>good stuff</td>\n","      <td>sostoken good stuff</td>\n","      <td>good stuff eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>99995</th>\n","      <td>love buy another box done last one</td>\n","      <td>yummy</td>\n","      <td>sostoken yummy</td>\n","      <td>yummy eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>99997</th>\n","      <td>favorite brand korean ramen spicy used eating ...</td>\n","      <td>great ramen</td>\n","      <td>sostoken great ramen</td>\n","      <td>great ramen eostoken</td>\n","    </tr>\n","    <tr>\n","      <th>99998</th>\n","      <td>like noodles although say spicy somewhat under...</td>\n","      <td>spicy</td>\n","      <td>sostoken spicy</td>\n","      <td>spicy eostoken</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>65818 rows × 4 columns</p>\n","</div>\n","    <div class=\"colab-df-buttons\">\n","\n","  <div class=\"colab-df-container\">\n","    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3e82000b-b367-47e5-ba7e-932328871951')\"\n","            title=\"Convert this dataframe to an interactive table.\"\n","            style=\"display:none;\">\n","\n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n","    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n","  </svg>\n","    </button>\n","\n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    .colab-df-buttons div {\n","      margin-bottom: 4px;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","    <script>\n","      const buttonEl =\n","        document.querySelector('#df-3e82000b-b367-47e5-ba7e-932328871951 button.colab-df-convert');\n","      buttonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","      async function convertToInteractive(key) {\n","        const element = document.querySelector('#df-3e82000b-b367-47e5-ba7e-932328871951');\n","        const dataTable =\n","          await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                    [key], {});\n","        if (!dataTable) return;\n","\n","        const docLinkHtml = 'Like what you see? Visit the ' +\n","          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","          + ' to learn more about interactive tables.';\n","        element.innerHTML = '';\n","        dataTable['output_type'] = 'display_data';\n","        await google.colab.output.renderOutput(dataTable, element);\n","        const docLink = document.createElement('div');\n","        docLink.innerHTML = docLinkHtml;\n","        element.appendChild(docLink);\n","      }\n","    </script>\n","  </div>\n","\n","\n","<div id=\"df-31fbe2de-c112-4c1c-95dd-996469abd2d8\">\n","  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-31fbe2de-c112-4c1c-95dd-996469abd2d8')\"\n","            title=\"Suggest charts\"\n","            style=\"display:none;\">\n","\n","<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","     width=\"24px\">\n","    <g>\n","        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n","    </g>\n","</svg>\n","  </button>\n","\n","<style>\n","  .colab-df-quickchart {\n","      --bg-color: #E8F0FE;\n","      --fill-color: #1967D2;\n","      --hover-bg-color: #E2EBFA;\n","      --hover-fill-color: #174EA6;\n","      --disabled-fill-color: #AAA;\n","      --disabled-bg-color: #DDD;\n","  }\n","\n","  [theme=dark] .colab-df-quickchart {\n","      --bg-color: #3B4455;\n","      --fill-color: #D2E3FC;\n","      --hover-bg-color: #434B5C;\n","      --hover-fill-color: #FFFFFF;\n","      --disabled-bg-color: #3B4455;\n","      --disabled-fill-color: #666;\n","  }\n","\n","  .colab-df-quickchart {\n","    background-color: var(--bg-color);\n","    border: none;\n","    border-radius: 50%;\n","    cursor: pointer;\n","    display: none;\n","    fill: var(--fill-color);\n","    height: 32px;\n","    padding: 0;\n","    width: 32px;\n","  }\n","\n","  .colab-df-quickchart:hover {\n","    background-color: var(--hover-bg-color);\n","    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n","    fill: var(--button-hover-fill-color);\n","  }\n","\n","  .colab-df-quickchart-complete:disabled,\n","  .colab-df-quickchart-complete:disabled:hover {\n","    background-color: var(--disabled-bg-color);\n","    fill: var(--disabled-fill-color);\n","    box-shadow: none;\n","  }\n","\n","  .colab-df-spinner {\n","    border: 2px solid var(--fill-color);\n","    border-color: transparent;\n","    border-bottom-color: var(--fill-color);\n","    animation:\n","      spin 1s steps(1) infinite;\n","  }\n","\n","  @keyframes spin {\n","    0% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","      border-left-color: var(--fill-color);\n","    }\n","    20% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    30% {\n","      border-color: transparent;\n","      border-left-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","      border-right-color: var(--fill-color);\n","    }\n","    40% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-top-color: var(--fill-color);\n","    }\n","    60% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","    }\n","    80% {\n","      border-color: transparent;\n","      border-right-color: var(--fill-color);\n","      border-bottom-color: var(--fill-color);\n","    }\n","    90% {\n","      border-color: transparent;\n","      border-bottom-color: var(--fill-color);\n","    }\n","  }\n","</style>\n","\n","  <script>\n","    async function quickchart(key) {\n","      const quickchartButtonEl =\n","        document.querySelector('#' + key + ' button');\n","      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n","      quickchartButtonEl.classList.add('colab-df-spinner');\n","      try {\n","        const charts = await google.colab.kernel.invokeFunction(\n","            'suggestCharts', [key], {});\n","      } catch (error) {\n","        console.error('Error during call to suggestCharts:', error);\n","      }\n","      quickchartButtonEl.classList.remove('colab-df-spinner');\n","      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n","    }\n","    (() => {\n","      let quickchartButtonEl =\n","        document.querySelector('#df-31fbe2de-c112-4c1c-95dd-996469abd2d8 button');\n","      quickchartButtonEl.style.display =\n","        google.colab.kernel.accessAllowed ? 'block' : 'none';\n","    })();\n","  </script>\n","</div>\n","    </div>\n","  </div>\n"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["### 2. Training data와 test data 분리"],"metadata":{"id":"RqxPvC71YWKZ"}},{"cell_type":"code","metadata":{"id":"cXh3ZP-qmIW0","executionInfo":{"status":"ok","timestamp":1700045371622,"user_tz":-540,"elapsed":9,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0bd0bd2f-221d-4183-d193-94019207bcc6"},"source":["encoder_input = np.array(data['Text'])\n","decoder_input = np.array(data['decoder_input'])\n","decoder_target = np.array(data['decoder_target'])\n","\n","# 데이터의 수만큼 정수 시퀀스 생성 후 shuffling\n","indices = np.arange(encoder_input.shape[0])\n","\n","np.random.seed(seed=0)\n","np.random.shuffle(indices)\n","\n","encoder_input = encoder_input[indices]\n","decoder_input = decoder_input[indices]\n","decoder_target = decoder_target[indices]\n","\n","# 인코더 입력, 디코더 입력, 디코더 레이블 데이터를 training data와 test data로 분리\n","n_of_val = int(len(encoder_input)*0.2)\n","\n","encoder_input_train = encoder_input[:-n_of_val]\n","decoder_input_train = decoder_input[:-n_of_val]\n","decoder_target_train = decoder_target[:-n_of_val]\n","\n","encoder_input_test = encoder_input[-n_of_val:]\n","decoder_input_test = decoder_input[-n_of_val:]\n","decoder_target_test = decoder_target[-n_of_val:]\n","\n","print('training data의 개수 :', len(encoder_input_train))\n","print('test data의 개수 :',len(encoder_input_test))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training data의 개수 : 52655\n","test data의 개수 : 13163\n"]}]},{"cell_type":"markdown","source":["### 3. 정수 인코딩"],"metadata":{"id":"g3WST0YiZG4n"}},{"cell_type":"markdown","source":["3-1. Text 정수 인코딩"],"metadata":{"id":"NZcL1FV_Zbas"}},{"cell_type":"code","metadata":{"id":"Jm5CavCyVySc","executionInfo":{"status":"ok","timestamp":1700045372249,"user_tz":-540,"elapsed":633,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"e3d5fd6d-7e42-4b94-dd17-2e6cedfb99ec"},"source":["src_tokenizer = Tokenizer()\n","src_tokenizer.fit_on_texts(encoder_input_train)\n","\n","threshold = 7\n","total_cnt = len(src_tokenizer.word_index)  # 단어의 수\n","rare_cnt = 0  # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0  # training data의 전체 단어 빈도수 총 합\n","rare_freq = 0  # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받음\n","for key, value in src_tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('전체 단어의 수: %s' % (total_cnt))\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' % (threshold - 1, rare_cnt))\n","print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'% (total_cnt - rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율: %.3f\" % (rare_cnt / total_cnt))\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: %.3f\" % (rare_freq / total_freq))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 단어의 수: 32031\n","등장 빈도가 6번 이하인 희귀 단어의 수: 23779\n","단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 8252\n","단어 집합에서 희귀 단어의 비율: 0.742\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.034\n"]}]},{"cell_type":"code","metadata":{"id":"1MA9Q1yomMRb","executionInfo":{"status":"ok","timestamp":1700045375245,"user_tz":-540,"elapsed":3002,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"65d36f70-af07-4014-e69a-83e526292475"},"source":["src_vocab = 8000\n","src_tokenizer = Tokenizer(num_words = src_vocab)\n","src_tokenizer.fit_on_texts(encoder_input_train)\n","\n","# 텍스트 시퀀스를 정수 시퀀스로 변환\n","print(encoder_input_train[0])\n","\n","encoder_input_train = src_tokenizer.texts_to_sequences(encoder_input_train)\n","encoder_input_test = src_tokenizer.texts_to_sequences(encoder_input_test)\n","\n","print(encoder_input_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["warning matter picture shows tin ordered thought getting tin quality street like states picture description received lb plastic jar container uk anymore ordered wanted tin put xmas tree rekindle old christmas tradition like many years ago younger safe say happen year giving rating allow give\n","[1882, 805, 844, 1855, 1120, 72, 131, 203, 1120, 83, 3896, 1, 1013, 844, 757, 167, 601, 350, 519, 435, 2482, 626, 72, 302, 1120, 132, 4281, 1007, 102, 449, 3450, 1, 75, 90, 343, 2307, 1188, 114, 1639, 166, 431, 1333, 1847, 70]\n"]}]},{"cell_type":"markdown","source":["3-2. Summary 정수 인코딩"],"metadata":{"id":"wBZ7vOcUatHT"}},{"cell_type":"code","metadata":{"id":"TxzhtQoLmOF0"},"source":["tar_tokenizer = Tokenizer()\n","tar_tokenizer.fit_on_texts(decoder_input_train)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xNvJIUZsmOxE","executionInfo":{"status":"ok","timestamp":1700045375799,"user_tz":-540,"elapsed":9,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"0af4eaaa-f1da-493d-e3c6-3defcf794efc"},"source":["threshold = 6\n","total_cnt = len(tar_tokenizer.word_index) # 단어의 수\n","rare_cnt = 0  # 등장 빈도수가 threshold보다 작은 단어의 개수를 카운트\n","total_freq = 0  # training data의 전체 단어 빈도수 총 합\n","rare_freq = 0  # 등장 빈도수가 threshold보다 작은 단어의 등장 빈도수의 총 합\n","\n","# 단어와 빈도수의 쌍(pair)을 key와 value로 받음\n","for key, value in tar_tokenizer.word_counts.items():\n","    total_freq = total_freq + value\n","\n","    # 단어의 등장 빈도수가 threshold보다 작으면\n","    if(value < threshold):\n","        rare_cnt = rare_cnt + 1\n","        rare_freq = rare_freq + value\n","\n","print('전체 단어의 수: %s' % (total_cnt))\n","print('등장 빈도가 %s번 이하인 희귀 단어의 수: %s' % (threshold - 1, rare_cnt))\n","print('단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 %s'% (total_cnt - rare_cnt))\n","print(\"단어 집합에서 희귀 단어의 비율: %.3f\" % (rare_cnt / total_cnt))\n","print(\"전체 등장 빈도에서 희귀 단어 등장 빈도 비율: %.3f\" % (rare_freq / total_freq))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["전체 단어의 수: 10510\n","등장 빈도가 5번 이하인 희귀 단어의 수: 8128\n","단어 집합에서 희귀 단어를 제외시킬 경우의 단어 집합의 크기 2382\n","단어 집합에서 희귀 단어의 비율: 0.773\n","전체 등장 빈도에서 희귀 단어 등장 빈도 비율: 0.059\n"]}]},{"cell_type":"code","metadata":{"id":"PtuS3Zr8mPoN","executionInfo":{"status":"ok","timestamp":1700045378378,"user_tz":-540,"elapsed":2583,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"b47be81d-376b-4b74-d311-a7b07c02b370"},"source":["tar_vocab = 2000\n","tar_tokenizer = Tokenizer(num_words = tar_vocab)\n","tar_tokenizer.fit_on_texts(decoder_input_train)\n","tar_tokenizer.fit_on_texts(decoder_target_train)\n","\n","# 텍스트 시퀀스를 정수 시퀀스로 변환\n","print(decoder_target_train[0])\n","\n","decoder_input_train = tar_tokenizer.texts_to_sequences(decoder_input_train)\n","decoder_target_train = tar_tokenizer.texts_to_sequences(decoder_target_train)\n","\n","decoder_input_test = tar_tokenizer.texts_to_sequences(decoder_input_test)\n","decoder_target_test = tar_tokenizer.texts_to_sequences(decoder_target_test)\n","\n","print(decoder_target_train[0])"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["warning eostoken\n","[687, 2]\n"]}]},{"cell_type":"markdown","source":["### 4. 빈 Summary 제거 및 패딩(padding)"],"metadata":{"id":"x2VSubAscJKP"}},{"cell_type":"code","metadata":{"id":"d6924EBsmRD0","executionInfo":{"status":"ok","timestamp":1700045378378,"user_tz":-540,"elapsed":8,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"d3485417-4f9c-430c-a721-678ff94df8e8"},"source":["# Summary의 길이가 1인 경우 제거하기 위해 index를 저장\n","drop_train = [index for index, sentence in enumerate(decoder_input_train) if len(sentence) == 1]\n","drop_test = [index for index, sentence in enumerate(decoder_input_test) if len(sentence) == 1]\n","\n","# 저장한 index에 해당하는 데이터를 제거\n","encoder_input_train = np.delete(encoder_input_train, drop_train, axis=0)\n","decoder_input_train = np.delete(decoder_input_train, drop_train, axis=0)\n","decoder_target_train = np.delete(decoder_target_train, drop_train, axis=0)\n","\n","encoder_input_test = np.delete(encoder_input_test, drop_test, axis=0)\n","decoder_input_test = np.delete(decoder_input_test, drop_test, axis=0)\n","decoder_target_test = np.delete(decoder_target_test, drop_test, axis=0)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/numpy/lib/function_base.py:5071: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n","  arr = asarray(arr)\n"]}]},{"cell_type":"code","metadata":{"id":"Jicti7sEmR2A"},"source":["# Text와 Summary를 정해진 길이 만큼 패딩처리\n","encoder_input_train = pad_sequences(encoder_input_train, maxlen = text_max_len, padding='post')\n","encoder_input_test = pad_sequences(encoder_input_test, maxlen = text_max_len, padding='post')\n","\n","decoder_input_train = pad_sequences(decoder_input_train, maxlen = summary_max_len, padding='post')\n","decoder_target_train = pad_sequences(decoder_target_train, maxlen = summary_max_len, padding='post')\n","\n","decoder_input_test = pad_sequences(decoder_input_test, maxlen = summary_max_len, padding='post')\n","decoder_target_test = pad_sequences(decoder_target_test, maxlen = summary_max_len, padding='post')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XsuLgBCwmTUc","executionInfo":{"status":"ok","timestamp":1700045379016,"user_tz":-540,"elapsed":21,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"206dfcc7-e909-4b1b-df9e-bb1cddd43e22"},"source":["encoder_input_train[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([1882,  805,  844, 1855, 1120,   72,  131,  203, 1120,   83, 3896,\n","          1, 1013,  844,  757,  167,  601,  350,  519,  435, 2482,  626,\n","         72,  302, 1120,  132, 4281, 1007,  102,  449, 3450,    1,   75,\n","         90,  343, 2307, 1188,  114, 1639,  166,  431, 1333, 1847,   70,\n","          0,    0,    0,    0,    0,    0], dtype=int32)"]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["print('training data의 개수 :', len(encoder_input_train))\n","print('test data의 개수 :',len(encoder_input_test))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"A2Wgd3yqVLwy","executionInfo":{"status":"ok","timestamp":1700045379017,"user_tz":-540,"elapsed":18,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"outputId":"6013ddb2-f65e-4621-fef1-30b0113addea"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["training data의 개수 : 51420\n","test data의 개수 : 12826\n"]}]},{"cell_type":"markdown","source":["### 5. seq2seq + attention으로 요약 모델 설계 및 훈련\n","\n"],"metadata":{"id":"MXevzaaXd1KP"}},{"cell_type":"code","metadata":{"id":"1io95xrrmUis"},"source":["from tensorflow.keras.layers import Input, LSTM, Embedding, Dense, Concatenate\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5-1. 인코더"],"metadata":{"id":"txEar3pYfNtV"}},{"cell_type":"code","metadata":{"id":"h_XiT21VmVtN"},"source":["embedding_dim = 128\n","hidden_size = 256\n","\n","# 인코더\n","encoder_inputs = Input(shape=(text_max_len,))\n","\n","# 인코더의 임베딩 층\n","enc_emb = Embedding(src_vocab, embedding_dim)(encoder_inputs)\n","\n","# 인코더의 LSTM 1\n","encoder_lstm1 = LSTM(hidden_size, return_sequences=True, return_state=True ,dropout = 0.4)\n","encoder_output1, state_h1, state_c1 = encoder_lstm1(enc_emb)\n","\n","# 인코더의 LSTM 2\n","encoder_lstm2 = LSTM(hidden_size, return_sequences=True, return_state=True, dropout=0.4)\n","encoder_output2, state_h2, state_c2 = encoder_lstm2(encoder_output1)\n","\n","# 인코더의 LSTM 3\n","encoder_lstm3 = LSTM(hidden_size, return_state=True, return_sequences=True, dropout=0.4)\n","encoder_outputs, state_h, state_c= encoder_lstm3(encoder_output2)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["5-2. 디코더"],"metadata":{"id":"3MCYA4zZffBM"}},{"cell_type":"code","metadata":{"id":"17OIN0TsmWoF"},"source":["# 디코더\n","decoder_inputs = Input(shape=(None,))\n","\n","# 디코더의 임베딩 층\n","dec_emb_layer = Embedding(tar_vocab, embedding_dim)\n","dec_emb = dec_emb_layer(decoder_inputs)\n","\n","# 디코더의 LSTM\n","decoder_lstm = LSTM(hidden_size, return_sequences = True, return_state = True, dropout = 0.4)\n","decoder_outputs, _, _ = decoder_lstm(dec_emb, initial_state = [state_h, state_c])  # 디코더의 initial_state는 인코더의 상태(state_h, state_c)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"df9gNGkFsiEA"},"source":["5-3. Attention layer(바다나우 어텐션, Bahdanau attention)"]},{"cell_type":"code","metadata":{"id":"jwYCBOJDbnf5"},"source":["import tensorflow as tf\n","import os\n","from tensorflow.keras.layers import Layer\n","from tensorflow.keras import backend as K\n","\n","\n","class AttentionLayer(Layer):\n","    \"\"\"\n","    This class implements Bahdanau attention (https://arxiv.org/pdf/1409.0473.pdf).\n","    There are three sets of weights introduced W_a, U_a, and V_a\n","     \"\"\"\n","\n","    def __init__(self, **kwargs):\n","        super(AttentionLayer, self).__init__(**kwargs)\n","\n","    def build(self, input_shape):\n","        assert isinstance(input_shape, list)\n","        # Create a trainable weight variable for this layer.\n","\n","        self.W_a = self.add_weight(name='W_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.U_a = self.add_weight(name='U_a',\n","                                   shape=tf.TensorShape((input_shape[1][2], input_shape[0][2])),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","        self.V_a = self.add_weight(name='V_a',\n","                                   shape=tf.TensorShape((input_shape[0][2], 1)),\n","                                   initializer='uniform',\n","                                   trainable=True)\n","\n","        super(AttentionLayer, self).build(input_shape)  # Be sure to call this at the end\n","\n","    def call(self, inputs, verbose=False):\n","        \"\"\"\n","        inputs: [encoder_output_sequence, decoder_output_sequence]\n","        \"\"\"\n","        assert type(inputs) == list\n","        encoder_out_seq, decoder_out_seq = inputs\n","        if verbose:\n","            print('encoder_out_seq>', encoder_out_seq.shape)\n","            print('decoder_out_seq>', decoder_out_seq.shape)\n","\n","        def energy_step(inputs, states):\n","            \"\"\" Step function for computing energy for a single decoder state\n","            inputs: (batchsize * 1 * de_in_dim)\n","            states: (batchsize * 1 * de_latent_dim)\n","            \"\"\"\n","\n","            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            \"\"\" Some parameters required for shaping tensors\"\"\"\n","            en_seq_len, en_hidden = encoder_out_seq.shape[1], encoder_out_seq.shape[2]\n","            de_hidden = inputs.shape[-1]\n","\n","            \"\"\" Computing S.Wa where S=[s0, s1, ..., si]\"\"\"\n","            # <= batch size * en_seq_len * latent_dim\n","            W_a_dot_s = K.dot(encoder_out_seq, self.W_a)\n","\n","            \"\"\" Computing hj.Ua \"\"\"\n","            U_a_dot_h = K.expand_dims(K.dot(inputs, self.U_a), 1)  # <= batch_size, 1, latent_dim\n","            if verbose:\n","                print('Ua.h>', U_a_dot_h.shape)\n","\n","            \"\"\" tanh(S.Wa + hj.Ua) \"\"\"\n","            # <= batch_size*en_seq_len, latent_dim\n","            Ws_plus_Uh = K.tanh(W_a_dot_s + U_a_dot_h)\n","            if verbose:\n","                print('Ws+Uh>', Ws_plus_Uh.shape)\n","\n","            \"\"\" softmax(va.tanh(S.Wa + hj.Ua)) \"\"\"\n","            # <= batch_size, en_seq_len\n","            e_i = K.squeeze(K.dot(Ws_plus_Uh, self.V_a), axis=-1)\n","            # <= batch_size, en_seq_len\n","            e_i = K.softmax(e_i)\n","\n","            if verbose:\n","                print('ei>', e_i.shape)\n","\n","            return e_i, [e_i]\n","\n","        def context_step(inputs, states):\n","            \"\"\" Step function for computing ci using ei \"\"\"\n","\n","            assert_msg = \"States must be an iterable. Got {} of type {}\".format(states, type(states))\n","            assert isinstance(states, list) or isinstance(states, tuple), assert_msg\n","\n","            # <= batch_size, hidden_size\n","            c_i = K.sum(encoder_out_seq * K.expand_dims(inputs, -1), axis=1)\n","            if verbose:\n","                print('ci>', c_i.shape)\n","            return c_i, [c_i]\n","\n","        fake_state_c = K.sum(encoder_out_seq, axis=1)\n","        fake_state_e = K.sum(encoder_out_seq, axis=2)  # <= (batch_size, enc_seq_len, latent_dim\n","\n","        \"\"\" Computing energy outputs \"\"\"\n","        # e_outputs => (batch_size, de_seq_len, en_seq_len)\n","        last_out, e_outputs, _ = K.rnn(\n","            energy_step, decoder_out_seq, [fake_state_e],\n","        )\n","\n","        \"\"\" Computing context vectors \"\"\"\n","        last_out, c_outputs, _ = K.rnn(\n","            context_step, e_outputs, [fake_state_c],\n","        )\n","\n","        return c_outputs, e_outputs\n","\n","    def compute_output_shape(self, input_shape):\n","        \"\"\" Outputs produced by the layer \"\"\"\n","        return [\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[1][2])),\n","            tf.TensorShape((input_shape[1][0], input_shape[1][1], input_shape[0][1]))\n","        ]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k73clQ2AmdfN"},"source":["# attention 함수\n","attn_layer = AttentionLayer(name='attention_layer')\n","attn_out, attn_states = attn_layer([encoder_outputs, decoder_outputs])\n","\n","# attention 결과와 디코더의 hidden state들을 연결\n","decoder_concat_input = Concatenate(axis = -1, name='concat_layer')([decoder_outputs, attn_out])\n","\n","# 디코더의 출력층\n","decoder_softmax_layer = Dense(tar_vocab, activation='softmax')\n","decoder_softmax_outputs = decoder_softmax_layer(decoder_concat_input)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LcOasiuYnV78","executionInfo":{"status":"ok","timestamp":1700045533038,"user_tz":-540,"elapsed":149764,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"569655d2-8bc2-404d-f28f-0d6bcfb66556"},"source":["# 모델 정의\n","model = Model([encoder_inputs, decoder_inputs], decoder_softmax_outputs)\n","model.summary()\n","\n","model.compile(optimizer='rmsprop', loss='sparse_categorical_crossentropy')\n","\n","es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience = 2)\n","\n","history = model.fit(x = [encoder_input_train, decoder_input_train], y = decoder_target_train, \\\n","          validation_data = ([encoder_input_test, decoder_input_test], decoder_target_test),\n","          batch_size = 256, callbacks=[es], epochs = 5)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model\"\n","__________________________________________________________________________________________________\n"," Layer (type)                Output Shape                 Param #   Connected to                  \n","==================================================================================================\n"," input_1 (InputLayer)        [(None, 50)]                 0         []                            \n","                                                                                                  \n"," embedding (Embedding)       (None, 50, 128)              1024000   ['input_1[0][0]']             \n","                                                                                                  \n"," lstm (LSTM)                 [(None, 50, 256),            394240    ['embedding[0][0]']           \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," input_2 (InputLayer)        [(None, None)]               0         []                            \n","                                                                                                  \n"," lstm_1 (LSTM)               [(None, 50, 256),            525312    ['lstm[0][0]']                \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," embedding_1 (Embedding)     (None, None, 128)            256000    ['input_2[0][0]']             \n","                                                                                                  \n"," lstm_2 (LSTM)               [(None, 50, 256),            525312    ['lstm_1[0][0]']              \n","                              (None, 256),                                                        \n","                              (None, 256)]                                                        \n","                                                                                                  \n"," lstm_3 (LSTM)               [(None, None, 256),          394240    ['embedding_1[0][0]',         \n","                              (None, 256),                           'lstm_2[0][1]',              \n","                              (None, 256)]                           'lstm_2[0][2]']              \n","                                                                                                  \n"," attention_layer (Attention  ((None, None, 256),          131328    ['lstm_2[0][0]',              \n"," Layer)                       (None, None, 50))                      'lstm_3[0][0]']              \n","                                                                                                  \n"," concat_layer (Concatenate)  (None, None, 512)            0         ['lstm_3[0][0]',              \n","                                                                     'attention_layer[0][0]']     \n","                                                                                                  \n"," dense (Dense)               (None, None, 2000)           1026000   ['concat_layer[0][0]']        \n","                                                                                                  \n","==================================================================================================\n","Total params: 4276432 (16.31 MB)\n","Trainable params: 4276432 (16.31 MB)\n","Non-trainable params: 0 (0.00 Byte)\n","__________________________________________________________________________________________________\n","Epoch 1/5\n","201/201 [==============================] - 41s 141ms/step - loss: 2.9069 - val_loss: 2.5570\n","Epoch 2/5\n","201/201 [==============================] - 21s 102ms/step - loss: 2.5481 - val_loss: 2.5022\n","Epoch 3/5\n","201/201 [==============================] - 21s 104ms/step - loss: 2.4758 - val_loss: 2.4328\n","Epoch 4/5\n","201/201 [==============================] - 19s 95ms/step - loss: 2.4179 - val_loss: 2.3775\n","Epoch 5/5\n","201/201 [==============================] - 20s 101ms/step - loss: 2.3580 - val_loss: 2.3350\n"]}]},{"cell_type":"markdown","source":["### 6. seq2seq + attention으로 요약 모델 테스트\n"],"metadata":{"id":"hrrOR1Yog403"}},{"cell_type":"code","source":["src_index_to_word = src_tokenizer.index_word # Text 단어 집합에서 정수 -> 단어를 얻음\n","tar_word_to_index = tar_tokenizer.word_index # Summary 단어 집합에서 단어 -> 정수를 얻음\n","tar_index_to_word = tar_tokenizer.index_word # Summary 단어 집합에서 정수 -> 단어를 얻음"],"metadata":{"id":"A25m-vddgeQ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["src_index_to_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7wrbtfV5jZR7","executionInfo":{"status":"ok","timestamp":1700045533038,"user_tz":-540,"elapsed":15,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"outputId":"d34f7dd0-91d7-4ae1-ad20-55a55c79b0e1"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{1: 'like',\n"," 2: 'good',\n"," 3: 'great',\n"," 4: 'taste',\n"," 5: 'product',\n"," 6: 'love',\n"," 7: 'one',\n"," 8: 'flavor',\n"," 9: 'coffee',\n"," 10: 'would',\n"," 11: 'tea',\n"," 12: 'really',\n"," 13: 'get',\n"," 14: 'amazon',\n"," 15: 'best',\n"," 16: 'price',\n"," 17: 'buy',\n"," 18: 'food',\n"," 19: 'much',\n"," 20: 'little',\n"," 21: 'time',\n"," 22: 'use',\n"," 23: 'find',\n"," 24: 'tried',\n"," 25: 'better',\n"," 26: 'also',\n"," 27: 'well',\n"," 28: 'make',\n"," 29: 'chocolate',\n"," 30: 'try',\n"," 31: 'dog',\n"," 32: 'eat',\n"," 33: 'even',\n"," 34: 'bought',\n"," 35: 'delicious',\n"," 36: 'found',\n"," 37: 'sweet',\n"," 38: 'order',\n"," 39: 'could',\n"," 40: 'tastes',\n"," 41: 'cup',\n"," 42: 'recommend',\n"," 43: 'loves',\n"," 44: 'drink',\n"," 45: 'used',\n"," 46: 'favorite',\n"," 47: 'sugar',\n"," 48: 'bag',\n"," 49: 'cannot',\n"," 50: 'first',\n"," 51: 'store',\n"," 52: 'free',\n"," 53: 'nice',\n"," 54: 'way',\n"," 55: 'made',\n"," 56: 'go',\n"," 57: 'box',\n"," 58: 'got',\n"," 59: 'perfect',\n"," 60: 'dogs',\n"," 61: 'day',\n"," 62: 'mix',\n"," 63: 'bit',\n"," 64: 'think',\n"," 65: 'easy',\n"," 66: 'water',\n"," 67: 'since',\n"," 68: 'hot',\n"," 69: 'snack',\n"," 70: 'give',\n"," 71: 'two',\n"," 72: 'ordered',\n"," 73: 'ever',\n"," 74: 'still',\n"," 75: 'many',\n"," 76: 'every',\n"," 77: 'flavors',\n"," 78: 'makes',\n"," 79: 'never',\n"," 80: 'stuff',\n"," 81: 'know',\n"," 82: 'always',\n"," 83: 'quality',\n"," 84: 'treats',\n"," 85: 'right',\n"," 86: 'without',\n"," 87: 'brand',\n"," 88: 'healthy',\n"," 89: 'fresh',\n"," 90: 'years',\n"," 91: 'want',\n"," 92: 'tasty',\n"," 93: 'keep',\n"," 94: 'definitely',\n"," 95: 'add',\n"," 96: 'lot',\n"," 97: 'strong',\n"," 98: 'something',\n"," 99: 'buying',\n"," 100: 'hard',\n"," 101: 'small',\n"," 102: 'old',\n"," 103: 'happy',\n"," 104: 'treat',\n"," 105: 'bad',\n"," 106: 'enough',\n"," 107: 'enjoy',\n"," 108: 'excellent',\n"," 109: 'wonderful',\n"," 110: 'local',\n"," 111: 'milk',\n"," 112: 'less',\n"," 113: 'chips',\n"," 114: 'say',\n"," 115: 'highly',\n"," 116: 'need',\n"," 117: 'however',\n"," 118: 'different',\n"," 119: 'shipping',\n"," 120: 'organic',\n"," 121: 'purchase',\n"," 122: 'far',\n"," 123: 'salt',\n"," 124: 'sure',\n"," 125: 'eating',\n"," 126: 'long',\n"," 127: 'regular',\n"," 128: 'tasting',\n"," 129: 'size',\n"," 130: 'looking',\n"," 131: 'thought',\n"," 132: 'put',\n"," 133: 'back',\n"," 134: 'though',\n"," 135: 'stores',\n"," 136: 'products',\n"," 137: 'tasted',\n"," 138: 'purchased',\n"," 139: 'cups',\n"," 140: 'using',\n"," 141: 'whole',\n"," 142: 'pack',\n"," 143: 'bars',\n"," 144: 'pretty',\n"," 145: 'bags',\n"," 146: 'work',\n"," 147: 'loved',\n"," 148: 'worth',\n"," 149: 'big',\n"," 150: 'high',\n"," 151: 'sauce',\n"," 152: 'low',\n"," 153: 'thing',\n"," 154: 'cookies',\n"," 155: 'texture',\n"," 156: 'family',\n"," 157: 'gluten',\n"," 158: 'ingredients',\n"," 159: 'arrived',\n"," 160: 'package',\n"," 161: 'grocery',\n"," 162: 'quite',\n"," 163: 'green',\n"," 164: 'last',\n"," 165: 'going',\n"," 166: 'year',\n"," 167: 'received',\n"," 168: 'popcorn',\n"," 169: 'rice',\n"," 170: 'take',\n"," 171: 'almost',\n"," 172: 'cat',\n"," 173: 'came',\n"," 174: 'candy',\n"," 175: 'anything',\n"," 176: 'actually',\n"," 177: 'real',\n"," 178: 'item',\n"," 179: 'feel',\n"," 180: 'see',\n"," 181: 'expensive',\n"," 182: 'dark',\n"," 183: 'natural',\n"," 184: 'calories',\n"," 185: 'oil',\n"," 186: 'chicken',\n"," 187: 'husband',\n"," 188: 'cereal',\n"," 189: 'new',\n"," 190: 'butter',\n"," 191: 'another',\n"," 192: 'full',\n"," 193: 'kids',\n"," 194: 'money',\n"," 195: 'blend',\n"," 196: 'people',\n"," 197: 'brands',\n"," 198: 'disappointed',\n"," 199: 'bar',\n"," 200: 'absolutely',\n"," 201: 'trying',\n"," 202: 'around',\n"," 203: 'getting',\n"," 204: 'fruit',\n"," 205: 'amount',\n"," 206: 'morning',\n"," 207: 'smell',\n"," 208: 'several',\n"," 209: 'home',\n"," 210: 'coconut',\n"," 211: 'half',\n"," 212: 'away',\n"," 213: 'added',\n"," 214: 'fast',\n"," 215: 'cheese',\n"," 216: 'wish',\n"," 217: 'bitter',\n"," 218: 'dry',\n"," 219: 'usually',\n"," 220: 'us',\n"," 221: 'fat',\n"," 222: 'diet',\n"," 223: 'smooth',\n"," 224: 'able',\n"," 225: 'available',\n"," 226: 'per',\n"," 227: 'come',\n"," 228: 'kind',\n"," 229: 'probably',\n"," 230: 'oz',\n"," 231: 'ones',\n"," 232: 'light',\n"," 233: 'foods',\n"," 234: 'nothing',\n"," 235: 'flavored',\n"," 236: 'works',\n"," 237: 'deal',\n"," 238: 'may',\n"," 239: 'problem',\n"," 240: 'breakfast',\n"," 241: 'ordering',\n"," 242: 'company',\n"," 243: 'cats',\n"," 244: 'liked',\n"," 245: 'boxes',\n"," 246: 'things',\n"," 247: 'case',\n"," 248: 'said',\n"," 249: 'cheaper',\n"," 250: 'quick',\n"," 251: 'days',\n"," 252: 'months',\n"," 253: 'save',\n"," 254: 'especially',\n"," 255: 'making',\n"," 256: 'seems',\n"," 257: 'variety',\n"," 258: 'glad',\n"," 259: 'reviews',\n"," 260: 'peanut',\n"," 261: 'black',\n"," 262: 'honey',\n"," 263: 'gift',\n"," 264: 'large',\n"," 265: 'fine',\n"," 266: 'quickly',\n"," 267: 'bread',\n"," 268: 'packaging',\n"," 269: 'pasta',\n"," 270: 'bottle',\n"," 271: 'others',\n"," 272: 'juice',\n"," 273: 'gave',\n"," 274: 'recommended',\n"," 275: 'drinking',\n"," 276: 'comes',\n"," 277: 'son',\n"," 278: 'rich',\n"," 279: 'look',\n"," 280: 'protein',\n"," 281: 'instead',\n"," 282: 'three',\n"," 283: 'amazing',\n"," 284: 'syrup',\n"," 285: 'house',\n"," 286: 'prefer',\n"," 287: 'spicy',\n"," 288: 'top',\n"," 289: 'teeth',\n"," 290: 'anyone',\n"," 291: 'energy',\n"," 292: 'roast',\n"," 293: 'likes',\n"," 294: 'thanks',\n"," 295: 'times',\n"," 296: 'cream',\n"," 297: 'vanilla',\n"," 298: 'yummy',\n"," 299: 'thank',\n"," 300: 'white',\n"," 301: 'everyone',\n"," 302: 'wanted',\n"," 303: 'cans',\n"," 304: 'month',\n"," 305: 'might',\n"," 306: 'fan',\n"," 307: 'plus',\n"," 308: 'next',\n"," 309: 'salty',\n"," 310: 'meal',\n"," 311: 'seem',\n"," 312: 'daughter',\n"," 313: 'else',\n"," 314: 'fact',\n"," 315: 'maybe',\n"," 316: 'soft',\n"," 317: 'awesome',\n"," 318: 'pieces',\n"," 319: 'extra',\n"," 320: 'value',\n"," 321: 'stars',\n"," 322: 'must',\n"," 323: 'cost',\n"," 324: 'teas',\n"," 325: 'friends',\n"," 326: 'everything',\n"," 327: 'baby',\n"," 328: 'either',\n"," 329: 'keurig',\n"," 330: 'enjoyed',\n"," 331: 'nuts',\n"," 332: 'least',\n"," 333: 'ginger',\n"," 334: 'bold',\n"," 335: 'health',\n"," 336: 'crunchy',\n"," 337: 'couple',\n"," 338: 'super',\n"," 339: 'longer',\n"," 340: 'yet',\n"," 341: 'beans',\n"," 342: 'open',\n"," 343: 'ago',\n"," 344: 'went',\n"," 345: 'soup',\n"," 346: 'online',\n"," 347: 'pleased',\n"," 348: 'decided',\n"," 349: 'ice',\n"," 350: 'plastic',\n"," 351: 'market',\n"," 352: 'ok',\n"," 353: 'help',\n"," 354: 'mouth',\n"," 355: 'cold',\n"," 356: 'pepper',\n"," 357: 'snacks',\n"," 358: 'started',\n"," 359: 'review',\n"," 360: 'chew',\n"," 361: 'took',\n"," 362: 'expected',\n"," 363: 'corn',\n"," 364: 'week',\n"," 365: 'lemon',\n"," 366: 'minutes',\n"," 367: 'rather',\n"," 368: 'delivery',\n"," 369: 'says',\n"," 370: 'service',\n"," 371: 'noodles',\n"," 372: 'although',\n"," 373: 'alternative',\n"," 374: 'powder',\n"," 375: 'cocoa',\n"," 376: 'let',\n"," 377: 'flavorful',\n"," 378: 'jerky',\n"," 379: 'read',\n"," 380: 'second',\n"," 381: 'wife',\n"," 382: 'goes',\n"," 383: 'crackers',\n"," 384: 'version',\n"," 385: 'soda',\n"," 386: 'machine',\n"," 387: 'wheat',\n"," 388: 'french',\n"," 389: 'cookie',\n"," 390: 'beef',\n"," 391: 'ounce',\n"," 392: 'drinks',\n"," 393: 'exactly',\n"," 394: 'type',\n"," 395: 'sometimes',\n"," 396: 'weight',\n"," 397: 'plain',\n"," 398: 'cooking',\n"," 399: 'surprised',\n"," 400: 'gets',\n"," 401: 'special',\n"," 402: 'aroma',\n"," 403: 'side',\n"," 404: 'red',\n"," 405: 'meat',\n"," 406: 'mixed',\n"," 407: 'smaller',\n"," 408: 'cook',\n"," 409: 'decaf',\n"," 410: 'believe',\n"," 411: 'easily',\n"," 412: 'problems',\n"," 413: 'dried',\n"," 414: 'clean',\n"," 415: 'opened',\n"," 416: 'convenient',\n"," 417: 'friend',\n"," 418: 'guess',\n"," 419: 'fantastic',\n"," 420: 'cake',\n"," 421: 'part',\n"," 422: 'wrong',\n"," 423: 'packaged',\n"," 424: 'artificial',\n"," 425: 'tell',\n"," 426: 'orange',\n"," 427: 'aftertaste',\n"," 428: 'smells',\n"," 429: 'hand',\n"," 430: 'choice',\n"," 431: 'giving',\n"," 432: 'subscribe',\n"," 433: 'place',\n"," 434: 'shipped',\n"," 435: 'container',\n"," 436: 'packs',\n"," 437: 'coffees',\n"," 438: 'refreshing',\n"," 439: 'difference',\n"," 440: 'stomach',\n"," 441: 'serving',\n"," 442: 'mild',\n"," 443: 'picky',\n"," 444: 'oatmeal',\n"," 445: 'recipe',\n"," 446: 'bulk',\n"," 447: 'line',\n"," 448: 'reason',\n"," 449: 'christmas',\n"," 450: 'brown',\n"," 451: 'care',\n"," 452: 'left',\n"," 453: 'seeds',\n"," 454: 'slightly',\n"," 455: 'continue',\n"," 456: 'recently',\n"," 457: 'cinnamon',\n"," 458: 'pop',\n"," 459: 'starbucks',\n"," 460: 'spice',\n"," 461: 'run',\n"," 462: 'lots',\n"," 463: 'live',\n"," 464: 'potato',\n"," 465: 'brew',\n"," 466: 'etc',\n"," 467: 'iced',\n"," 468: 'often',\n"," 469: 'cherry',\n"," 470: 'cut',\n"," 471: 'almonds',\n"," 472: 'pay',\n"," 473: 'bite',\n"," 474: 'life',\n"," 475: 'huge',\n"," 476: 'carry',\n"," 477: 'chewy',\n"," 478: 'looks',\n"," 479: 'stick',\n"," 480: 'sent',\n"," 481: 'end',\n"," 482: 'compared',\n"," 483: 'needed',\n"," 484: 'past',\n"," 485: 'close',\n"," 486: 'delivered',\n"," 487: 'fiber',\n"," 488: 'gives',\n"," 489: 'simply',\n"," 490: 'looked',\n"," 491: 'dinner',\n"," 492: 'excited',\n"," 493: 'ate',\n"," 494: 'bottles',\n"," 495: 'calorie',\n"," 496: 'toy',\n"," 497: 'packages',\n"," 498: 'chai',\n"," 499: 'unfortunately',\n"," 500: 'filling',\n"," 501: 'start',\n"," 502: 'seller',\n"," 503: 'night',\n"," 504: 'overall',\n"," 505: 'date',\n"," 506: 'gum',\n"," 507: 'apple',\n"," 508: 'weeks',\n"," 509: 'broken',\n"," 510: 'com',\n"," 511: 'larger',\n"," 512: 'original',\n"," 513: 'seasoning',\n"," 514: 'eaten',\n"," 515: 'lunch',\n"," 516: 'salad',\n"," 517: 'color',\n"," 518: 'canned',\n"," 519: 'jar',\n"," 520: 'soon',\n"," 521: 'helps',\n"," 522: 'items',\n"," 523: 'chip',\n"," 524: 'four',\n"," 525: 'granola',\n"," 526: 'someone',\n"," 527: 'needs',\n"," 528: 'creamy',\n"," 529: 'hope',\n"," 530: 'keeps',\n"," 531: 'idea',\n"," 532: 'similar',\n"," 533: 'nut',\n"," 534: 'finally',\n"," 535: 'extremely',\n"," 536: 'waste',\n"," 537: 'fish',\n"," 538: 'gone',\n"," 539: 'purchasing',\n"," 540: 'feed',\n"," 541: 'heat',\n"," 542: 'saw',\n"," 543: 'already',\n"," 544: 'weak',\n"," 545: 'stale',\n"," 546: 'inside',\n"," 547: 'takes',\n"," 548: 'healthier',\n"," 549: 'crunch',\n"," 550: 'course',\n"," 551: 'non',\n"," 552: 'pound',\n"," 553: 'wait',\n"," 554: 'star',\n"," 555: 'packed',\n"," 556: 'hooked',\n"," 557: 'pumpkin',\n"," 558: 'condition',\n"," 559: 'caffeine',\n"," 560: 'along',\n"," 561: 'microwave',\n"," 562: 'sweetness',\n"," 563: 'baking',\n"," 564: 'olive',\n"," 565: 'locally',\n"," 566: 'change',\n"," 567: 'single',\n"," 568: 'stock',\n"," 569: 'mine',\n"," 570: 'hours',\n"," 571: 'expect',\n"," 572: 'sold',\n"," 573: 'shipment',\n"," 574: 'please',\n"," 575: 'soy',\n"," 576: 'given',\n"," 577: 'beat',\n"," 578: 'experience',\n"," 579: 'anywhere',\n"," 580: 'name',\n"," 581: 'reasonable',\n"," 582: 'rest',\n"," 583: 'difficult',\n"," 584: 'packets',\n"," 585: 'consistency',\n"," 586: 'cheap',\n"," 587: 'adding',\n"," 588: 'flour',\n"," 589: 'sour',\n"," 590: 'stop',\n"," 591: 'crazy',\n"," 592: 'hit',\n"," 593: 'greenies',\n"," 594: 'daily',\n"," 595: 'due',\n"," 596: 'together',\n"," 597: 'instant',\n"," 598: 'substitute',\n"," 599: 'within',\n"," 600: 'yogurt',\n"," 601: 'lb',\n"," 602: 'leave',\n"," 603: 'banana',\n"," 604: 'ground',\n"," 605: 'almond',\n"," 606: 'chili',\n"," 607: 'espresso',\n"," 608: 'vet',\n"," 609: 'bowl',\n"," 610: 'medium',\n"," 611: 'list',\n"," 612: 'puppy',\n"," 613: 'worked',\n"," 614: 'totally',\n"," 615: 'certainly',\n"," 616: 'eats',\n"," 617: 'fun',\n"," 618: 'training',\n"," 619: 'pet',\n"," 620: 'break',\n"," 621: 'perfectly',\n"," 622: 'satisfying',\n"," 623: 'sodium',\n"," 624: 'leaves',\n"," 625: 'maker',\n"," 626: 'anymore',\n"," 627: 'stopped',\n"," 628: 'sale',\n"," 629: 'wow',\n"," 630: 'licorice',\n"," 631: 'yum',\n"," 632: 'thick',\n"," 633: 'shop',\n"," 634: 'easier',\n"," 635: 'combination',\n"," 636: 'chews',\n"," 637: 'pork',\n"," 638: 'batch',\n"," 639: 'throw',\n"," 640: 'hair',\n"," 641: 'future',\n"," 642: 'true',\n"," 643: 'mind',\n"," 644: 'pure',\n"," 645: 'opinion',\n"," 646: 'stay',\n"," 647: 'yes',\n"," 648: 'baked',\n"," 649: 'ingredient',\n"," 650: 'finding',\n"," 651: 'raw',\n"," 652: 'grain',\n"," 653: 'done',\n"," 654: 'entire',\n"," 655: 'become',\n"," 656: 'decent',\n"," 657: 'moist',\n"," 658: 'bland',\n"," 659: 'based',\n"," 660: 'mint',\n"," 661: 'sell',\n"," 662: 'area',\n"," 663: 'kick',\n"," 664: 'recipes',\n"," 665: 'okay',\n"," 666: 'horrible',\n"," 667: 'pricey',\n"," 668: 'today',\n"," 669: 'five',\n"," 670: 'satisfied',\n"," 671: 'completely',\n"," 672: 'pot',\n"," 673: 'spices',\n"," 674: 'summer',\n"," 675: 'maple',\n"," 676: 'dish',\n"," 677: 'world',\n"," 678: 'carb',\n"," 679: 'count',\n"," 680: 'priced',\n"," 681: 'plan',\n"," 682: 'truly',\n"," 683: 'hint',\n"," 684: 'hoping',\n"," 685: 'formula',\n"," 686: 'simple',\n"," 687: 'favorites',\n"," 688: 'packet',\n"," 689: 'finish',\n"," 690: 'later',\n"," 691: 'addition',\n"," 692: 'grey',\n"," 693: 'remember',\n"," 694: 'costco',\n"," 695: 'seemed',\n"," 696: 'twice',\n"," 697: 'pick',\n"," 698: 'content',\n"," 699: 'option',\n"," 700: 'mixes',\n"," 701: 'blue',\n"," 702: 'thin',\n"," 703: 'discovered',\n"," 704: 'none',\n"," 705: 'customer',\n"," 706: 'lower',\n"," 707: 'pancakes',\n"," 708: 'normally',\n"," 709: 'expecting',\n"," 710: 'bottom',\n"," 711: 'contains',\n"," 712: 'newman',\n"," 713: 'mess',\n"," 714: 'terrible',\n"," 715: 'mom',\n"," 716: 'cooked',\n"," 717: 'door',\n"," 718: 'pleasant',\n"," 719: 'varieties',\n"," 720: 'piece',\n"," 721: 'tiny',\n"," 722: 'serve',\n"," 723: 'told',\n"," 724: 'glass',\n"," 725: 'awful',\n"," 726: 'six',\n"," 727: 'dont',\n"," 728: 'switch',\n"," 729: 'ready',\n"," 730: 'vinegar',\n"," 731: 'forward',\n"," 732: 'body',\n"," 733: 'noticed',\n"," 734: 'adds',\n"," 735: 'particular',\n"," 736: 'roasted',\n"," 737: 'return',\n"," 738: 'hour',\n"," 739: 'seen',\n"," 740: 'veggies',\n"," 741: 'strawberry',\n"," 742: 'sweetener',\n"," 743: 'normal',\n"," 744: 'unless',\n"," 745: 'garlic',\n"," 746: 'oh',\n"," 747: 'bears',\n"," 748: 'label',\n"," 749: 'prices',\n"," 750: 'earl',\n"," 751: 'mountain',\n"," 752: 'turned',\n"," 753: 'drinker',\n"," 754: 'acid',\n"," 755: 'issues',\n"," 756: 'candies',\n"," 757: 'description',\n"," 758: 'warm',\n"," 759: 'supermarket',\n"," 760: 'felt',\n"," 761: 'chocolates',\n"," 762: 'impressed',\n"," 763: 'called',\n"," 764: 'anyway',\n"," 765: 'caramel',\n"," 766: 'everyday',\n"," 767: 'contain',\n"," 768: 'touch',\n"," 769: 'paid',\n"," 770: 'allergies',\n"," 771: 'job',\n"," 772: 'ask',\n"," 773: 'individual',\n"," 774: 'feeding',\n"," 775: 'unlike',\n"," 776: 'pie',\n"," 777: 'homemade',\n"," 778: 'pods',\n"," 779: 'agree',\n"," 780: 'loose',\n"," 781: 'italian',\n"," 782: 'otherwise',\n"," 783: 'thinking',\n"," 784: 'overly',\n"," 785: 'bones',\n"," 786: 'thrilled',\n"," 787: 'feeling',\n"," 788: 'sticks',\n"," 789: 'fit',\n"," 790: 'uses',\n"," 791: 'skin',\n"," 792: 'chewing',\n"," 793: 'stronger',\n"," 794: 'subscription',\n"," 795: 'taking',\n"," 796: 'peanuts',\n"," 797: 'raspberry',\n"," 798: 'meals',\n"," 799: 'shape',\n"," 800: 'bring',\n"," 801: 'liquid',\n"," 802: 'immediately',\n"," 803: 'sealed',\n"," 804: 'heavy',\n"," 805: 'matter',\n"," 806: 'carrying',\n"," 807: 'person',\n"," 808: 'ship',\n"," 809: 'overpowering',\n"," 810: 'salmon',\n"," 811: 'hands',\n"," 812: 'bean',\n"," 813: 'wrapped',\n"," 814: 'reading',\n"," 815: 'sea',\n"," 816: 'changed',\n"," 817: 'beverage',\n"," 818: 'stevia',\n"," 819: 'office',\n"," 820: 'gummy',\n"," 821: 'mother',\n"," 822: 'flavoring',\n"," 823: 'convenience',\n"," 824: 'breath',\n"," 825: 'shake',\n"," 826: 'results',\n"," 827: 'check',\n"," 828: 'nearly',\n"," 829: 'party',\n"," 830: 'style',\n"," 831: 'supply',\n"," 832: 'crisp',\n"," 833: 'point',\n"," 834: 'plenty',\n"," 835: 'mostly',\n"," 836: 'kitchen',\n"," 837: 'supposed',\n"," 838: 'nicely',\n"," 839: 'trouble',\n"," 840: 'complaint',\n"," 841: 'set',\n"," 842: 'bbq',\n"," 843: 'china',\n"," 844: 'picture',\n"," 845: 'afternoon',\n"," 846: 'biscuits',\n"," 847: 'benefits',\n"," 848: 'berry',\n"," 849: 'carbs',\n"," 850: 'expiration',\n"," 851: 'bigger',\n"," 852: 'sick',\n"," 853: 'near',\n"," 854: 'somewhat',\n"," 855: 'craving',\n"," 856: 'stuck',\n"," 857: 'fairly',\n"," 858: 'kept',\n"," 859: 'alot',\n"," 860: 'lime',\n"," 861: 'pizza',\n"," 862: 'except',\n"," 863: 'dishes',\n"," 864: 'send',\n"," 865: 'dressing',\n"," 866: 'addicted',\n"," 867: 'brought',\n"," 868: 'lover',\n"," 869: 'gf',\n"," 870: 'nutrition',\n"," 871: 'prepare',\n"," 872: 'perhaps',\n"," 873: 'short',\n"," 874: 'lbs',\n"," 875: 'mango',\n"," 876: 'plant',\n"," 877: 'kinds',\n"," 878: 'replacement',\n"," 879: 'types',\n"," 880: 'balance',\n"," 881: 'worst',\n"," 882: 'weird',\n"," 883: 'bake',\n"," 884: 'coming',\n"," 885: 'kid',\n"," 886: 'share',\n"," 887: 'call',\n"," 888: 'sorry',\n"," 889: 'higher',\n"," 890: 'brewed',\n"," 891: 'helped',\n"," 892: 'portion',\n"," 893: 'walmart',\n"," 894: 'pops',\n"," 895: 'quantity',\n"," 896: 'children',\n"," 897: 'crispy',\n"," 898: 'pouch',\n"," 899: 'usual',\n"," 900: 'dented',\n"," 901: 'served',\n"," 902: 'source',\n"," 903: 'jars',\n"," 904: 'running',\n"," 905: 'eggs',\n"," 906: 'gummi',\n"," 907: 'sort',\n"," 908: 'cashews',\n"," 909: 'chance',\n"," 910: 'gourmet',\n"," 911: 'jelly',\n"," 912: 'sitting',\n"," 913: 'unique',\n"," 914: 'working',\n"," 915: 'alone',\n"," 916: 'number',\n"," 917: 'disappointing',\n"," 918: 'reviewer',\n"," 919: 'whatever',\n"," 920: 'notice',\n"," 921: 'vegetables',\n"," 922: 'fill',\n"," 923: 'eater',\n"," 924: 'bitterness',\n"," 925: 'hate',\n"," 926: 'reviewers',\n"," 927: 'means',\n"," 928: 'busy',\n"," 929: 'restaurant',\n"," 930: 'gotten',\n"," 931: 'pleasantly',\n"," 932: 'tuna',\n"," 933: 'grams',\n"," 934: 'sample',\n"," 935: 'sauces',\n"," 936: 'personally',\n"," 937: 'shelf',\n"," 938: 'potatoes',\n"," 939: 'outside',\n"," 940: 'cause',\n"," 941: 'selling',\n"," 942: 'website',\n"," 943: 'enjoys',\n"," 944: 'ended',\n"," 945: 'knew',\n"," 946: 'whenever',\n"," 947: 'standard',\n"," 948: 'slight',\n"," 949: 'air',\n"," 950: 'covered',\n"," 951: 'heard',\n"," 952: 'mustard',\n"," 953: 'listed',\n"," 954: 'directions',\n"," 955: 'blends',\n"," 956: 'soups',\n"," 957: 'beautiful',\n"," 958: 'carbonated',\n"," 959: 'birthday',\n"," 960: 'blood',\n"," 961: 'tart',\n"," 962: 'brewing',\n"," 963: 'threw',\n"," 964: 'grains',\n"," 965: 'dessert',\n"," 966: 'lasts',\n"," 967: 'tomato',\n"," 968: 'clear',\n"," 969: 'bodied',\n"," 970: 'fair',\n"," 971: 'pour',\n"," 972: 'pounds',\n"," 973: 'tired',\n"," 974: 'double',\n"," 975: 'school',\n"," 976: 'paying',\n"," 977: 'issue',\n"," 978: 'careful',\n"," 979: 'traditional',\n"," 980: 'sensitive',\n"," 981: 'offer',\n"," 982: 'straight',\n"," 983: 'wants',\n"," 984: 'sized',\n"," 985: 'subtle',\n"," 986: 'offered',\n"," 987: 'brownies',\n"," 988: 'paste',\n"," 989: 'cheddar',\n"," 990: 'site',\n"," 991: 'upset',\n"," 992: 'switched',\n"," 993: 'instructions',\n"," 994: 'lab',\n"," 995: 'appreciate',\n"," 996: 'grade',\n"," 997: 'sweetened',\n"," 998: 'child',\n"," 999: 'suggest',\n"," 1000: 'nasty',\n"," ...}"]},"metadata":{},"execution_count":28}]},{"cell_type":"markdown","source":["6-1. 인코더"],"metadata":{"id":"w2q38OyIllPu"}},{"cell_type":"code","metadata":{"id":"EdGYDkqJnYts"},"source":["# 인코더\n","encoder_model = Model(inputs=encoder_inputs, outputs=[encoder_outputs, state_h, state_c])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["6-2. 디코더"],"metadata":{"id":"s75qmTKllq9Z"}},{"cell_type":"code","metadata":{"id":"FC-3uDPdnZhk"},"source":["# 이전 시점의 상태들을 저장하는 텐서\n","decoder_state_input_h = Input(shape=(hidden_size,))\n","decoder_state_input_c = Input(shape=(hidden_size,))\n","\n","dec_emb2 = dec_emb_layer(decoder_inputs)\n","\n","# 문장의 다음 단어를 예측하기 위해서 초기 상태(initial_state)를 이전 시점의 상태로 사용. 이는 뒤의 함수 decode_sequence()에 구현\n","# 학습 과정에서와 달리 LSTM의 리턴하는 hidden state(state_h)와 cell state(state_c)를 버리지 않음\n","decoder_outputs2, state_h2, state_c2 = decoder_lstm(dec_emb2, initial_state=[decoder_state_input_h, decoder_state_input_c])\n","\n","# attention 함수\n","decoder_hidden_state_input = Input(shape=(text_max_len, hidden_size))\n","attn_out_inf, attn_states_inf = attn_layer([decoder_hidden_state_input, decoder_outputs2])\n","decoder_inf_concat = Concatenate(axis=-1, name='concat')([decoder_outputs2, attn_out_inf])\n","\n","# 디코더의 출력층\n","decoder_outputs2 = decoder_softmax_layer(decoder_inf_concat)\n","\n","# 최종 디코더 모델\n","decoder_model = Model(\n","    [decoder_inputs] + [decoder_hidden_state_input, decoder_state_input_h, decoder_state_input_c],\n","    [decoder_outputs2] + [state_h2, state_c2])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uRENVLlDnaZN"},"source":["def decode_sequence(input_seq):\n","    # 입력으로부터 인코더의 상태를 얻음\n","    e_out, e_h, e_c = encoder_model.predict(input_seq)\n","\n","     # <SOS>에 해당하는 토큰 생성\n","    target_seq = np.zeros((1,1))\n","    target_seq[0, 0] = tar_word_to_index['sostoken']\n","\n","    stop_condition = False\n","    decoded_sentence = ''\n","    while not stop_condition: # stop_condition이 True가 될 때까지 루프 반복\n","\n","        output_tokens, h, c = decoder_model.predict([target_seq] + [e_out, e_h, e_c])\n","        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","        sampled_token = tar_index_to_word[sampled_token_index]\n","\n","        if(sampled_token!='eostoken'):\n","            decoded_sentence += ' '+sampled_token\n","\n","        #  <eos>에 도달하거나 최대 길이를 넘으면 중단\n","        if (sampled_token == 'eostoken'  or len(decoded_sentence.split()) >= (summary_max_len-1)):\n","            stop_condition = True\n","\n","        # 길이가 1인 target 시퀀스 업데이트\n","        target_seq = np.zeros((1,1))\n","        target_seq[0, 0] = sampled_token_index\n","\n","        # 상태 업데이트\n","        e_h, e_c = h, c\n","\n","    return decoded_sentence"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QhOF2BzyncVM"},"source":["# Text의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq2text(input_seq):\n","    temp=''\n","    for i in input_seq:\n","        if(i!=0):\n","            temp = temp + src_index_to_word[i]+' '\n","    return temp\n","\n","# Summary의 정수 시퀀스를 텍스트 시퀀스로 변환\n","def seq2summary(input_seq):\n","    temp=''\n","    for i in input_seq:\n","        if((i!=0 and i!=tar_word_to_index['sostoken']) and i!=tar_word_to_index['eostoken']):\n","            temp = temp + tar_index_to_word[i] + ' '\n","    return temp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wVf6fDQSnda9","executionInfo":{"status":"ok","timestamp":1700045537336,"user_tz":-540,"elapsed":3684,"user":{"displayName":"최대영","userId":"01139173733614706768"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8582c340-df53-46af-b38f-62723517a0c0"},"source":["for i in range(5, 10):\n","    print(\"Text: \",seq2text(encoder_input_test[i]))\n","    print(\"True Summary :\",seq2summary(decoder_input_test[i]))\n","    print(\"Predicted Summary :\",decode_sequence(encoder_input_test[i].reshape(1, text_max_len)))\n","    print(\"\\n\")"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Text:  started buying nature valley brand type bars must admit flavor wise superior slightly eat organic sticking bb brand believe like peanut butter bars honestly better peanut butter pie \n","True Summary : these are excellent \n","1/1 [==============================] - 1s 1s/step\n","1/1 [==============================] - 1s 580ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 24ms/step\n","Predicted Summary :  great product\n","\n","\n","Text:  love decaf tea love convenience ordering case \n","True Summary : rooibos tea \n","1/1 [==============================] - 0s 38ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 65ms/step\n","1/1 [==============================] - 0s 55ms/step\n","Predicted Summary :  great tea\n","\n","\n","Text:  bulbs buying big box store never seemed last anything close years color always seemed bit true color fair price fair shipping cost ones get \n","True Summary : better then the big box store \n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 42ms/step\n","1/1 [==============================] - 0s 44ms/step\n","Predicted Summary :  great product\n","\n","\n","Text:  took kettle chips rice chips good great pretzel chips super crunchy hard teeth like fancy brands cant name make pretzels like something dog would love chomp snack factory pretzel crisps crunchy well toasted thin sprinkled sesame poppy salt think pinch spices mild used dipping darn delicious \n","True Summary : yum \n","1/1 [==============================] - 0s 40ms/step\n","1/1 [==============================] - 0s 50ms/step\n","1/1 [==============================] - 0s 41ms/step\n","1/1 [==============================] - 0s 29ms/step\n","Predicted Summary :  great product\n","\n","\n","Text:  german shepherd breeder recommended food itchy gsd way hates food smells like cat food actually case half left guess donate shelter shame expensive eat dry kibble trout formula either \n","True Summary : we to \n","1/1 [==============================] - 0s 22ms/step\n","1/1 [==============================] - 0s 21ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 23ms/step\n","1/1 [==============================] - 0s 25ms/step\n","1/1 [==============================] - 0s 25ms/step\n","Predicted Summary :  my dog loves these\n","\n","\n"]}]}]}