{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "HA9F-ehts7th",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.587715Z",
     "start_time": "2023-12-21T02:32:12.487632Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Br8r6gNSC8fg",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.588996Z",
     "start_time": "2023-12-21T02:32:12.493200Z"
    }
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": 29,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roKevKwlsiqr"
   },
   "source": [
    "# ZOO classification\n",
    "\n",
    "### Data list\n",
    "\n",
    "1. 동물 이름  animal name:     (deleted)\n",
    "2. 털  hair     Boolean\n",
    "3. 깃털  feathers     Boolean\n",
    "4. 알  eggs     Boolean\n",
    "5. 우유 milk     Boolean\n",
    "6. 날 수있는지  airborne     Boolean\n",
    "7. 수중 생물  aquatic      Boolean\n",
    "8. 포식자  predator     Boolean\n",
    "9. 이빨이 있는지 toothed      Boolean\n",
    "10. 척추 동물  backbone     Boolean\n",
    "11. 호흡 방법  breathes     Boolean\n",
    "12. 독  venomous     Boolean\n",
    "13. 물갈퀴  fins     Boolean\n",
    "14. 다리  legs     Numeric (set of values: {0\",2,4,5,6,8})\n",
    "15. 꼬리  tail     Boolean\n",
    "16. 사육 가능한 지 domestic     Boolean\n",
    "17. 고양이 크기인지 catsize      Boolean\n",
    "18. 동물 타입 type     Numeric (integer values in range [0\",6])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-i11AGBVtU1s",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.605254Z",
     "start_time": "2023-12-21T02:32:12.501539Z"
    }
   },
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv',\n",
    "                delimiter=',',\n",
    "                dtype=np.int32)\n",
    "x_train = xy[0:-10, 0:-1]\n",
    "y_train = xy[0:-10, [-1]]\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "\n",
    "x_test = xy[-10:, 0:-1]\n",
    "y_test = xy[-10:, [-1]]\n",
    "\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "nb_classes = 7  # 0 ~ 6\n",
    "\n",
    "# [0, 1, 2] 총 class가 3개일때,\n",
    "# label : 0, 0, 1, 2, 0, 1, 2 ....\n",
    "# 1 => [0, 1, 0]\n",
    "# 0 => [1, 0, 0]\n",
    "# 2 => [0, 0, 1]\n",
    "\n",
    "print(y_train[15])\n",
    "y_train = tf.one_hot(list(y_train), nb_classes) # one hot 으로 변환\n",
    "y_train = tf.reshape(y_train, [-1, nb_classes]) # reshape\n",
    "print(y_train[15])\n",
    "\n",
    "y_test = tf.one_hot(list(y_test), nb_classes) # one hot 으로 변환\n",
    "print(f\"before reshape:{y_test.shape}\")\n",
    "y_test = tf.reshape(y_test, [-1, nb_classes]) \n",
    "# -1은 뒤의 지정한 데이타의 특징을 유지하면서 나머지 차원은 알아서 조정\n",
    "print(f\"after reshape:{y_test.shape}\")\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(x_train.dtype, y_train.dtype)\n",
    "print(x_test.dtype, y_test.dtype)\n"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6]\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1.], shape=(7,), dtype=float32)\n",
      "before reshape:(10, 1, 7)\n",
      "after reshape:(10, 7)\n",
      "(91, 16) (91, 7)\n",
      "(10, 16) (10, 7)\n",
      "<dtype: 'float32'> <dtype: 'float32'>\n",
      "<dtype: 'float32'> <dtype: 'float32'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vA5v-Z1butQj",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.605447Z",
     "start_time": "2023-12-21T02:32:12.536298Z"
    }
   },
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "W = tf.Variable(tf.random.normal([16,nb_classes],0,1), name='weight')\n",
    "b = tf.Variable(tf.random.normal([nb_classes],0,1), name='bias')\n",
    "\n",
    "print(W.shape, b.shape)"
   ],
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7) (7,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4r7rIGXsiqy"
   },
   "source": [
    "# 가설 설정\n",
    "\n",
    "* 주어진 동물의 데이터들로 분류하는 가설 모델을 생성한다\n",
    "\n",
    "## $$ y_k = \\frac{exp(H(x_k))}{\\sum_{i=1}^{n}exp(H(x_i))}  $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "koTAYczVts_I",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.606895Z",
     "start_time": "2023-12-21T02:32:12.547093Z"
    }
   },
   "source": [
    "def logistic_regression(features): # hypothesis_softmax\n",
    "    return tf.nn.softmax(tf.matmul(features, W) + b)\n",
    "\n",
    "print(logistic_regression(x_train))"
   ],
   "execution_count": 32,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[4.10938100e-07 1.39875337e-03 1.85227429e-04 2.16101602e-04\n",
      "  1.86940633e-06 9.98000562e-01 1.97088782e-04]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [7.83748031e-02 8.18328142e-01 1.52283655e-02 2.52695531e-02\n",
      "  8.26386642e-03 1.44316591e-02 4.01035249e-02]\n",
      " [4.10938100e-07 1.39875337e-03 1.85227429e-04 2.16101602e-04\n",
      "  1.86940633e-06 9.98000562e-01 1.97088782e-04]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [4.32815284e-07 1.26512023e-03 3.18771927e-04 1.08118380e-04\n",
      "  3.33464850e-05 9.97328877e-01 9.45373205e-04]\n",
      " [2.66861413e-02 4.99959111e-01 1.92274172e-02 4.61701304e-02\n",
      "  7.17142597e-02 9.82112810e-03 3.26421678e-01]\n",
      " [7.83748031e-02 8.18328142e-01 1.52283655e-02 2.52695531e-02\n",
      "  8.26386642e-03 1.44316591e-02 4.01035249e-02]\n",
      " [2.17401109e-07 7.81040639e-03 1.82700180e-03 5.70603600e-03\n",
      "  3.05827525e-05 9.82857108e-01 1.76855468e-03]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [9.56407574e-04 2.89190076e-02 1.03249522e-02 1.99639350e-02\n",
      "  2.87243903e-01 6.32298231e-01 2.02935301e-02]\n",
      " [7.83748031e-02 8.18328142e-01 1.52283655e-02 2.52695531e-02\n",
      "  8.26386642e-03 1.44316591e-02 4.01035249e-02]\n",
      " [1.88301709e-02 2.46662110e-01 2.85831958e-01 2.66991377e-01\n",
      "  8.88401344e-02 2.04997789e-02 7.23444670e-02]\n",
      " [4.57938677e-06 2.34869891e-03 2.62855971e-03 3.11473608e-02\n",
      "  1.11426496e-04 9.62914765e-01 8.44672846e-04]\n",
      " [5.85932325e-09 4.04501043e-05 3.59308106e-05 1.35923608e-03\n",
      "  4.45348917e-07 9.98550594e-01 1.32373189e-05]\n",
      " [2.71659601e-03 4.57791612e-02 7.90882297e-03 1.05675412e-02\n",
      "  3.20125483e-02 8.98603916e-01 2.41130707e-03]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [2.59466290e-01 4.60555911e-01 1.00269187e-02 8.99424963e-03\n",
      "  2.25482658e-02 5.12958094e-02 1.87112570e-01]\n",
      " [3.39870304e-01 3.55434865e-01 1.73143707e-02 2.07996322e-03\n",
      "  2.44494900e-03 2.61294574e-01 2.15609502e-02]\n",
      " [9.56407574e-04 2.89190076e-02 1.03249522e-02 1.99639350e-02\n",
      "  2.87243903e-01 6.32298231e-01 2.02935301e-02]\n",
      " [1.48060443e-02 1.19602531e-02 1.09847430e-02 3.23797166e-02\n",
      "  1.34292215e-01 7.83870101e-01 1.17070004e-02]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [4.68184054e-03 2.97509902e-03 2.08517420e-03 2.66938074e-03\n",
      "  6.62173778e-02 9.05068636e-01 1.63024329e-02]\n",
      " [1.22680788e-09 2.54569386e-06 1.39792492e-05 1.74119064e-04\n",
      "  8.96177426e-08 9.99798000e-01 1.12596481e-05]\n",
      " [5.11868393e-06 1.40452327e-03 5.80578810e-04 1.17129472e-03\n",
      "  1.04763276e-05 9.96002853e-01 8.25167750e-04]\n",
      " [1.44484784e-06 4.06962703e-04 3.63940519e-04 7.59798641e-05\n",
      "  3.72040836e-06 9.98810053e-01 3.37926525e-04]\n",
      " [1.36575967e-04 1.08101584e-01 1.53736072e-02 8.13129172e-03\n",
      "  1.75368460e-03 8.59407246e-01 7.09600793e-03]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [7.31269611e-05 1.49587691e-01 1.48739396e-02 4.43810737e-03\n",
      "  1.86384830e-03 8.04571629e-01 2.45915763e-02]\n",
      " [1.40625289e-10 1.46261630e-06 2.50866788e-06 6.86579660e-05\n",
      "  7.71411166e-08 9.99922752e-01 4.55127429e-06]\n",
      " [4.32815284e-07 1.26512023e-03 3.18771927e-04 1.08118380e-04\n",
      "  3.33464850e-05 9.97328877e-01 9.45373205e-04]\n",
      " [5.39737637e-04 3.02751828e-02 1.75158586e-02 1.13452114e-02\n",
      "  1.14465109e-03 8.80350590e-01 5.88287078e-02]\n",
      " [9.01021343e-03 3.28128971e-02 8.69073812e-03 1.44539708e-02\n",
      "  5.61192520e-02 8.76353502e-01 2.55946582e-03]\n",
      " [1.79112330e-01 4.14828181e-01 2.67689638e-02 7.87278786e-02\n",
      "  2.75021940e-02 1.79525446e-02 2.55107969e-01]\n",
      " [4.60598642e-07 7.91956857e-03 1.70565257e-03 1.07017974e-03\n",
      "  4.30570872e-05 9.88547206e-01 7.13850604e-04]\n",
      " [1.70012686e-06 3.61371576e-03 1.30593032e-03 1.00355921e-03\n",
      "  9.08082984e-06 9.93759274e-01 3.06811271e-04]\n",
      " [2.71659601e-03 4.57791612e-02 7.90882297e-03 1.05675412e-02\n",
      "  3.20125483e-02 8.98603916e-01 2.41130707e-03]\n",
      " [7.83748031e-02 8.18328142e-01 1.52283655e-02 2.52695531e-02\n",
      "  8.26386642e-03 1.44316591e-02 4.01035249e-02]\n",
      " [4.74809471e-12 3.21404605e-06 3.64478478e-06 1.93770247e-05\n",
      "  3.44475779e-07 9.99966502e-01 6.86800558e-06]\n",
      " [6.19211002e-11 5.04782111e-06 4.43973204e-06 2.79360946e-04\n",
      "  2.04024417e-07 9.99703825e-01 7.18851561e-06]\n",
      " [2.12380290e-02 7.14034736e-02 3.94937731e-02 2.40162648e-02\n",
      "  3.33275869e-02 8.05174947e-01 5.34589030e-03]\n",
      " [7.65495653e-11 3.58936859e-06 1.77538755e-06 2.74149879e-05\n",
      "  2.88356929e-08 9.99966264e-01 8.90061870e-07]\n",
      " [4.71773650e-03 1.76347028e-02 1.05645172e-02 2.50186864e-02\n",
      "  8.09587613e-02 8.49449456e-01 1.16561102e-02]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [5.85932325e-09 4.04501043e-05 3.59308106e-05 1.35923608e-03\n",
      "  4.45348917e-07 9.98550594e-01 1.32373189e-05]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [2.94576785e-06 1.03704224e-03 1.93843865e-04 5.65514601e-05\n",
      "  4.70667692e-06 9.98618841e-01 8.61387016e-05]\n",
      " [9.21724961e-07 8.83247051e-03 9.20472026e-04 3.99099168e-04\n",
      "  3.38072869e-06 9.89783943e-01 5.97583239e-05]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [6.19211002e-11 5.04782111e-06 4.43973204e-06 2.79360946e-04\n",
      "  2.04024417e-07 9.99703825e-01 7.18851561e-06]\n",
      " [1.07981632e-05 1.41803536e-03 5.39688393e-04 2.18735193e-04\n",
      "  1.46861303e-05 9.97466326e-01 3.31635878e-04]\n",
      " [6.74327347e-12 1.06523743e-07 8.78638673e-08 5.73608440e-06\n",
      "  1.31953759e-09 9.99993801e-01 2.62973316e-07]\n",
      " [9.21724961e-07 8.83247051e-03 9.20472026e-04 3.99099168e-04\n",
      "  3.38072869e-06 9.89783943e-01 5.97583239e-05]\n",
      " [1.59132935e-06 5.75020676e-04 2.43113172e-04 1.00991529e-04\n",
      "  7.00534247e-06 9.98667598e-01 4.04730410e-04]\n",
      " [3.75880264e-02 4.76537226e-03 1.06930872e-02 6.22996688e-03\n",
      "  7.07945228e-02 8.32812726e-01 3.71162258e-02]\n",
      " [9.56407574e-04 2.89190076e-02 1.03249522e-02 1.99639350e-02\n",
      "  2.87243903e-01 6.32298231e-01 2.02935301e-02]\n",
      " [7.11148530e-02 8.78380332e-03 8.71403795e-03 3.56547814e-03\n",
      "  4.86135110e-02 8.51134658e-01 8.07362981e-03]\n",
      " [4.71773650e-03 1.76347028e-02 1.05645172e-02 2.50186864e-02\n",
      "  8.09587613e-02 8.49449456e-01 1.16561102e-02]\n",
      " [2.59466290e-01 4.60555911e-01 1.00269187e-02 8.99424963e-03\n",
      "  2.25482658e-02 5.12958094e-02 1.87112570e-01]\n",
      " [7.83748031e-02 8.18328142e-01 1.52283655e-02 2.52695531e-02\n",
      "  8.26386642e-03 1.44316591e-02 4.01035249e-02]\n",
      " [9.66475531e-02 3.32750231e-01 2.83684582e-01 9.37901495e-04\n",
      "  3.20656784e-02 1.64214760e-01 8.96992385e-02]\n",
      " [1.55203306e-05 7.98941066e-04 2.46094470e-03 5.65915718e-04\n",
      "  7.32944391e-05 9.94603336e-01 1.48211198e-03]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [4.32815284e-07 1.26512023e-03 3.18771927e-04 1.08118380e-04\n",
      "  3.33464850e-05 9.97328877e-01 9.45373205e-04]\n",
      " [3.39870304e-01 3.55434865e-01 1.73143707e-02 2.07996322e-03\n",
      "  2.44494900e-03 2.61294574e-01 2.15609502e-02]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [2.35381776e-07 3.10177589e-03 2.25382944e-04 4.31308035e-05\n",
      "  1.24533162e-05 9.96432304e-01 1.84705990e-04]\n",
      " [8.65881873e-07 1.41055486e-03 1.71979947e-04 4.03089325e-05\n",
      "  2.61753598e-06 9.98294532e-01 7.91173661e-05]\n",
      " [4.32815284e-07 1.26512023e-03 3.18771927e-04 1.08118380e-04\n",
      "  3.33464850e-05 9.97328877e-01 9.45373205e-04]\n",
      " [2.25148741e-02 1.28684184e-02 8.32710043e-03 2.73730839e-03\n",
      "  2.91195419e-02 9.16445613e-01 7.98714254e-03]\n",
      " [1.27527898e-13 2.12805134e-08 6.79892409e-09 4.40382930e-09\n",
      "  1.46054401e-11 1.00000000e+00 4.77488660e-10]\n",
      " [1.79112330e-01 4.14828181e-01 2.67689638e-02 7.87278786e-02\n",
      "  2.75021940e-02 1.79525446e-02 2.55107969e-01]\n",
      " [4.13790010e-02 7.08692193e-01 1.92274116e-02 2.64338609e-02\n",
      "  2.69060372e-03 1.52152985e-01 4.94239256e-02]\n",
      " [6.52252813e-04 7.19635934e-02 1.42677838e-03 1.25803100e-03\n",
      "  8.80369189e-05 9.22793388e-01 1.81791012e-03]\n",
      " [1.03348225e-01 7.08308518e-01 4.32255864e-02 1.06832408e-03\n",
      "  4.54206094e-02 7.65851960e-02 2.20436826e-02]\n",
      " [4.44908366e-02 1.29284829e-01 4.96898293e-01 5.97840436e-02\n",
      "  1.39580697e-01 5.05970269e-02 7.93642476e-02]\n",
      " [9.01021343e-03 3.28128971e-02 8.69073812e-03 1.44539708e-02\n",
      "  5.61192520e-02 8.76353502e-01 2.55946582e-03]\n",
      " [9.01021343e-03 3.28128971e-02 8.69073812e-03 1.44539708e-02\n",
      "  5.61192520e-02 8.76353502e-01 2.55946582e-03]\n",
      " [1.40852138e-01 4.72420603e-01 1.86166957e-01 5.94786694e-03\n",
      "  3.71445268e-02 6.73637167e-02 9.01041552e-02]\n",
      " [4.22018170e-02 3.59089822e-02 3.94375712e-01 1.50973052e-01\n",
      "  1.01142175e-01 6.46011531e-02 2.10797057e-01]\n",
      " [1.79112330e-01 4.14828181e-01 2.67689638e-02 7.87278786e-02\n",
      "  2.75021940e-02 1.79525446e-02 2.55107969e-01]\n",
      " [4.71773650e-03 1.76347028e-02 1.05645172e-02 2.50186864e-02\n",
      "  8.09587613e-02 8.49449456e-01 1.16561102e-02]\n",
      " [1.01443741e-03 1.60193712e-01 7.29380697e-02 1.75571088e-02\n",
      "  1.73459097e-03 7.31615365e-01 1.49466321e-02]\n",
      " [1.65827046e-07 3.12034186e-04 3.11115145e-04 6.58698287e-03\n",
      "  7.13136433e-06 9.92675602e-01 1.07046544e-04]\n",
      " [2.09476680e-01 3.81679922e-01 1.79774426e-02 1.66873867e-03\n",
      "  2.29026712e-02 1.47127986e-01 2.19166547e-01]\n",
      " [1.49362134e-02 2.05112528e-03 2.20394670e-03 3.51186213e-03\n",
      "  1.11654833e-01 8.48997891e-01 1.66442022e-02]\n",
      " [1.22680788e-09 2.54569386e-06 1.39792492e-05 1.74119064e-04\n",
      "  8.96177426e-08 9.99798000e-01 1.12596481e-05]\n",
      " [9.36075139e-06 5.69735072e-04 8.16662970e-04 2.92011932e-03\n",
      "  2.78994958e-05 9.91455853e-01 4.20036633e-03]\n",
      " [7.49414994e-06 6.77341304e-05 1.43455807e-04 4.89905287e-05\n",
      "  5.98057268e-05 9.96582210e-01 3.09044868e-03]], shape=(91, 7), dtype=float32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Biydb3siq2"
   },
   "source": [
    "## Loss Function\n",
    "\n",
    "##$$\n",
    "\\begin{align}\n",
    "cost(H(x),y) & = −\\sum_{n=1}^{n} Y log(H(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sh42tbvItxYP",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:32:12.607005Z",
     "start_time": "2023-12-21T02:32:12.559547Z"
    }
   },
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    #loss = -tf.reduce_mean(tf.reduce_sum(labels * tf.math.log(hypothesis) +(1 - labels) * tf.math.log(1 - hypothesis), axis=1))\n",
    "    loss = tf.keras.losses.categorical_crossentropy(labels, hypothesis)\n",
    "    return loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ],
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZOSOjizZtx03",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:33:14.022090Z",
     "start_time": "2023-12-21T02:32:12.562866Z"
    }
   },
   "source": [
    "epochs = 10001\n",
    "\n",
    "for step in range(epochs):\n",
    "  for features, labels in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = logistic_regression(features)\n",
    "        loss_value = loss_fn(pred,labels)\n",
    "    grads = tape.gradient(loss_value, [W,b])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "    if step % 200 == 0:\n",
    "        print(\"Iter: {}, Loss: {:.4f}\".format(step, tf.reduce_mean(loss_fn(logistic_regression(features),labels))))\n"
   ],
   "execution_count": 34,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loc(\"mps_select\"(\"(mpsFileLoc): /AppleInternal/Library/BuildRoots/0032d1ee-80fd-11ee-8227-6aecfccc70fe/Library/Caches/com.apple.xbs/Sources/MetalPerformanceShadersGraph/mpsgraph/MetalPerformanceShadersGraph/Core/Files/MPSGraphUtilities.mm\":294:0)): error: 'anec.gain_offset_control' op result #0 must be 4D/5D memref of 16-bit float or 8-bit signed integer or 8-bit unsigned integer values, but got 'memref<1x91x1x7xi1>'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 2.7610\n",
      "Iter: 100, Loss: 0.1172\n",
      "Iter: 200, Loss: 0.0608\n",
      "Iter: 300, Loss: 0.0408\n",
      "Iter: 400, Loss: 0.0307\n",
      "Iter: 500, Loss: 0.0246\n",
      "Iter: 600, Loss: 0.0205\n",
      "Iter: 700, Loss: 0.0176\n",
      "Iter: 800, Loss: 0.0154\n",
      "Iter: 900, Loss: 0.0137\n",
      "Iter: 1000, Loss: 0.0124\n",
      "Iter: 1100, Loss: 0.0113\n",
      "Iter: 1200, Loss: 0.0103\n",
      "Iter: 1300, Loss: 0.0095\n",
      "Iter: 1400, Loss: 0.0089\n",
      "Iter: 1500, Loss: 0.0083\n",
      "Iter: 1600, Loss: 0.0078\n",
      "Iter: 1700, Loss: 0.0073\n",
      "Iter: 1800, Loss: 0.0069\n",
      "Iter: 1900, Loss: 0.0065\n",
      "Iter: 2000, Loss: 0.0062\n",
      "Iter: 2100, Loss: 0.0059\n",
      "Iter: 2200, Loss: 0.0057\n",
      "Iter: 2300, Loss: 0.0054\n",
      "Iter: 2400, Loss: 0.0052\n",
      "Iter: 2500, Loss: 0.0050\n",
      "Iter: 2600, Loss: 0.0048\n",
      "Iter: 2700, Loss: 0.0046\n",
      "Iter: 2800, Loss: 0.0044\n",
      "Iter: 2900, Loss: 0.0043\n",
      "Iter: 3000, Loss: 0.0042\n",
      "Iter: 3100, Loss: 0.0040\n",
      "Iter: 3200, Loss: 0.0039\n",
      "Iter: 3300, Loss: 0.0038\n",
      "Iter: 3400, Loss: 0.0037\n",
      "Iter: 3500, Loss: 0.0036\n",
      "Iter: 3600, Loss: 0.0035\n",
      "Iter: 3700, Loss: 0.0034\n",
      "Iter: 3800, Loss: 0.0033\n",
      "Iter: 3900, Loss: 0.0032\n",
      "Iter: 4000, Loss: 0.0031\n",
      "Iter: 4100, Loss: 0.0030\n",
      "Iter: 4200, Loss: 0.0030\n",
      "Iter: 4300, Loss: 0.0029\n",
      "Iter: 4400, Loss: 0.0028\n",
      "Iter: 4500, Loss: 0.0028\n",
      "Iter: 4600, Loss: 0.0027\n",
      "Iter: 4700, Loss: 0.0027\n",
      "Iter: 4800, Loss: 0.0026\n",
      "Iter: 4900, Loss: 0.0026\n",
      "Iter: 5000, Loss: 0.0025\n",
      "Iter: 5100, Loss: 0.0025\n",
      "Iter: 5200, Loss: 0.0024\n",
      "Iter: 5300, Loss: 0.0024\n",
      "Iter: 5400, Loss: 0.0023\n",
      "Iter: 5500, Loss: 0.0023\n",
      "Iter: 5600, Loss: 0.0022\n",
      "Iter: 5700, Loss: 0.0022\n",
      "Iter: 5800, Loss: 0.0022\n",
      "Iter: 5900, Loss: 0.0021\n",
      "Iter: 6000, Loss: 0.0021\n",
      "Iter: 6100, Loss: 0.0021\n",
      "Iter: 6200, Loss: 0.0020\n",
      "Iter: 6300, Loss: 0.0020\n",
      "Iter: 6400, Loss: 0.0020\n",
      "Iter: 6500, Loss: 0.0019\n",
      "Iter: 6600, Loss: 0.0019\n",
      "Iter: 6700, Loss: 0.0019\n",
      "Iter: 6800, Loss: 0.0018\n",
      "Iter: 6900, Loss: 0.0018\n",
      "Iter: 7000, Loss: 0.0018\n",
      "Iter: 7100, Loss: 0.0018\n",
      "Iter: 7200, Loss: 0.0017\n",
      "Iter: 7300, Loss: 0.0017\n",
      "Iter: 7400, Loss: 0.0017\n",
      "Iter: 7500, Loss: 0.0017\n",
      "Iter: 7600, Loss: 0.0017\n",
      "Iter: 7700, Loss: 0.0016\n",
      "Iter: 7800, Loss: 0.0016\n",
      "Iter: 7900, Loss: 0.0016\n",
      "Iter: 8000, Loss: 0.0016\n",
      "Iter: 8100, Loss: 0.0015\n",
      "Iter: 8200, Loss: 0.0015\n",
      "Iter: 8300, Loss: 0.0015\n",
      "Iter: 8400, Loss: 0.0015\n",
      "Iter: 8500, Loss: 0.0015\n",
      "Iter: 8600, Loss: 0.0015\n",
      "Iter: 8700, Loss: 0.0014\n",
      "Iter: 8800, Loss: 0.0014\n",
      "Iter: 8900, Loss: 0.0014\n",
      "Iter: 9000, Loss: 0.0014\n",
      "Iter: 9100, Loss: 0.0014\n",
      "Iter: 9200, Loss: 0.0014\n",
      "Iter: 9300, Loss: 0.0014\n",
      "Iter: 9400, Loss: 0.0013\n",
      "Iter: 9500, Loss: 0.0013\n",
      "Iter: 9600, Loss: 0.0013\n",
      "Iter: 9700, Loss: 0.0013\n",
      "Iter: 9800, Loss: 0.0013\n",
      "Iter: 9900, Loss: 0.0013\n",
      "Iter: 10000, Loss: 0.0013\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5vben5FYty5m",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:33:14.028301Z",
     "start_time": "2023-12-21T02:33:14.024432Z"
    }
   },
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    hypothesis = tf.argmax(hypothesis, 1)\n",
    "    predicted = tf.cast(hypothesis, dtype=tf.float32)\n",
    "    print(predicted)\n",
    "\n",
    "    labels = tf.argmax(labels, 1)\n",
    "    labels = tf.cast(labels, dtype=tf.float32)\n",
    "    print(labels)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "\n",
    "    return accuracy"
   ],
   "execution_count": 35,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GSS_yRMRt6Pp",
    "ExecuteTime": {
     "end_time": "2023-12-21T02:33:14.039239Z",
     "start_time": "2023-12-21T02:33:14.029655Z"
    }
   },
   "source": [
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ],
   "execution_count": 36,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 0. 0. 1. 0. 5. 0. 6. 1.], shape=(10,), dtype=float32)\n",
      "tf.Tensor([2. 3. 0. 0. 1. 0. 5. 0. 6. 1.], shape=(10,), dtype=float32)\n",
      "Testset Accuracy: 1.0000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T02:33:14.040752Z",
     "start_time": "2023-12-21T02:33:14.038925Z"
    }
   }
  }
 ]
}
