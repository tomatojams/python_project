{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "HA9F-ehts7th",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:07:09.930562Z",
     "start_time": "2023-12-20T06:07:05.623252Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Br8r6gNSC8fg"
   },
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "roKevKwlsiqr"
   },
   "source": [
    "# ZOO classification\n",
    "\n",
    "### Data list\n",
    "\n",
    "1. 동물 이름  animal name:     (deleted)\n",
    "2. 털  hair     Boolean\n",
    "3. 깃털  feathers     Boolean\n",
    "4. 알  eggs     Boolean\n",
    "5. 우유 milk     Boolean\n",
    "6. 날 수있는지  airborne     Boolean\n",
    "7. 수중 생물  aquatic      Boolean\n",
    "8. 포식자  predator     Boolean\n",
    "9. 이빨이 있는지 toothed      Boolean\n",
    "10. 척추 동물  backbone     Boolean\n",
    "11. 호흡 방법  breathes     Boolean\n",
    "12. 독  venomous     Boolean\n",
    "13. 물갈퀴  fins     Boolean\n",
    "14. 다리  legs     Numeric (set of values: {0\",2,4,5,6,8})\n",
    "15. 꼬리  tail     Boolean\n",
    "16. 사육 가능한 지 domestic     Boolean\n",
    "17. 고양이 크기인지 catsize      Boolean\n",
    "18. 동물 타입 type     Numeric (integer values in range [0\",6])"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "-i11AGBVtU1s",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:07:15.100904Z",
     "start_time": "2023-12-20T06:07:14.117253Z"
    }
   },
   "source": [
    "xy = np.loadtxt('data-04-zoo.csv',\n",
    "                delimiter=',',\n",
    "                dtype=np.int32)\n",
    "x_train = xy[0:-10, 0:-1]\n",
    "y_train = xy[0:-10, [-1]]\n",
    "\n",
    "x_train = tf.cast(x_train, tf.float32)\n",
    "\n",
    "x_test = xy[-10:, 0:-1]\n",
    "y_test = xy[-10:, [-1]]\n",
    "\n",
    "x_test = tf.cast(x_test, tf.float32)\n",
    "\n",
    "nb_classes = 7  # 0 ~ 6\n",
    "\n",
    "# [0, 1, 2] 총 class가 3개일때,\n",
    "# label : 0, 0, 1, 2, 0, 1, 2 ....\n",
    "# 1 => [0, 1, 0]\n",
    "# 0 => [1, 0, 0]\n",
    "# 2 => [0, 0, 1]\n",
    "\n",
    "print(y_train[15])\n",
    "y_train = tf.one_hot(list(y_train), nb_classes)\n",
    "y_train = tf.reshape(y_train, [-1, nb_classes])\n",
    "print(y_train[15])\n",
    "\n",
    "y_test = tf.one_hot(list(y_test), nb_classes)\n",
    "y_test = tf.reshape(y_test, [-1, nb_classes])\n",
    "\n",
    "print(x_train.shape, y_train.shape)\n",
    "print(x_test.shape, y_test.shape)\n",
    "\n",
    "print(x_train.dtype, y_train.dtype)\n",
    "print(x_test.dtype, y_test.dtype)\n"
   ],
   "execution_count": 2,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-20 15:07:14.125808: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-20 15:07:14.126956: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n",
      "[6]\n",
      "tf.Tensor([0. 0. 0. 0. 0. 0. 1.], shape=(7,), dtype=float32)\n",
      "(91, 16) (91, 7)\n",
      "(10, 16) (10, 7)\n",
      "<dtype: 'float32'> <dtype: 'float32'>\n",
      "<dtype: 'float32'> <dtype: 'float32'>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "vA5v-Z1butQj",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:08:12.368721Z",
     "start_time": "2023-12-20T06:08:11.664006Z"
    }
   },
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "W = tf.Variable(tf.random.normal([16,7],0,1), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1],0,1), name='bias')\n",
    "\n",
    "print(W.shape, b.shape)"
   ],
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16, 7) (1,)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V4r7rIGXsiqy"
   },
   "source": [
    "# 가설 설정\n",
    "\n",
    "* 주어진 동물의 데이터들로 분류하는 가설 모델을 생성한다\n",
    "\n",
    "## $$ y_k = \\frac{exp(H(x_k))}{\\sum_{i=1}^{n}exp(H(x_i))}  $$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "koTAYczVts_I",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:08:31.565976Z",
     "start_time": "2023-12-20T06:08:30.901179Z"
    }
   },
   "source": [
    "def logistic_regression(features): # hypothesis_softmax\n",
    "    return tf.nn.softmax(tf.matmul(features, W) + b)\n",
    "\n",
    "print(logistic_regression(x_train))"
   ],
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[3.50468617e-05 1.46588475e-01 3.02867392e-07 1.59002331e-04\n",
      "  3.15243209e-09 2.92947218e-02 8.23922455e-01]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [4.10990033e-04 1.65545044e-03 2.81437319e-02 7.27509081e-01\n",
      "  3.21609550e-05 1.21626854e-01 1.20621718e-01]\n",
      " [3.50468617e-05 1.46588475e-01 3.02867392e-07 1.59002331e-04\n",
      "  3.15243209e-09 2.92947218e-02 8.23922455e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [5.88102557e-06 6.32969797e-01 5.23096901e-07 1.55069447e-05\n",
      "  3.16872861e-10 1.58700533e-02 3.51138264e-01]\n",
      " [1.23423897e-03 3.19530442e-02 2.40213513e-01 9.33423266e-02\n",
      "  9.64143474e-05 9.78529155e-02 5.35307527e-01]\n",
      " [4.10990033e-04 1.65545044e-03 2.81437319e-02 7.27509081e-01\n",
      "  3.21609550e-05 1.21626854e-01 1.20621718e-01]\n",
      " [1.30870612e-05 5.22103012e-01 2.61686296e-06 6.81391293e-06\n",
      "  4.45421061e-10 1.93324429e-03 4.75941300e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [1.96594905e-04 8.36295366e-01 1.67406574e-02 5.92548342e-04\n",
      "  1.67914038e-08 2.38328408e-02 1.22341916e-01]\n",
      " [4.10990033e-04 1.65545044e-03 2.81437319e-02 7.27509081e-01\n",
      "  3.21609550e-05 1.21626854e-01 1.20621718e-01]\n",
      " [3.07087856e-03 2.78255250e-02 1.82371940e-02 3.70288908e-01\n",
      "  2.24404316e-03 5.44099584e-02 5.23923516e-01]\n",
      " [7.47026252e-06 1.50238120e-04 2.84559360e-06 2.97785649e-04\n",
      "  3.67176356e-09 9.28839378e-04 9.98612761e-01]\n",
      " [3.35974363e-07 1.57332488e-05 1.46131951e-08 8.65233233e-06\n",
      "  2.54546015e-12 4.86299177e-05 9.99926567e-01]\n",
      " [6.10883289e-04 4.04312789e-01 1.83025096e-02 4.30960469e-02\n",
      "  5.22670156e-08 2.76430070e-01 2.57247716e-01]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [7.14131747e-04 1.93832908e-03 6.00676285e-03 4.70605701e-01\n",
      "  1.47430561e-04 3.20367277e-01 2.00220287e-01]\n",
      " [2.37777509e-04 1.93325654e-02 6.67001470e-04 2.69005746e-02\n",
      "  9.62284103e-05 9.49716568e-01 3.04920692e-03]\n",
      " [1.96594905e-04 8.36295366e-01 1.67406574e-02 5.92548342e-04\n",
      "  1.67914038e-08 2.38328408e-02 1.22341916e-01]\n",
      " [5.22170914e-04 1.67237580e-01 2.33768612e-01 2.67878547e-03\n",
      "  1.71172914e-07 3.87463421e-01 2.08329216e-01]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [9.99907264e-04 5.27129531e-01 1.11765377e-02 2.41093850e-03\n",
      "  3.05469229e-07 2.17193052e-01 2.41089672e-01]\n",
      " [1.52352115e-07 7.00937118e-04 4.85556377e-08 6.86847955e-07\n",
      "  2.80853249e-13 7.76341039e-06 9.99290466e-01]\n",
      " [9.42793577e-07 1.21598144e-03 5.47970512e-06 9.98826290e-05\n",
      "  1.01546089e-11 6.08122966e-04 9.98069584e-01]\n",
      " [4.32991737e-06 1.00193704e-02 2.30215737e-05 9.87887615e-04\n",
      "  3.65564523e-11 5.36953798e-03 9.83595848e-01]\n",
      " [8.00548660e-05 8.51809323e-01 2.47166492e-03 1.61135138e-03\n",
      "  3.75892384e-08 1.29240364e-01 1.47871478e-02]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [7.70257902e-05 7.52337515e-01 5.45508783e-06 2.51725840e-04\n",
      "  3.31534068e-07 4.67920788e-02 2.00535893e-01]\n",
      " [9.36326273e-07 3.63336131e-03 1.35946800e-06 3.60659214e-06\n",
      "  4.51183280e-13 4.26157058e-05 9.96318102e-01]\n",
      " [5.88102557e-06 6.32969797e-01 5.23096901e-07 1.55069447e-05\n",
      "  3.16872861e-10 1.58700533e-02 3.51138264e-01]\n",
      " [3.34955868e-04 7.11220860e-01 7.69966937e-05 2.15952037e-04\n",
      "  2.64538221e-06 7.61591941e-02 2.11989373e-01]\n",
      " [2.87010538e-04 7.77651519e-02 4.23046425e-02 1.60379093e-02\n",
      "  6.95174407e-08 6.72555983e-01 1.91049263e-01]\n",
      " [1.54803216e-03 7.37053435e-03 3.21968824e-01 2.51572073e-01\n",
      "  1.63947363e-04 1.45066023e-01 2.72310585e-01]\n",
      " [4.46403465e-06 7.13005722e-01 3.23254744e-06 3.16175938e-05\n",
      "  9.11691278e-11 7.94659369e-03 2.79008329e-01]\n",
      " [1.75916393e-05 5.16746938e-01 1.36131739e-05 2.67738418e-04\n",
      "  4.87089313e-10 3.70144136e-02 4.45939720e-01]\n",
      " [6.10883289e-04 4.04312789e-01 1.83025096e-02 4.30960469e-02\n",
      "  5.22670156e-08 2.76430070e-01 2.57247716e-01]\n",
      " [4.10990033e-04 1.65545044e-03 2.81437319e-02 7.27509081e-01\n",
      "  3.21609550e-05 1.21626854e-01 1.20621718e-01]\n",
      " [3.68499173e-07 3.12182475e-02 9.70640031e-07 1.14026420e-06\n",
      "  2.38851419e-13 7.80938281e-05 9.68701243e-01]\n",
      " [2.00903941e-07 1.74468174e-03 6.18203615e-07 6.20306082e-07\n",
      "  2.25228622e-13 2.61756668e-05 9.98227656e-01]\n",
      " [2.51430029e-04 1.97299287e-01 1.65355543e-03 2.07605381e-02\n",
      "  8.22984632e-08 1.27381310e-01 6.52653754e-01]\n",
      " [5.62174648e-07 1.84551871e-03 2.68738603e-07 2.35866082e-05\n",
      "  2.00156460e-13 8.08028199e-05 9.98049259e-01]\n",
      " [7.83393334e-04 6.12876892e-01 7.12878928e-02 5.07381419e-03\n",
      "  9.07144582e-08 1.12252101e-01 1.97725803e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [3.35974363e-07 1.57332488e-05 1.46131951e-08 8.65233233e-06\n",
      "  2.54546015e-12 4.86299177e-05 9.99926567e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [8.13450879e-06 5.57648800e-02 1.25242150e-06 3.97651282e-04\n",
      "  1.24292454e-09 4.24310297e-01 5.19517779e-01]\n",
      " [1.35214605e-05 3.36016953e-01 3.44503542e-06 2.24157237e-03\n",
      "  2.76630024e-10 8.98464620e-02 5.71878076e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [2.00903941e-07 1.74468174e-03 6.18203615e-07 6.20306082e-07\n",
      "  2.25228622e-13 2.61756668e-05 9.98227656e-01]\n",
      " [5.45323246e-07 2.81588756e-03 1.14781697e-05 7.85911398e-04\n",
      "  3.52444376e-12 4.23874613e-03 9.92147386e-01]\n",
      " [1.57979123e-08 1.16076410e-06 9.63723719e-12 9.78493446e-08\n",
      "  4.86736345e-15 4.03516560e-06 9.99994755e-01]\n",
      " [1.35214605e-05 3.36016953e-01 3.44503542e-06 2.24157237e-03\n",
      "  2.76630024e-10 8.98464620e-02 5.71878076e-01]\n",
      " [2.11834576e-05 4.19307590e-01 2.01354646e-06 1.20025405e-04\n",
      "  1.54743107e-09 6.75667971e-02 5.12982428e-01]\n",
      " [4.23593447e-04 2.64762223e-01 1.03931210e-03 1.19541283e-03\n",
      "  4.95064626e-07 1.03014164e-01 6.29564881e-01]\n",
      " [1.96594905e-04 8.36295366e-01 1.67406574e-02 5.92548342e-04\n",
      "  1.67914038e-08 2.38328408e-02 1.22341916e-01]\n",
      " [1.22811063e-04 2.65850760e-02 4.88077058e-04 2.99020647e-03\n",
      "  3.00226731e-07 4.88428652e-01 4.81384814e-01]\n",
      " [7.83393334e-04 6.12876892e-01 7.12878928e-02 5.07381419e-03\n",
      "  9.07144582e-08 1.12252101e-01 1.97725803e-01]\n",
      " [7.14131747e-04 1.93832908e-03 6.00676285e-03 4.70605701e-01\n",
      "  1.47430561e-04 3.20367277e-01 2.00220287e-01]\n",
      " [4.10990033e-04 1.65545044e-03 2.81437319e-02 7.27509081e-01\n",
      "  3.21609550e-05 1.21626854e-01 1.20621718e-01]\n",
      " [6.06384856e-05 2.53102690e-01 1.82029046e-02 5.69289684e-01\n",
      "  4.56724734e-07 1.29129589e-01 3.02139856e-02]\n",
      " [1.96514065e-07 3.76724056e-03 4.50917867e-07 2.33374922e-05\n",
      "  4.20138702e-10 9.71204340e-02 8.99088383e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [5.88102557e-06 6.32969797e-01 5.23096901e-07 1.55069447e-05\n",
      "  3.16872861e-10 1.58700533e-02 3.51138264e-01]\n",
      " [2.37777509e-04 1.93325654e-02 6.67001470e-04 2.69005746e-02\n",
      "  9.62284103e-05 9.49716568e-01 3.04920692e-03]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [5.01951763e-06 4.57043737e-01 1.46996740e-07 1.44164922e-04\n",
      "  1.99832720e-10 4.27759513e-02 5.00030994e-01]\n",
      " [1.48623121e-05 2.48878762e-01 4.65122525e-07 9.17248661e-04\n",
      "  8.02183708e-10 1.49704620e-01 6.00484133e-01]\n",
      " [5.88102557e-06 6.32969797e-01 5.23096901e-07 1.55069447e-05\n",
      "  3.16872861e-10 1.58700533e-02 3.51138264e-01]\n",
      " [2.62533751e-04 1.38821840e-01 2.12079409e-04 8.07009079e-03\n",
      "  2.26710185e-07 2.01625451e-01 6.51007712e-01]\n",
      " [1.12915882e-06 6.86288299e-03 2.48473420e-09 9.47981389e-05\n",
      "  1.12749496e-14 8.73480109e-04 9.92167652e-01]\n",
      " [1.54803216e-03 7.37053435e-03 3.21968824e-01 2.51572073e-01\n",
      "  1.63947363e-04 1.45066023e-01 2.72310585e-01]\n",
      " [9.61555983e-04 4.37006950e-02 1.57853228e-03 6.41012611e-03\n",
      "  1.50877773e-03 9.12337363e-01 3.35029364e-02]\n",
      " [6.61058293e-05 2.80073639e-02 4.48743631e-05 3.87291238e-03\n",
      "  9.59407203e-07 8.79877150e-01 8.81305933e-02]\n",
      " [1.24983734e-03 5.86007396e-03 8.62181373e-03 5.55873096e-01\n",
      "  5.29446370e-05 4.26685989e-01 1.65625336e-03]\n",
      " [2.10101530e-03 1.39826201e-02 5.61536178e-02 4.32148278e-01\n",
      "  3.40692676e-03 3.70622069e-01 1.21585473e-01]\n",
      " [2.87010538e-04 7.77651519e-02 4.23046425e-02 1.60379093e-02\n",
      "  6.95174407e-08 6.72555983e-01 1.91049263e-01]\n",
      " [2.87010538e-04 7.77651519e-02 4.23046425e-02 1.60379093e-02\n",
      "  6.95174407e-08 6.72555983e-01 1.91049263e-01]\n",
      " [9.57421580e-05 2.22741410e-01 3.14181186e-02 4.17381585e-01\n",
      "  9.19963838e-07 1.06046826e-01 2.22315401e-01]\n",
      " [8.17395514e-04 2.97892213e-01 1.74991712e-01 1.36667620e-02\n",
      "  4.11430374e-04 2.64033098e-02 4.85817224e-01]\n",
      " [1.54803216e-03 7.37053435e-03 3.21968824e-01 2.51572073e-01\n",
      "  1.63947363e-04 1.45066023e-01 2.72310585e-01]\n",
      " [7.83393334e-04 6.12876892e-01 7.12878928e-02 5.07381419e-03\n",
      "  9.07144582e-08 1.12252101e-01 1.97725803e-01]\n",
      " [6.41318329e-05 8.09053481e-01 4.34634945e-04 1.51083979e-03\n",
      "  1.15200457e-07 1.15916580e-01 7.30201676e-02]\n",
      " [1.58490150e-06 4.86385434e-05 2.04004877e-07 5.07808581e-05\n",
      "  9.67166347e-11 2.12619547e-04 9.99686241e-01]\n",
      " [4.24530474e-04 2.06732471e-03 3.26652802e-03 6.02480233e-01\n",
      "  6.87000211e-05 3.66151959e-01 2.55406443e-02]\n",
      " [5.61896770e-04 1.21266939e-01 3.08988336e-02 1.07313378e-03\n",
      "  4.85948874e-07 6.32042944e-01 2.14155808e-01]\n",
      " [1.52352115e-07 7.00937118e-04 4.85556377e-08 6.86847955e-07\n",
      "  2.80853249e-13 7.76341039e-06 9.99290466e-01]\n",
      " [1.57168211e-06 2.39612232e-03 2.77452236e-05 1.52866669e-05\n",
      "  2.29106734e-11 3.21015978e-04 9.97238278e-01]\n",
      " [2.14807415e-06 5.63465152e-03 2.83290387e-06 2.93144603e-05\n",
      "  2.47736498e-10 2.61366786e-03 9.91717398e-01]], shape=(91, 7), dtype=float32)\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r7Biydb3siq2"
   },
   "source": [
    "## Loss Function\n",
    "\n",
    "##$$\n",
    "\\begin{align}\n",
    "cost(H(x),y) & = −\\sum_{n=1}^{n} Y log(H(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "sh42tbvItxYP",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:08:56.865216Z",
     "start_time": "2023-12-20T06:08:56.849502Z"
    }
   },
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    loss = -tf.reduce_mean(tf.reduce_sum(labels * tf.math.log(hypothesis), axis=1))\n",
    "    return loss\n",
    "\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)"
   ],
   "execution_count": 5,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "ZOSOjizZtx03",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:11:57.959429Z",
     "start_time": "2023-12-20T06:11:10.155312Z"
    }
   },
   "source": [
    "epochs = 10001\n",
    "\n",
    "for step in range(epochs):\n",
    "  for features, labels in dataset:\n",
    "    with tf.GradientTape() as tape:\n",
    "        pred = logistic_regression(features)\n",
    "        loss_value = loss_fn(pred,labels)\n",
    "    grads = tape.gradient(loss_value, [W,b])\n",
    "    optimizer.apply_gradients(grads_and_vars=zip(grads,[W,b]))\n",
    "    if step % 100 == 0:\n",
    "        print(\"Iter: {}, Loss: {:.4f}\".format(step, tf.reduce_mean(loss_fn(logistic_regression(features),labels))))\n"
   ],
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 0.4350\n",
      "Iter: 100, Loss: 0.4222\n",
      "Iter: 200, Loss: 0.4101\n",
      "Iter: 300, Loss: 0.3985\n",
      "Iter: 400, Loss: 0.3876\n",
      "Iter: 500, Loss: 0.3772\n",
      "Iter: 600, Loss: 0.3673\n",
      "Iter: 700, Loss: 0.3579\n",
      "Iter: 800, Loss: 0.3489\n",
      "Iter: 900, Loss: 0.3404\n",
      "Iter: 1000, Loss: 0.3323\n",
      "Iter: 1100, Loss: 0.3245\n",
      "Iter: 1200, Loss: 0.3171\n",
      "Iter: 1300, Loss: 0.3101\n",
      "Iter: 1400, Loss: 0.3033\n",
      "Iter: 1500, Loss: 0.2969\n",
      "Iter: 1600, Loss: 0.2907\n",
      "Iter: 1700, Loss: 0.2848\n",
      "Iter: 1800, Loss: 0.2792\n",
      "Iter: 1900, Loss: 0.2737\n",
      "Iter: 2000, Loss: 0.2685\n",
      "Iter: 2100, Loss: 0.2635\n",
      "Iter: 2200, Loss: 0.2586\n",
      "Iter: 2300, Loss: 0.2540\n",
      "Iter: 2400, Loss: 0.2495\n",
      "Iter: 2500, Loss: 0.2452\n",
      "Iter: 2600, Loss: 0.2410\n",
      "Iter: 2700, Loss: 0.2370\n",
      "Iter: 2800, Loss: 0.2331\n",
      "Iter: 2900, Loss: 0.2293\n",
      "Iter: 3000, Loss: 0.2256\n",
      "Iter: 3100, Loss: 0.2221\n",
      "Iter: 3200, Loss: 0.2187\n",
      "Iter: 3300, Loss: 0.2153\n",
      "Iter: 3400, Loss: 0.2121\n",
      "Iter: 3500, Loss: 0.2090\n",
      "Iter: 3600, Loss: 0.2059\n",
      "Iter: 3700, Loss: 0.2029\n",
      "Iter: 3800, Loss: 0.2000\n",
      "Iter: 3900, Loss: 0.1972\n",
      "Iter: 4000, Loss: 0.1945\n",
      "Iter: 4100, Loss: 0.1918\n",
      "Iter: 4200, Loss: 0.1893\n",
      "Iter: 4300, Loss: 0.1867\n",
      "Iter: 4400, Loss: 0.1843\n",
      "Iter: 4500, Loss: 0.1819\n",
      "Iter: 4600, Loss: 0.1795\n",
      "Iter: 4700, Loss: 0.1772\n",
      "Iter: 4800, Loss: 0.1750\n",
      "Iter: 4900, Loss: 0.1728\n",
      "Iter: 5000, Loss: 0.1707\n",
      "Iter: 5100, Loss: 0.1686\n",
      "Iter: 5200, Loss: 0.1666\n",
      "Iter: 5300, Loss: 0.1646\n",
      "Iter: 5400, Loss: 0.1626\n",
      "Iter: 5500, Loss: 0.1607\n",
      "Iter: 5600, Loss: 0.1589\n",
      "Iter: 5700, Loss: 0.1571\n",
      "Iter: 5800, Loss: 0.1553\n",
      "Iter: 5900, Loss: 0.1535\n",
      "Iter: 6000, Loss: 0.1518\n",
      "Iter: 6100, Loss: 0.1502\n",
      "Iter: 6200, Loss: 0.1485\n",
      "Iter: 6300, Loss: 0.1469\n",
      "Iter: 6400, Loss: 0.1454\n",
      "Iter: 6500, Loss: 0.1438\n",
      "Iter: 6600, Loss: 0.1423\n",
      "Iter: 6700, Loss: 0.1408\n",
      "Iter: 6800, Loss: 0.1394\n",
      "Iter: 6900, Loss: 0.1380\n",
      "Iter: 7000, Loss: 0.1366\n",
      "Iter: 7100, Loss: 0.1352\n",
      "Iter: 7200, Loss: 0.1339\n",
      "Iter: 7300, Loss: 0.1326\n",
      "Iter: 7400, Loss: 0.1313\n",
      "Iter: 7500, Loss: 0.1300\n",
      "Iter: 7600, Loss: 0.1288\n",
      "Iter: 7700, Loss: 0.1275\n",
      "Iter: 7800, Loss: 0.1263\n",
      "Iter: 7900, Loss: 0.1252\n",
      "Iter: 8000, Loss: 0.1240\n",
      "Iter: 8100, Loss: 0.1229\n",
      "Iter: 8200, Loss: 0.1218\n",
      "Iter: 8300, Loss: 0.1207\n",
      "Iter: 8400, Loss: 0.1196\n",
      "Iter: 8500, Loss: 0.1185\n",
      "Iter: 8600, Loss: 0.1175\n",
      "Iter: 8700, Loss: 0.1165\n",
      "Iter: 8800, Loss: 0.1155\n",
      "Iter: 8900, Loss: 0.1145\n",
      "Iter: 9000, Loss: 0.1135\n",
      "Iter: 9100, Loss: 0.1126\n",
      "Iter: 9200, Loss: 0.1116\n",
      "Iter: 9300, Loss: 0.1107\n",
      "Iter: 9400, Loss: 0.1098\n",
      "Iter: 9500, Loss: 0.1089\n",
      "Iter: 9600, Loss: 0.1080\n",
      "Iter: 9700, Loss: 0.1072\n",
      "Iter: 9800, Loss: 0.1063\n",
      "Iter: 9900, Loss: 0.1055\n",
      "Iter: 10000, Loss: 0.1046\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "5vben5FYty5m",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:11:57.962783Z",
     "start_time": "2023-12-20T06:11:57.958628Z"
    }
   },
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    hypothesis = tf.argmax(hypothesis, 1)\n",
    "    predicted = tf.cast(hypothesis, dtype=tf.float32)\n",
    "    print(predicted)\n",
    "\n",
    "    labels = tf.argmax(labels, 1)\n",
    "    labels = tf.cast(labels, dtype=tf.float32)\n",
    "    print(labels)\n",
    "\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "\n",
    "    return accuracy"
   ],
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "GSS_yRMRt6Pp",
    "ExecuteTime": {
     "end_time": "2023-12-20T06:11:58.212295Z",
     "start_time": "2023-12-20T06:11:57.962911Z"
    }
   },
   "source": [
    "test_acc = accuracy_fn(logistic_regression(x_test),y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ],
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([2. 3. 0. 0. 1. 0. 5. 0. 1. 1.], shape=(10,), dtype=float32)\n",
      "tf.Tensor([2. 3. 0. 0. 1. 0. 5. 0. 6. 1.], shape=(10,), dtype=float32)\n",
      "Testset Accuracy: 0.9000\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ]
}
