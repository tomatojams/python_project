{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxCeEJ9mjZuC"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gEndPDUNEe-H",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217760454,
     "user_tz": -540,
     "elapsed": 4444,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "a39fb250-15f9-4530-f71e-0e9ceb5b3ecd",
    "ExecuteTime": {
     "end_time": "2023-12-21T00:41:55.306833Z",
     "start_time": "2023-12-21T00:41:52.557787Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 1,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRqCpkpdMdTQ"
   },
   "source": [
    "## Make a dataset for Logistic Regression\n",
    "\n",
    "### Logistic Regression을 위한 Dataset을 임의로 만들어 봅시다.\n",
    "\n",
    "* 2가지 위치에 몰려있는 데이터\n",
    "* 테스트를 위한 빨간색 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hYtiGWxjZuJ"
   },
   "source": [
    "## tf.data.Dataset\n",
    "* 데이터를 관리해주기위한 tf function\n",
    "* 각 데이터의 필요 기능들을 지원해준다.\n",
    "* 데이터셋 크기가 클 경우에 메모리에 나눠올리는 기능을 지원"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (x_train, y_train))\n",
    "\n",
    "# for t, l in dataset:\n",
    "#   print(t, l)\n",
    "#   break"
   ],
   "metadata": {
    "id": "_HugkU46hHhd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:56.912808300Z",
     "start_time": "2023-12-20T13:34:56.892755Z"
    }
   },
   "execution_count": 464,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "data": {
      "text/plain": "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n0  1.593274  0.613349  0.309724  2.042536 -0.514878  0.997845  1.417079   \n1  0.568722  1.843700 -0.737456 -0.919461  0.417854  0.260081  0.443729   \n2 -0.114487  0.271091 -1.536920  0.114670 -2.048833  0.925066 -0.076973   \n3  0.251630  1.136448 -0.562255 -0.137424 -0.989744  1.476076 -1.091534   \n4 -1.210856 -1.738332 -1.599511  1.365527 -0.338294 -1.879252 -0.437457   \n5 -0.393734  0.707135  0.824390 -0.261638  1.503827 -0.782529  1.674010   \n6  0.085253  0.030386  2.491486 -1.286241 -0.258209 -1.402205 -2.924153   \n7  0.099422  0.765002  1.011855 -1.654657 -0.154596 -1.455286  1.682530   \n8 -1.530616  0.867665 -0.281238  0.037233 -1.655827 -1.152335 -0.147113   \n9  0.327623 -2.256250  0.016707  1.270301 -0.093555  0.096549 -0.367859   \n\n   feature8  feature9  feature10  feature11  feature12  feature13  feature14  \\\n0 -0.202117  0.072554   0.945508  -0.650232  -0.706413   2.469982  -1.962653   \n1 -0.833231 -0.072568   0.422924  -1.382024  -0.302917   0.587017  -0.834032   \n2  1.733600  0.608673  -1.175680   1.354920   1.463529  -0.397353   1.993837   \n3  0.190649  0.650469  -0.204851   0.208252   1.800252   0.433550  -0.666660   \n4 -0.177810 -0.038883   0.956495   1.015896   0.465122   0.500297   0.976290   \n5 -1.085025  0.645358   1.586134  -0.360298  -0.371584   1.236835  -0.803021   \n6  0.972262  1.519226   0.791284   1.031475  -0.297113  -1.019225   1.003510   \n7  1.431472 -1.347119  -0.550834   0.770652   0.357193  -0.472224   0.438418   \n8 -0.245073  0.311860  -0.671678  -1.467719  -2.678413   0.142993   1.193230   \n9 -0.623254 -0.695882  -0.696827   0.494101   0.364937  -0.664375  -0.267144   \n\n   feature15  feature16  target  \n0  -0.626638   0.006014       1  \n1  -2.269351   0.752771       0  \n2   0.318233   0.232441       1  \n3  -1.061392   0.591500       1  \n4   0.644269  -1.021144       0  \n5  -0.500096   0.146819       1  \n6  -2.045259   0.994773       1  \n7   1.431038  -0.115347       1  \n8   1.810005  -2.203884       0  \n9  -0.670133  -0.366456       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>feature9</th>\n      <th>feature10</th>\n      <th>feature11</th>\n      <th>feature12</th>\n      <th>feature13</th>\n      <th>feature14</th>\n      <th>feature15</th>\n      <th>feature16</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.593274</td>\n      <td>0.613349</td>\n      <td>0.309724</td>\n      <td>2.042536</td>\n      <td>-0.514878</td>\n      <td>0.997845</td>\n      <td>1.417079</td>\n      <td>-0.202117</td>\n      <td>0.072554</td>\n      <td>0.945508</td>\n      <td>-0.650232</td>\n      <td>-0.706413</td>\n      <td>2.469982</td>\n      <td>-1.962653</td>\n      <td>-0.626638</td>\n      <td>0.006014</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.568722</td>\n      <td>1.843700</td>\n      <td>-0.737456</td>\n      <td>-0.919461</td>\n      <td>0.417854</td>\n      <td>0.260081</td>\n      <td>0.443729</td>\n      <td>-0.833231</td>\n      <td>-0.072568</td>\n      <td>0.422924</td>\n      <td>-1.382024</td>\n      <td>-0.302917</td>\n      <td>0.587017</td>\n      <td>-0.834032</td>\n      <td>-2.269351</td>\n      <td>0.752771</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.114487</td>\n      <td>0.271091</td>\n      <td>-1.536920</td>\n      <td>0.114670</td>\n      <td>-2.048833</td>\n      <td>0.925066</td>\n      <td>-0.076973</td>\n      <td>1.733600</td>\n      <td>0.608673</td>\n      <td>-1.175680</td>\n      <td>1.354920</td>\n      <td>1.463529</td>\n      <td>-0.397353</td>\n      <td>1.993837</td>\n      <td>0.318233</td>\n      <td>0.232441</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.251630</td>\n      <td>1.136448</td>\n      <td>-0.562255</td>\n      <td>-0.137424</td>\n      <td>-0.989744</td>\n      <td>1.476076</td>\n      <td>-1.091534</td>\n      <td>0.190649</td>\n      <td>0.650469</td>\n      <td>-0.204851</td>\n      <td>0.208252</td>\n      <td>1.800252</td>\n      <td>0.433550</td>\n      <td>-0.666660</td>\n      <td>-1.061392</td>\n      <td>0.591500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.210856</td>\n      <td>-1.738332</td>\n      <td>-1.599511</td>\n      <td>1.365527</td>\n      <td>-0.338294</td>\n      <td>-1.879252</td>\n      <td>-0.437457</td>\n      <td>-0.177810</td>\n      <td>-0.038883</td>\n      <td>0.956495</td>\n      <td>1.015896</td>\n      <td>0.465122</td>\n      <td>0.500297</td>\n      <td>0.976290</td>\n      <td>0.644269</td>\n      <td>-1.021144</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.393734</td>\n      <td>0.707135</td>\n      <td>0.824390</td>\n      <td>-0.261638</td>\n      <td>1.503827</td>\n      <td>-0.782529</td>\n      <td>1.674010</td>\n      <td>-1.085025</td>\n      <td>0.645358</td>\n      <td>1.586134</td>\n      <td>-0.360298</td>\n      <td>-0.371584</td>\n      <td>1.236835</td>\n      <td>-0.803021</td>\n      <td>-0.500096</td>\n      <td>0.146819</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.085253</td>\n      <td>0.030386</td>\n      <td>2.491486</td>\n      <td>-1.286241</td>\n      <td>-0.258209</td>\n      <td>-1.402205</td>\n      <td>-2.924153</td>\n      <td>0.972262</td>\n      <td>1.519226</td>\n      <td>0.791284</td>\n      <td>1.031475</td>\n      <td>-0.297113</td>\n      <td>-1.019225</td>\n      <td>1.003510</td>\n      <td>-2.045259</td>\n      <td>0.994773</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.099422</td>\n      <td>0.765002</td>\n      <td>1.011855</td>\n      <td>-1.654657</td>\n      <td>-0.154596</td>\n      <td>-1.455286</td>\n      <td>1.682530</td>\n      <td>1.431472</td>\n      <td>-1.347119</td>\n      <td>-0.550834</td>\n      <td>0.770652</td>\n      <td>0.357193</td>\n      <td>-0.472224</td>\n      <td>0.438418</td>\n      <td>1.431038</td>\n      <td>-0.115347</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-1.530616</td>\n      <td>0.867665</td>\n      <td>-0.281238</td>\n      <td>0.037233</td>\n      <td>-1.655827</td>\n      <td>-1.152335</td>\n      <td>-0.147113</td>\n      <td>-0.245073</td>\n      <td>0.311860</td>\n      <td>-0.671678</td>\n      <td>-1.467719</td>\n      <td>-2.678413</td>\n      <td>0.142993</td>\n      <td>1.193230</td>\n      <td>1.810005</td>\n      <td>-2.203884</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.327623</td>\n      <td>-2.256250</td>\n      <td>0.016707</td>\n      <td>1.270301</td>\n      <td>-0.093555</td>\n      <td>0.096549</td>\n      <td>-0.367859</td>\n      <td>-0.623254</td>\n      <td>-0.695882</td>\n      <td>-0.696827</td>\n      <td>0.494101</td>\n      <td>0.364937</td>\n      <td>-0.664375</td>\n      <td>-0.267144</td>\n      <td>-0.670133</td>\n      <td>-0.366456</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('logistic_regression_dataset_16_features.csv', )\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T00:42:00.971Z",
     "start_time": "2023-12-21T00:42:00.916472Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metal device set to: Apple M1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-21 09:42:05.490929: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2023-12-21 09:42:05.491714: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 0 MB memory) -> physical PluggableDevice (device: 0, name: METAL, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "x_train = data.iloc[:-100, :-1]\n",
    "y_train = data.iloc[:-100, [-1]]\n",
    "x_test = data.iloc[-100:, :-1]\n",
    "y_test = data.iloc[-100:, [-1]]\n",
    "# x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "# y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "# x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "# y_test = tf.cast(y_test, dtype=tf.float32)\n",
    "y_train = tf.cast(y_train, dtype=tf.float64)\n",
    "y_test = tf.cast(y_test, dtype=tf.float64)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T00:42:05.550645Z",
     "start_time": "2023-12-21T00:42:05.484151Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "outputs": [],
   "source": [
    "\n",
    "# plt.hist(x_train[:, 12], bins=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:56.987654300Z",
     "start_time": "2023-12-20T13:34:56.951067800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 468,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# \n",
    "# \n",
    "# def normalize_features(features):\n",
    "#     \"\"\"\n",
    "#     각 특성을 정규화하는 함수.\n",
    "# \n",
    "#     Parameters:\n",
    "#     - features: 2D NumPy 배열. 각 열은 하나의 특성을 나타냅니다.\n",
    "# \n",
    "#     Returns:\n",
    "#     - normalized_features: 정규화된 특성을 담은 2D NumPy 배열.\n",
    "#     - mean_values: 각 특성의 평균을 담은 1D NumPy 배열.\n",
    "#     - std_dev_values: 각 특성의 표준 편차를 담은 1D NumPy 배열.\n",
    "#     \"\"\"\n",
    "#     mean_values = np.mean(features, axis=0)\n",
    "#     std_dev_values = np.std(features, axis=0)\n",
    "# \n",
    "#     # 0으로 나누기를 피하기 위해 표준 편차가 0이면 1로 대체\n",
    "#     std_dev_values[std_dev_values == 0] = 1.0\n",
    "# \n",
    "#     normalized_features = (features - mean_values) / std_dev_values\n",
    "# \n",
    "#     return normalized_features, mean_values, std_dev_values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:57.001192300Z",
     "start_time": "2023-12-20T13:34:56.967602Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "outputs": [],
   "source": [
    "# x_train, mean_values, std_dev_values = normalize_features(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:57.046728200Z",
     "start_time": "2023-12-20T13:34:56.982648Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "# for t, l in dataset:\n",
    "#   print(t, l)\n",
    "#   break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-21T00:42:11.926486Z",
     "start_time": "2023-12-21T00:42:11.903880Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MxddblPApI8v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "94bcf791-be3a-46d5-b56f-1423bf410f12",
    "ExecuteTime": {
     "end_time": "2023-12-21T00:42:15.800135Z",
     "start_time": "2023-12-21T00:42:15.759147Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "W = tf.Variable(tf.random.normal([16, 1], 0, 1, dtype=tf.float64), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1], 0, 1, dtype=tf.float64), name='bias')\n",
    "print(type(W[0, 0]))\n",
    "\n",
    "tf.print(W, b)"
   ],
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[0.50637771248050889]\n",
      " [-0.14843687296417338]\n",
      " [-0.80145811870268635]\n",
      " ...\n",
      " [-0.53017404129335532]\n",
      " [0.806981694523159]\n",
      " [0.306150488831741]] [-0.15229604769720931]\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYPKT6To56Iv"
   },
   "source": [
    "## Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "## $$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LFAWvdar8PP-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "a205371c-0955-4bbd-e906-a3fcdd4557e4",
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:57.086908900Z",
     "start_time": "2023-12-20T13:34:57.031401700Z"
    }
   },
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis = tf.divide(1., 1. + tf.exp(-(tf.matmul(features, W, ) + b)))\n",
    "    # tf.sigmoid(tf.matmul(features, W) + b)\n",
    "    return hypothesis\n",
    "\n",
    "\n",
    "tf.print(logistic_regression(x_train))"
   ],
   "execution_count": 472,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00082499885293243634]\n",
      " [0.013401250914629098]\n",
      " [0.986039403232019]\n",
      " ...\n",
      " [0.10973120920636803]\n",
      " [0.87891029902518147]\n",
      " [0.1407594466429683]]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:57.088908Z",
     "start_time": "2023-12-20T13:34:57.048268Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXHVNZ6W8V83"
   },
   "source": [
    "## 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if :  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if :  &  y=0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### 두 식을 한번에 쓰게되면,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oxIgE6nt8zvR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761055,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-12-20T13:34:57.102963700Z",
     "start_time": "2023-12-20T13:34:57.062828800Z"
    }
   },
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + \\\n",
    "                           (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = Adam(learning_rate=0.0007)"
   ],
   "execution_count": 473,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 1.63872508\n",
      "Iter: 100, Loss: 1.52110891\n",
      "Iter: 200, Loss: 1.41209982\n",
      "Iter: 300, Loss: 1.31051027\n",
      "Iter: 400, Loss: 1.21585847\n",
      "Iter: 500, Loss: 1.12792808\n",
      "Iter: 600, Loss: 1.04656321\n",
      "Iter: 700, Loss: 0.97157266\n",
      "Iter: 800, Loss: 0.90271327\n",
      "Iter: 900, Loss: 0.83969515\n",
      "Iter: 1000, Loss: 0.78218666\n",
      "Iter: 1100, Loss: 0.72982336\n",
      "Iter: 1200, Loss: 0.68222418\n",
      "Iter: 1300, Loss: 0.63900786\n",
      "Iter: 1400, Loss: 0.59980351\n",
      "Iter: 1500, Loss: 0.56425665\n",
      "Iter: 1600, Loss: 0.53203340\n",
      "Iter: 1700, Loss: 0.50282337\n",
      "Iter: 1800, Loss: 0.47634071\n",
      "Iter: 1900, Loss: 0.45232345\n",
      "Iter: 2000, Loss: 0.43053218\n",
      "Iter: 2100, Loss: 0.41074833\n",
      "Iter: 2200, Loss: 0.39277272\n",
      "Iter: 2300, Loss: 0.37642421\n",
      "Iter: 2400, Loss: 0.36153862\n",
      "Iter: 2500, Loss: 0.34796751\n",
      "Iter: 2600, Loss: 0.33557715\n",
      "Iter: 2700, Loss: 0.32424740\n",
      "Iter: 2800, Loss: 0.31387064\n",
      "Iter: 2900, Loss: 0.30435066\n",
      "Iter: 3000, Loss: 0.29560167\n",
      "Iter: 3100, Loss: 0.28754723\n",
      "Iter: 3200, Loss: 0.28011932\n",
      "Iter: 3300, Loss: 0.27325747\n",
      "Iter: 3400, Loss: 0.26690786\n",
      "Iter: 3500, Loss: 0.26102267\n",
      "Iter: 3600, Loss: 0.25555930\n",
      "Iter: 3700, Loss: 0.25047983\n",
      "Iter: 3800, Loss: 0.24575047\n",
      "Iter: 3900, Loss: 0.24134105\n"
     ]
    }
   ],
   "source": [
    "epochs = 10001\n",
    "\n",
    "br = False\n",
    "for step in range(epochs):\n",
    "    if br == True:\n",
    "        break;\n",
    "    for features, labels in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(logistic_regression(features), labels)\n",
    "        grads = tape.gradient(loss_value, [W, b])\n",
    "        optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "        if loss_fn(logistic_regression(features),\n",
    "                   labels) < 0.24:\n",
    "            br = True\n",
    "            break;\n",
    "        if step % 100 == 0:\n",
    "            print(\"Iter: {}, Loss: {:.8f}\".format(step, loss_fn(logistic_regression(features),\n",
    "                                                                labels)))\n"
   ],
   "metadata": {
    "id": "8xmYMVq65vFd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "344b7c66-5227-4913-924e-6788aab98681",
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.582932100Z",
     "start_time": "2023-12-20T13:34:57.080381800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ci-nHblj--z9",
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.597984Z",
     "start_time": "2023-12-20T13:35:43.583932700Z"
    }
   },
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    print(hypothesis)\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float64)\n",
    "    print(predicted, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float64))\n",
    "    return accuracy"
   ],
   "execution_count": 475,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YANtydPI6-sl",
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.628832300Z",
     "start_time": "2023-12-20T13:35:43.600488Z"
    }
   },
   "source": [
    "test_acc = accuracy_fn(logistic_regression(x_test), y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ],
   "execution_count": 476,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[7.56593771e-02]\n",
      " [9.99486956e-01]\n",
      " [8.52580509e-03]\n",
      " [1.56893832e-02]\n",
      " [9.79271323e-01]\n",
      " [4.18978921e-01]\n",
      " [9.28079271e-01]\n",
      " [9.91301258e-01]\n",
      " [7.65407260e-03]\n",
      " [9.16756826e-01]\n",
      " [6.78668539e-01]\n",
      " [2.95664850e-01]\n",
      " [3.20871031e-01]\n",
      " [5.00300856e-02]\n",
      " [8.66286166e-01]\n",
      " [1.20820044e-01]\n",
      " [9.93018151e-01]\n",
      " [8.84016161e-01]\n",
      " [9.81303139e-01]\n",
      " [1.06002883e-01]\n",
      " [9.94850504e-01]\n",
      " [8.64609076e-01]\n",
      " [1.33685628e-02]\n",
      " [1.61434440e-01]\n",
      " [4.83679713e-01]\n",
      " [8.01965873e-03]\n",
      " [1.88863038e-01]\n",
      " [7.75794914e-01]\n",
      " [9.28539366e-01]\n",
      " [9.81163372e-01]\n",
      " [5.10560547e-02]\n",
      " [4.98759660e-01]\n",
      " [4.28615431e-01]\n",
      " [7.51892486e-01]\n",
      " [8.45897144e-01]\n",
      " [4.11037623e-01]\n",
      " [9.93738927e-01]\n",
      " [2.94289519e-01]\n",
      " [2.43957174e-01]\n",
      " [9.98843463e-01]\n",
      " [1.35093219e-01]\n",
      " [5.09739678e-01]\n",
      " [6.78065402e-01]\n",
      " [3.48730085e-04]\n",
      " [9.20574770e-01]\n",
      " [9.91752830e-01]\n",
      " [9.84251559e-01]\n",
      " [9.17656301e-01]\n",
      " [3.04998218e-03]\n",
      " [8.81389451e-02]\n",
      " [2.92868979e-01]\n",
      " [9.81366045e-01]\n",
      " [9.17385711e-01]\n",
      " [9.78790164e-01]\n",
      " [1.57726545e-01]\n",
      " [8.59982070e-01]\n",
      " [3.47241501e-02]\n",
      " [8.91816983e-01]\n",
      " [9.99830990e-01]\n",
      " [9.84458728e-01]\n",
      " [3.08634436e-02]\n",
      " [2.97418488e-01]\n",
      " [6.99460615e-01]\n",
      " [2.44417867e-02]\n",
      " [9.09605544e-01]\n",
      " [6.07574333e-01]\n",
      " [2.92421217e-01]\n",
      " [6.43986053e-01]\n",
      " [4.20380993e-03]\n",
      " [7.97294020e-01]\n",
      " [9.99819797e-01]\n",
      " [9.27223956e-02]\n",
      " [4.40652286e-01]\n",
      " [5.54788198e-01]\n",
      " [1.46706074e-01]\n",
      " [4.46664305e-02]\n",
      " [9.89395643e-01]\n",
      " [1.73701697e-01]\n",
      " [8.91028203e-01]\n",
      " [9.86069828e-01]\n",
      " [1.79407291e-02]\n",
      " [1.70118675e-01]\n",
      " [4.00597788e-03]\n",
      " [7.60336465e-02]\n",
      " [3.83163735e-01]\n",
      " [3.32854292e-01]\n",
      " [2.73085172e-01]\n",
      " [9.83877108e-01]\n",
      " [9.34487340e-01]\n",
      " [9.94189836e-01]\n",
      " [2.00021394e-01]\n",
      " [9.17791352e-01]\n",
      " [9.95935713e-01]\n",
      " [9.57259454e-01]\n",
      " [2.17007080e-01]\n",
      " [2.24865267e-02]\n",
      " [9.99810532e-01]\n",
      " [8.72552075e-01]\n",
      " [6.64115497e-01]\n",
      " [4.35873802e-01]], shape=(100, 1), dtype=float64)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]], shape=(100, 1), dtype=float64) tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]], shape=(100, 1), dtype=float64)\n",
      "Testset Accuracy: 0.8800\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.630340400Z",
     "start_time": "2023-12-20T13:35:43.614786700Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176472\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      883\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Wed, 20 Dec 2023   Pseudo R-squ.:                  0.7453\n",
      "Time:                        22:35:43   Log-Likelihood:                -158.82\n",
      "converged:                       True   LL-Null:                       -623.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.455e-187\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1462      0.150      0.974      0.330      -0.148       0.440\n",
      "x1             1.8174      0.208      8.751      0.000       1.410       2.224\n",
      "x2             2.2840      0.242      9.432      0.000       1.809       2.759\n",
      "x3             1.9617      0.213      9.226      0.000       1.545       2.378\n",
      "x4             1.8296      0.206      8.886      0.000       1.426       2.233\n",
      "x5             1.8075      0.224      8.068      0.000       1.368       2.247\n",
      "x6             1.6915      0.206      8.193      0.000       1.287       2.096\n",
      "x7             1.8240      0.212      8.609      0.000       1.409       2.239\n",
      "x8             1.8708      0.199      9.417      0.000       1.481       2.260\n",
      "x9             1.8468      0.208      8.891      0.000       1.440       2.254\n",
      "x10            1.7757      0.213      8.319      0.000       1.357       2.194\n",
      "x11            2.2695      0.244      9.303      0.000       1.791       2.748\n",
      "x12            1.7215      0.221      7.788      0.000       1.288       2.155\n",
      "x13            1.9416      0.212      9.151      0.000       1.526       2.357\n",
      "x14            1.7855      0.203      8.809      0.000       1.388       2.183\n",
      "x15            1.9274      0.218      8.854      0.000       1.501       2.354\n",
      "x16            1.7537      0.207      8.468      0.000       1.348       2.160\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.20 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "Wald 검정 결과:\n",
      "                        chi2                  P>chi2  df constraint\n",
      "const  [[0.949215279386571]]      0.3299191216428535              1\n",
      "x1      [[76.5803255614396]]  2.1143562260993156e-18              1\n",
      "x2     [[88.95858629848718]]   4.031648969657435e-21              1\n",
      "x3     [[85.12610311790873]]   2.799305443020824e-20              1\n",
      "x4     [[78.95706542089601]]   6.347451998943744e-19              1\n",
      "x5     [[65.08894519441013]]   7.159257526027282e-16              1\n",
      "x6     [[67.12341781314312]]  2.5503095141113983e-16              1\n",
      "x7     [[74.11170828100137]]   7.381919830229054e-18              1\n",
      "x8     [[88.68909808364049]]   4.620043757809397e-21              1\n",
      "x9     [[79.04446736790452]]   6.072755885546323e-19              1\n",
      "x10    [[69.21108256012928]]    8.84695203879294e-17              1\n",
      "x11    [[86.54281786141516]]  1.3674437824816102e-20              1\n",
      "x12    [[60.65264398471187]]  6.8088558230063725e-15              1\n",
      "x13     [[83.7486719268534]]   5.618478849884417e-20              1\n",
      "x14    [[77.59850219341182]]  1.2626583211581707e-18              1\n",
      "x15    [[78.39432222768095]]   8.439438759045757e-19              1\n",
      "x16    [[71.70513990945615]]  2.4988079445482218e-17              1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\statsmodels\\base\\model.py:1906: FutureWarning: The behavior of wald_test will change after 0.14 to returning scalar test statistic values. To get the future behavior now, set scalar to True. To silence this message while retaining the legacy behavior, set scalar to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# lib import\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 상수 항 추가\n",
    "x_train = sm.add_constant(x_train)\n",
    "\n",
    "# 로지스틱 회귀 모델 피팅\n",
    "x_train = np.asarray(x_train).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "logit_model = sm.Logit(y_train, x_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# 결과 요약 출력\n",
    "print(result.summary())\n",
    "\n",
    "# 각 계수에 대한 Wald 검정\n",
    "wald_test_results = result.wald_test_terms()\n",
    "\n",
    "# Wald 검정 결과 출력\n",
    "print(\"\\nWald 검정 결과:\")\n",
    "print(wald_test_results)\n",
    "\n",
    "# 아래 검정 결과를 통해 얻을 수 있는 결론:\n",
    "# 1. \"Optimization terminated successfully\" -> 최적화가 성공적으로 종료되었다.\n",
    "# 2. p-value(P>|z|)가 0.05를 넘는 값이 없다 -> 통계적으로 유의미한 파라미터가 없다.\n",
    "# 3. Wald검정에서 (P>chi2)의 값이 0.05보다 낮은 값이 없다 -> 통계적으로 유의미한 파라미터가 없다.\n",
    "# 4. Possibly complete quasi-separation -> 모델이 데이터에 완전히 학습되었다, 즉 과적합일 수 있다는 경고."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.675878400Z",
     "start_time": "2023-12-20T13:35:43.635877200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T13:35:43.702016Z",
     "start_time": "2023-12-20T13:35:43.677874500Z"
    }
   }
  }
 ]
}
