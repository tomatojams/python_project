{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VxCeEJ9mjZuC"
   },
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "gEndPDUNEe-H",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217760454,
     "user_tz": -540,
     "elapsed": 4444,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "a39fb250-15f9-4530-f71e-0e9ceb5b3ecd",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.453617Z",
     "start_time": "2023-12-20T12:49:38.396684Z"
    }
   },
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "tf.__version__"
   ],
   "execution_count": 163,
   "outputs": [
    {
     "data": {
      "text/plain": "'2.10.0'"
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dRqCpkpdMdTQ"
   },
   "source": [
    "## Make a dataset for Logistic Regression\n",
    "\n",
    "### Logistic Regression을 위한 Dataset을 임의로 만들어 봅시다.\n",
    "\n",
    "* 2가지 위치에 몰려있는 데이터\n",
    "* 테스트를 위한 빨간색 데이터"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5hYtiGWxjZuJ"
   },
   "source": [
    "## tf.data.Dataset\n",
    "* 데이터를 관리해주기위한 tf function\n",
    "* 각 데이터의 필요 기능들을 지원해준다.\n",
    "* 데이터셋 크기가 클 경우에 메모리에 나눠올리는 기능을 지원"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# dataset = tf.data.Dataset.from_tensor_slices(\n",
    "#     (x_train, y_train))\n",
    "\n",
    "# for t, l in dataset:\n",
    "#   print(t, l)\n",
    "#   break"
   ],
   "metadata": {
    "id": "_HugkU46hHhd",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 8,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.479614700Z",
     "start_time": "2023-12-20T12:49:38.457615300Z"
    }
   },
   "execution_count": 164,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "outputs": [
    {
     "data": {
      "text/plain": "   feature1  feature2  feature3  feature4  feature5  feature6  feature7  \\\n0  1.593274  0.613349  0.309724  2.042536 -0.514878  0.997845  1.417079   \n1  0.568722  1.843700 -0.737456 -0.919461  0.417854  0.260081  0.443729   \n2 -0.114487  0.271091 -1.536920  0.114670 -2.048833  0.925066 -0.076973   \n3  0.251630  1.136448 -0.562255 -0.137424 -0.989744  1.476076 -1.091534   \n4 -1.210856 -1.738332 -1.599511  1.365527 -0.338294 -1.879252 -0.437457   \n5 -0.393734  0.707135  0.824390 -0.261638  1.503827 -0.782529  1.674010   \n6  0.085253  0.030386  2.491486 -1.286241 -0.258209 -1.402205 -2.924153   \n7  0.099422  0.765002  1.011855 -1.654657 -0.154596 -1.455286  1.682530   \n8 -1.530616  0.867665 -0.281238  0.037233 -1.655827 -1.152335 -0.147113   \n9  0.327623 -2.256250  0.016707  1.270301 -0.093555  0.096549 -0.367859   \n\n   feature8  feature9  feature10  feature11  feature12  feature13  feature14  \\\n0 -0.202117  0.072554   0.945508  -0.650232  -0.706413   2.469982  -1.962653   \n1 -0.833231 -0.072568   0.422924  -1.382024  -0.302917   0.587017  -0.834032   \n2  1.733600  0.608673  -1.175680   1.354920   1.463529  -0.397353   1.993837   \n3  0.190649  0.650469  -0.204851   0.208252   1.800252   0.433550  -0.666660   \n4 -0.177810 -0.038883   0.956495   1.015896   0.465122   0.500297   0.976290   \n5 -1.085025  0.645358   1.586134  -0.360298  -0.371584   1.236835  -0.803021   \n6  0.972262  1.519226   0.791284   1.031475  -0.297113  -1.019225   1.003510   \n7  1.431472 -1.347119  -0.550834   0.770652   0.357193  -0.472224   0.438418   \n8 -0.245073  0.311860  -0.671678  -1.467719  -2.678413   0.142993   1.193230   \n9 -0.623254 -0.695882  -0.696827   0.494101   0.364937  -0.664375  -0.267144   \n\n   feature15  feature16  target  \n0  -0.626638   0.006014       1  \n1  -2.269351   0.752771       0  \n2   0.318233   0.232441       1  \n3  -1.061392   0.591500       1  \n4   0.644269  -1.021144       0  \n5  -0.500096   0.146819       1  \n6  -2.045259   0.994773       1  \n7   1.431038  -0.115347       1  \n8   1.810005  -2.203884       0  \n9  -0.670133  -0.366456       0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>feature1</th>\n      <th>feature2</th>\n      <th>feature3</th>\n      <th>feature4</th>\n      <th>feature5</th>\n      <th>feature6</th>\n      <th>feature7</th>\n      <th>feature8</th>\n      <th>feature9</th>\n      <th>feature10</th>\n      <th>feature11</th>\n      <th>feature12</th>\n      <th>feature13</th>\n      <th>feature14</th>\n      <th>feature15</th>\n      <th>feature16</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1.593274</td>\n      <td>0.613349</td>\n      <td>0.309724</td>\n      <td>2.042536</td>\n      <td>-0.514878</td>\n      <td>0.997845</td>\n      <td>1.417079</td>\n      <td>-0.202117</td>\n      <td>0.072554</td>\n      <td>0.945508</td>\n      <td>-0.650232</td>\n      <td>-0.706413</td>\n      <td>2.469982</td>\n      <td>-1.962653</td>\n      <td>-0.626638</td>\n      <td>0.006014</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.568722</td>\n      <td>1.843700</td>\n      <td>-0.737456</td>\n      <td>-0.919461</td>\n      <td>0.417854</td>\n      <td>0.260081</td>\n      <td>0.443729</td>\n      <td>-0.833231</td>\n      <td>-0.072568</td>\n      <td>0.422924</td>\n      <td>-1.382024</td>\n      <td>-0.302917</td>\n      <td>0.587017</td>\n      <td>-0.834032</td>\n      <td>-2.269351</td>\n      <td>0.752771</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.114487</td>\n      <td>0.271091</td>\n      <td>-1.536920</td>\n      <td>0.114670</td>\n      <td>-2.048833</td>\n      <td>0.925066</td>\n      <td>-0.076973</td>\n      <td>1.733600</td>\n      <td>0.608673</td>\n      <td>-1.175680</td>\n      <td>1.354920</td>\n      <td>1.463529</td>\n      <td>-0.397353</td>\n      <td>1.993837</td>\n      <td>0.318233</td>\n      <td>0.232441</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.251630</td>\n      <td>1.136448</td>\n      <td>-0.562255</td>\n      <td>-0.137424</td>\n      <td>-0.989744</td>\n      <td>1.476076</td>\n      <td>-1.091534</td>\n      <td>0.190649</td>\n      <td>0.650469</td>\n      <td>-0.204851</td>\n      <td>0.208252</td>\n      <td>1.800252</td>\n      <td>0.433550</td>\n      <td>-0.666660</td>\n      <td>-1.061392</td>\n      <td>0.591500</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-1.210856</td>\n      <td>-1.738332</td>\n      <td>-1.599511</td>\n      <td>1.365527</td>\n      <td>-0.338294</td>\n      <td>-1.879252</td>\n      <td>-0.437457</td>\n      <td>-0.177810</td>\n      <td>-0.038883</td>\n      <td>0.956495</td>\n      <td>1.015896</td>\n      <td>0.465122</td>\n      <td>0.500297</td>\n      <td>0.976290</td>\n      <td>0.644269</td>\n      <td>-1.021144</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>-0.393734</td>\n      <td>0.707135</td>\n      <td>0.824390</td>\n      <td>-0.261638</td>\n      <td>1.503827</td>\n      <td>-0.782529</td>\n      <td>1.674010</td>\n      <td>-1.085025</td>\n      <td>0.645358</td>\n      <td>1.586134</td>\n      <td>-0.360298</td>\n      <td>-0.371584</td>\n      <td>1.236835</td>\n      <td>-0.803021</td>\n      <td>-0.500096</td>\n      <td>0.146819</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.085253</td>\n      <td>0.030386</td>\n      <td>2.491486</td>\n      <td>-1.286241</td>\n      <td>-0.258209</td>\n      <td>-1.402205</td>\n      <td>-2.924153</td>\n      <td>0.972262</td>\n      <td>1.519226</td>\n      <td>0.791284</td>\n      <td>1.031475</td>\n      <td>-0.297113</td>\n      <td>-1.019225</td>\n      <td>1.003510</td>\n      <td>-2.045259</td>\n      <td>0.994773</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>0.099422</td>\n      <td>0.765002</td>\n      <td>1.011855</td>\n      <td>-1.654657</td>\n      <td>-0.154596</td>\n      <td>-1.455286</td>\n      <td>1.682530</td>\n      <td>1.431472</td>\n      <td>-1.347119</td>\n      <td>-0.550834</td>\n      <td>0.770652</td>\n      <td>0.357193</td>\n      <td>-0.472224</td>\n      <td>0.438418</td>\n      <td>1.431038</td>\n      <td>-0.115347</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>8</th>\n      <td>-1.530616</td>\n      <td>0.867665</td>\n      <td>-0.281238</td>\n      <td>0.037233</td>\n      <td>-1.655827</td>\n      <td>-1.152335</td>\n      <td>-0.147113</td>\n      <td>-0.245073</td>\n      <td>0.311860</td>\n      <td>-0.671678</td>\n      <td>-1.467719</td>\n      <td>-2.678413</td>\n      <td>0.142993</td>\n      <td>1.193230</td>\n      <td>1.810005</td>\n      <td>-2.203884</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>0.327623</td>\n      <td>-2.256250</td>\n      <td>0.016707</td>\n      <td>1.270301</td>\n      <td>-0.093555</td>\n      <td>0.096549</td>\n      <td>-0.367859</td>\n      <td>-0.623254</td>\n      <td>-0.695882</td>\n      <td>-0.696827</td>\n      <td>0.494101</td>\n      <td>0.364937</td>\n      <td>-0.664375</td>\n      <td>-0.267144</td>\n      <td>-0.670133</td>\n      <td>-0.366456</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('logistic_regression_dataset_16_features.csv', )\n",
    "data.head(10)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.519103100Z",
     "start_time": "2023-12-20T12:49:38.472097200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "outputs": [],
   "source": [
    "x_train = data.iloc[:-100, :-1]\n",
    "y_train = data.iloc[:-100, [-1]]\n",
    "x_test = data.iloc[-100:, :-1]\n",
    "y_test = data.iloc[-100:, [-1]]\n",
    "x_train = tf.cast(x_train, dtype=tf.float32)\n",
    "y_train = tf.cast(y_train, dtype=tf.float32)\n",
    "x_test = tf.cast(x_test, dtype=tf.float32)\n",
    "y_test = tf.cast(y_test, dtype=tf.float32)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.520102800Z",
     "start_time": "2023-12-20T12:49:38.504566300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "outputs": [],
   "source": [
    "\n",
    "# plt.hist(x_train[:, 0], bins=100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.558555100Z",
     "start_time": "2023-12-20T12:49:38.519103100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# \n",
    "# \n",
    "# def normalize_features(features):\n",
    "#     \"\"\"\n",
    "#     각 특성을 정규화하는 함수.\n",
    "# \n",
    "#     Parameters:\n",
    "#     - features: 2D NumPy 배열. 각 열은 하나의 특성을 나타냅니다.\n",
    "# \n",
    "#     Returns:\n",
    "#     - normalized_features: 정규화된 특성을 담은 2D NumPy 배열.\n",
    "#     - mean_values: 각 특성의 평균을 담은 1D NumPy 배열.\n",
    "#     - std_dev_values: 각 특성의 표준 편차를 담은 1D NumPy 배열.\n",
    "#     \"\"\"\n",
    "#     mean_values = np.mean(features, axis=0)\n",
    "#     std_dev_values = np.std(features, axis=0)\n",
    "# \n",
    "#     # 0으로 나누기를 피하기 위해 표준 편차가 0이면 1로 대체\n",
    "#     std_dev_values[std_dev_values == 0] = 1.0\n",
    "# \n",
    "#     normalized_features = (features - mean_values) / std_dev_values\n",
    "# \n",
    "#     return normalized_features, mean_values, std_dev_values\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.560556500Z",
     "start_time": "2023-12-20T12:49:38.533480400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "outputs": [],
   "source": [
    "# x_train, mean_values, std_dev_values = normalize_features(x_train)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.576603Z",
     "start_time": "2023-12-20T12:49:38.548518400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices(\n",
    "    (x_train, y_train)).batch(len(x_train))\n",
    "\n",
    "# for t, l in dataset:\n",
    "#   print(t, l)\n",
    "#   break"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.635838800Z",
     "start_time": "2023-12-20T12:49:38.565433400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MxddblPApI8v",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 7,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "94bcf791-be3a-46d5-b56f-1423bf410f12",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.636838400Z",
     "start_time": "2023-12-20T12:49:38.582612200Z"
    }
   },
   "source": [
    "\n",
    "\n",
    "W = tf.Variable(tf.random.normal([16, 1], 0, 1), name='weight')\n",
    "b = tf.Variable(tf.random.normal([1], 0, 1), name='bias')\n",
    "print(type(W[0, 0]))\n",
    "\n",
    "tf.print(W, b)"
   ],
   "execution_count": 171,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "[[-1.70261908]\n",
      " [-0.592573881]\n",
      " [-0.0558454283]\n",
      " ...\n",
      " [0.24616012]\n",
      " [0.862352431]\n",
      " [-0.473407418]] [-0.519637585]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYPKT6To56Iv"
   },
   "source": [
    "## Sigmoid 함수를 가설로 선언합니다\n",
    "* Sigmoid는 아래 그래프와 같이 0과 1의 값만을 리턴합니다 tf.sigmoid(tf.matmul(X, W) + b)와 같습니다\n",
    "\n",
    "## $$\n",
    "\\begin{align}\n",
    "sigmoid(x) & = \\frac{1}{1+e^{-x}}  \\\\\\\\\\\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "![sigmoid](https://upload.wikimedia.org/wikipedia/commons/8/88/Logistic-curve.svg)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "LFAWvdar8PP-",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761054,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "outputId": "a205371c-0955-4bbd-e906-a3fcdd4557e4",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.637837500Z",
     "start_time": "2023-12-20T12:49:38.596627300Z"
    }
   },
   "source": [
    "def logistic_regression(features):\n",
    "    hypothesis = tf.divide(1., 1. + tf.exp(-(tf.matmul(features, W, ) + b)))\n",
    "    # tf.sigmoid(tf.matmul(features, W) + b)\n",
    "    return hypothesis\n",
    "\n",
    "\n",
    "tf.print(logistic_regression(x_train))"
   ],
   "execution_count": 172,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.000729567255]\n",
      " [0.0156650376]\n",
      " [0.320276231]\n",
      " ...\n",
      " [0.527601421]\n",
      " [0.00484084524]\n",
      " [0.00149267737]]\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PXHVNZ6W8V83"
   },
   "source": [
    "## 가설을 검증할 Cost 함수를 정의합니다\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −log(h(x))  &  if :  &  y=1 \\\\\\\\\\\n",
    "cost(h(x),y) & = -log(1−h(x))  &  if :  &  y=0\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "### 두 식을 한번에 쓰게되면,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "cost(h(x),y) & = −y log(h(x))−(1−y)log(1−h(x))\n",
    "\\end{align}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "oxIgE6nt8zvR",
    "executionInfo": {
     "status": "ok",
     "timestamp": 1675217761055,
     "user_tz": -540,
     "elapsed": 5,
     "user": {
      "displayName": "­소준섭",
      "userId": "06480402923742517511"
     }
    },
    "ExecuteTime": {
     "end_time": "2023-12-20T12:49:38.637837500Z",
     "start_time": "2023-12-20T12:49:38.610644900Z"
    }
   },
   "source": [
    "def loss_fn(hypothesis, labels):\n",
    "    cost = -tf.reduce_mean(labels * tf.math.log(hypothesis) + \\\n",
    "                           (1 - labels) * tf.math.log(1 - hypothesis))\n",
    "    return cost\n",
    "\n",
    "\n",
    "# optimizer = tf.compat.v1.train.GradientDescentOptimizer(learning_rate=0.01)\n",
    "optimizer = Adam(learning_rate=0.0007)"
   ],
   "execution_count": 173,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter: 0, Loss: 2.3262\n",
      "Iter: 100, Loss: 2.1828\n",
      "Iter: 200, Loss: 2.0472\n",
      "Iter: 300, Loss: 1.9196\n",
      "Iter: 400, Loss: 1.7994\n",
      "Iter: 500, Loss: 1.6862\n",
      "Iter: 600, Loss: 1.5794\n",
      "Iter: 700, Loss: 1.4787\n",
      "Iter: 800, Loss: 1.3840\n",
      "Iter: 900, Loss: 1.2952\n",
      "Iter: 1000, Loss: 1.2122\n",
      "Iter: 1100, Loss: 1.1348\n",
      "Iter: 1200, Loss: 1.0630\n",
      "Iter: 1300, Loss: 0.9963\n",
      "Iter: 1400, Loss: 0.9346\n",
      "Iter: 1500, Loss: 0.8775\n",
      "Iter: 1600, Loss: 0.8247\n",
      "Iter: 1700, Loss: 0.7760\n",
      "Iter: 1800, Loss: 0.7310\n",
      "Iter: 1900, Loss: 0.6896\n",
      "Iter: 2000, Loss: 0.6513\n",
      "Iter: 2100, Loss: 0.6161\n",
      "Iter: 2200, Loss: 0.5836\n",
      "Iter: 2300, Loss: 0.5537\n",
      "Iter: 2400, Loss: 0.5261\n",
      "Iter: 2500, Loss: 0.5007\n",
      "Iter: 2600, Loss: 0.4772\n",
      "Iter: 2700, Loss: 0.4555\n",
      "Iter: 2800, Loss: 0.4355\n",
      "Iter: 2900, Loss: 0.4170\n",
      "Iter: 3000, Loss: 0.3999\n",
      "Iter: 3100, Loss: 0.3841\n",
      "Iter: 3200, Loss: 0.3696\n",
      "Iter: 3300, Loss: 0.3561\n",
      "Iter: 3400, Loss: 0.3436\n",
      "Iter: 3500, Loss: 0.3321\n",
      "Iter: 3600, Loss: 0.3215\n",
      "Iter: 3700, Loss: 0.3117\n",
      "Iter: 3800, Loss: 0.3026\n",
      "Iter: 3900, Loss: 0.2942\n",
      "Iter: 4000, Loss: 0.2864\n",
      "Iter: 4100, Loss: 0.2792\n",
      "Iter: 4200, Loss: 0.2725\n",
      "Iter: 4300, Loss: 0.2663\n",
      "Iter: 4400, Loss: 0.2606\n",
      "Iter: 4500, Loss: 0.2552\n",
      "Iter: 4600, Loss: 0.2502\n",
      "Iter: 4700, Loss: 0.2456\n",
      "Iter: 4800, Loss: 0.2412\n",
      "Iter: 4900, Loss: 0.2371\n",
      "Iter: 5000, Loss: 0.2333\n"
     ]
    }
   ],
   "source": [
    "epochs = 5001\n",
    "\n",
    "for step in range(epochs):\n",
    "    for features, labels in dataset:\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss_value = loss_fn(logistic_regression(features), labels)\n",
    "            grads = tape.gradient(loss_value, [W, b])\n",
    "            optimizer.apply_gradients(grads_and_vars=zip(grads, [W, b]))\n",
    "            if step % 100 == 0:\n",
    "                print(\"Iter: {}, Loss: {:.4f}\".format(step, loss_fn(logistic_regression(features),\n",
    "                                                                    labels)))"
   ],
   "metadata": {
    "id": "8xmYMVq65vFd",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "344b7c66-5227-4913-924e-6788aab98681",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.851587400Z",
     "start_time": "2023-12-20T12:49:38.626810100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Ci-nHblj--z9",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.866443800Z",
     "start_time": "2023-12-20T12:50:26.851587400Z"
    }
   },
   "source": [
    "def accuracy_fn(hypothesis, labels):\n",
    "    print(hypothesis)\n",
    "    predicted = tf.cast(hypothesis > 0.5, dtype=tf.float32)\n",
    "    print(predicted, labels)\n",
    "    accuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, labels), dtype=tf.float32))\n",
    "    return accuracy\n"
   ],
   "execution_count": 175,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "YANtydPI6-sl",
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.885483300Z",
     "start_time": "2023-12-20T12:50:26.866443800Z"
    }
   },
   "source": [
    "test_acc = accuracy_fn(logistic_regression(x_test), y_test)\n",
    "print(\"Testset Accuracy: {:.4f}\".format(test_acc))"
   ],
   "execution_count": 176,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[2.17167847e-02]\n",
      " [9.99688387e-01]\n",
      " [1.04685919e-02]\n",
      " [3.29177617e-03]\n",
      " [9.61106777e-01]\n",
      " [4.89061296e-01]\n",
      " [8.78411710e-01]\n",
      " [9.51045573e-01]\n",
      " [1.22651048e-02]\n",
      " [8.64196599e-01]\n",
      " [4.57005531e-01]\n",
      " [6.13784730e-01]\n",
      " [1.43426001e-01]\n",
      " [1.40485495e-01]\n",
      " [5.93822360e-01]\n",
      " [2.24867061e-01]\n",
      " [9.86573219e-01]\n",
      " [8.08031976e-01]\n",
      " [9.84035134e-01]\n",
      " [6.05320372e-02]\n",
      " [9.98829067e-01]\n",
      " [7.95241892e-01]\n",
      " [2.61981301e-02]\n",
      " [2.47607991e-01]\n",
      " [8.53405654e-01]\n",
      " [1.60323512e-02]\n",
      " [1.49593338e-01]\n",
      " [4.70057160e-01]\n",
      " [9.71124887e-01]\n",
      " [9.56688881e-01]\n",
      " [3.87116447e-02]\n",
      " [6.92741752e-01]\n",
      " [4.40070301e-01]\n",
      " [3.54046643e-01]\n",
      " [6.58475459e-01]\n",
      " [2.28623286e-01]\n",
      " [9.93947268e-01]\n",
      " [4.07937258e-01]\n",
      " [1.18249208e-01]\n",
      " [9.96832192e-01]\n",
      " [4.66805995e-02]\n",
      " [5.21149755e-01]\n",
      " [5.49897850e-01]\n",
      " [1.24856902e-04]\n",
      " [9.61723566e-01]\n",
      " [9.98964548e-01]\n",
      " [9.87734497e-01]\n",
      " [9.54803109e-01]\n",
      " [7.17309723e-03]\n",
      " [1.01279564e-01]\n",
      " [2.93850511e-01]\n",
      " [9.69483793e-01]\n",
      " [9.49525774e-01]\n",
      " [9.96205568e-01]\n",
      " [1.33055478e-01]\n",
      " [9.18193877e-01]\n",
      " [1.65386740e-02]\n",
      " [6.61153436e-01]\n",
      " [9.99863863e-01]\n",
      " [9.97497737e-01]\n",
      " [1.64608747e-01]\n",
      " [3.14523309e-01]\n",
      " [5.97800434e-01]\n",
      " [7.54121831e-03]\n",
      " [9.14382458e-01]\n",
      " [8.98420811e-01]\n",
      " [1.06281184e-01]\n",
      " [6.42972410e-01]\n",
      " [1.08587733e-02]\n",
      " [9.32222307e-01]\n",
      " [9.99165058e-01]\n",
      " [5.74462339e-02]\n",
      " [5.81164896e-01]\n",
      " [2.26021498e-01]\n",
      " [1.80132445e-02]\n",
      " [3.67555022e-02]\n",
      " [9.80329752e-01]\n",
      " [9.69112366e-02]\n",
      " [8.46933544e-01]\n",
      " [9.74172235e-01]\n",
      " [2.32295357e-02]\n",
      " [1.11664206e-01]\n",
      " [9.19891521e-03]\n",
      " [5.56279067e-03]\n",
      " [3.41744334e-01]\n",
      " [5.32823466e-02]\n",
      " [3.17935735e-01]\n",
      " [9.94304478e-01]\n",
      " [9.85898376e-01]\n",
      " [9.98226106e-01]\n",
      " [6.45082667e-02]\n",
      " [9.32469368e-01]\n",
      " [9.69980299e-01]\n",
      " [9.64903772e-01]\n",
      " [1.65112779e-01]\n",
      " [1.24124102e-02]\n",
      " [9.99815524e-01]\n",
      " [9.76872325e-01]\n",
      " [4.94142830e-01]\n",
      " [5.19647956e-01]], shape=(100, 1), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]], shape=(100, 1), dtype=float32) tf.Tensor(\n",
      "[[0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]], shape=(100, 1), dtype=float32)\n",
      "Testset Accuracy: 0.9400\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "outputs": [],
   "source": [
    "import statsmodels.api as sm"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.904859500Z",
     "start_time": "2023-12-20T12:50:26.881476500Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.176472\n",
      "         Iterations 9\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:                      y   No. Observations:                  900\n",
      "Model:                          Logit   Df Residuals:                      883\n",
      "Method:                           MLE   Df Model:                           16\n",
      "Date:                Wed, 20 Dec 2023   Pseudo R-squ.:                  0.7453\n",
      "Time:                        21:50:26   Log-Likelihood:                -158.82\n",
      "converged:                       True   LL-Null:                       -623.51\n",
      "Covariance Type:            nonrobust   LLR p-value:                1.455e-187\n",
      "==============================================================================\n",
      "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const          0.1462      0.150      0.974      0.330      -0.148       0.440\n",
      "x1             1.8174      0.208      8.751      0.000       1.410       2.224\n",
      "x2             2.2840      0.242      9.432      0.000       1.809       2.759\n",
      "x3             1.9617      0.213      9.226      0.000       1.545       2.378\n",
      "x4             1.8296      0.206      8.886      0.000       1.426       2.233\n",
      "x5             1.8075      0.224      8.068      0.000       1.368       2.247\n",
      "x6             1.6915      0.206      8.193      0.000       1.287       2.096\n",
      "x7             1.8240      0.212      8.609      0.000       1.409       2.239\n",
      "x8             1.8708      0.199      9.417      0.000       1.481       2.260\n",
      "x9             1.8468      0.208      8.891      0.000       1.440       2.254\n",
      "x10            1.7757      0.213      8.319      0.000       1.357       2.194\n",
      "x11            2.2695      0.244      9.303      0.000       1.791       2.748\n",
      "x12            1.7215      0.221      7.788      0.000       1.288       2.155\n",
      "x13            1.9416      0.212      9.151      0.000       1.526       2.357\n",
      "x14            1.7855      0.203      8.809      0.000       1.388       2.183\n",
      "x15            1.9274      0.218      8.854      0.000       1.501       2.354\n",
      "x16            1.7537      0.207      8.468      0.000       1.348       2.160\n",
      "==============================================================================\n",
      "\n",
      "Possibly complete quasi-separation: A fraction 0.20 of observations can be\n",
      "perfectly predicted. This might indicate that there is complete\n",
      "quasi-separation. In this case some parameters will not be identified.\n",
      "\n",
      "Wald 검정 결과:\n",
      "                         chi2                  P>chi2  df constraint\n",
      "const  [[0.9492152793865731]]       0.329919121642853              1\n",
      "x1      [[76.58032556143957]]  2.1143562260993464e-18              1\n",
      "x2       [[88.9585862984872]]   4.031648969657377e-21              1\n",
      "x3      [[85.12610311790881]]   2.799305443020722e-20              1\n",
      "x4      [[78.95706542089606]]  6.3474519989436065e-19              1\n",
      "x5      [[65.08894519441016]]   7.159257526027176e-16              1\n",
      "x6      [[67.12341781314313]]  2.5503095141113786e-16              1\n",
      "x7      [[74.11170828100143]]   7.381919830228837e-18              1\n",
      "x8      [[88.68909808364052]]   4.620043757809333e-21              1\n",
      "x9      [[79.04446736790457]]   6.072755885546146e-19              1\n",
      "x10     [[69.21108256012933]]    8.84695203879274e-17              1\n",
      "x11     [[86.54281786141526]]  1.3674437824815407e-20              1\n",
      "x12     [[60.65264398471188]]   6.808855823006345e-15              1\n",
      "x13     [[83.74867192685345]]   5.618478849884296e-20              1\n",
      "x14     [[77.59850219341183]]  1.2626583211581614e-18              1\n",
      "x15     [[78.39432222768099]]   8.439438759045571e-19              1\n",
      "x16     [[71.70513990945615]]  2.4988079445482218e-17              1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\Anaconda3_envs\\tensor2\\lib\\site-packages\\statsmodels\\base\\model.py:1906: FutureWarning: The behavior of wald_test will change after 0.14 to returning scalar test statistic values. To get the future behavior now, set scalar to True. To silence this message while retaining the legacy behavior, set scalar to False.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# lib import\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# 상수 항 추가\n",
    "x_train = sm.add_constant(x_train)\n",
    "\n",
    "# 로지스틱 회귀 모델 피팅\n",
    "x_train = np.asarray(x_train).astype('float32')\n",
    "y_train = np.asarray(y_train).astype('float32')\n",
    "logit_model = sm.Logit(y_train, x_train)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# 결과 요약 출력\n",
    "print(result.summary())\n",
    "\n",
    "# 각 계수에 대한 Wald 검정\n",
    "wald_test_results = result.wald_test_terms()\n",
    "\n",
    "# Wald 검정 결과 출력\n",
    "print(\"\\nWald 검정 결과:\")\n",
    "print(wald_test_results)\n",
    "\n",
    "# 아래 검정 결과를 통해 얻을 수 있는 결론:\n",
    "# 1. \"Optimization terminated successfully\" -> 최적화가 성공적으로 종료되었다.\n",
    "# 2. p-value(P>|z|)가 0.05를 넘는 값이 없다 -> 통계적으로 유의미한 파라미터가 없다.\n",
    "# 3. Wald검정에서 (P>chi2)의 값이 0.05보다 낮은 값이 없다 -> 통계적으로 유의미한 파라미터가 없다.\n",
    "# 4. Possibly complete quasi-separation -> 모델이 데이터에 완전히 학습되었다, 즉 과적합일 수 있다는 경고."
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.945586200Z",
     "start_time": "2023-12-20T12:50:26.898348100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-12-20T12:50:26.975477700Z",
     "start_time": "2023-12-20T12:50:26.943587100Z"
    }
   }
  }
 ]
}
