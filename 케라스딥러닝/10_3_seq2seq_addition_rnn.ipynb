{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGVRoK-4lGvH"
      },
      "source": [
        "# Sequence to sequence learning for performing number addition\n",
        "\n",
        "**Author:** [Smerity](https://twitter.com/Smerity) and others<br>\n",
        "**Date created:** 2015/08/17<br>\n",
        "**Last modified:** 2020/04/17<br>\n",
        "**Description:** A model that learns to add strings of numbers, e.g. \"535+61\" -> \"596\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7vkoV6J1lGvJ"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this example, we train a model to learn to add two numbers, provided as strings.\n",
        "\n",
        "**Example:**\n",
        "\n",
        "- Input: \"535+61\"\n",
        "- Output: \"596\"\n",
        "\n",
        "Input may optionally be reversed, which was shown to increase performance in many tasks\n",
        " in: [Learning to Execute](http://arxiv.org/abs/1410.4615) and\n",
        "[Sequence to Sequence Learning with Neural Networks](\n",
        "\n",
        " http://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf)\n",
        "\n",
        "Theoretically, sequence order inversion introduces shorter term dependencies between\n",
        " source and target for this problem.\n",
        "\n",
        "**Results:**\n",
        "\n",
        "For two digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 5k training examples = 99% train/test accuracy in 55 epochs\n",
        "\n",
        "Three digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 50k training examples = 99% train/test accuracy in 100 epochs\n",
        "\n",
        "Four digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 400k training examples = 99% train/test accuracy in 20 epochs\n",
        "\n",
        "Five digits (reversed):\n",
        "\n",
        "+ One layer LSTM (128 HN), 550k training examples = 99% train/test accuracy in 30 epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t8EIl_n4lGvK"
      },
      "source": [
        "## Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJlRGCddlGvK"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import numpy as np\n",
        "\n",
        "# Parameters for the model and dataset.\n",
        "TRAINING_SIZE = 50000\n",
        "DIGITS = 3\n",
        "REVERSE = True\n",
        "\n",
        "# Maximum length of input is 'int + int' (e.g., '345+678'). Maximum length of\n",
        "# int is DIGITS.\n",
        "MAXLEN = DIGITS + 1 + DIGITS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iVXbD4rulGvL"
      },
      "source": [
        "## Generate the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk8wgL_glGvL",
        "outputId": "18756a46-d001-4687-b1b2-5ecb19eaee62"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating data...\n",
            "Total questions: 50000\n"
          ]
        }
      ],
      "source": [
        "\n",
        "class CharacterTable:\n",
        "    \"\"\"Given a set of characters:\n",
        "    + Encode them to a one-hot integer representation\n",
        "    + Decode the one-hot or integer representation to their character output\n",
        "    + Decode a vector of probabilities to their character output\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, chars):\n",
        "        \"\"\"Initialize character table.\n",
        "        # Arguments\n",
        "            chars: Characters that can appear in the input.\n",
        "        \"\"\"\n",
        "        self.chars = sorted(set(chars))\n",
        "        self.char_indices = dict((c, i) for i, c in enumerate(self.chars))\n",
        "        self.indices_char = dict((i, c) for i, c in enumerate(self.chars))\n",
        "\n",
        "    def encode(self, C, num_rows):\n",
        "        \"\"\"One-hot encode given string C.\n",
        "        # Arguments\n",
        "            C: string, to be encoded.\n",
        "            num_rows: Number of rows in the returned one-hot encoding. This is\n",
        "                used to keep the # of rows for each data the same.\n",
        "        \"\"\"\n",
        "        x = np.zeros((num_rows, len(self.chars)))\n",
        "        for i, c in enumerate(C):\n",
        "            x[i, self.char_indices[c]] = 1\n",
        "        return x\n",
        "\n",
        "    def decode(self, x, calc_argmax=True):\n",
        "        \"\"\"Decode the given vector or 2D array to their character output.\n",
        "        # Arguments\n",
        "            x: A vector or a 2D array of probabilities or one-hot representations;\n",
        "                or a vector of character indices (used with `calc_argmax=False`).\n",
        "            calc_argmax: Whether to find the character index with maximum\n",
        "                probability, defaults to `True`.\n",
        "        \"\"\"\n",
        "        if calc_argmax:\n",
        "            x = x.argmax(axis=-1)\n",
        "        return \"\".join(self.indices_char[x] for x in x)\n",
        "\n",
        "\n",
        "# All the numbers, plus sign and space for padding.\n",
        "chars = \"0123456789+ \"\n",
        "ctable = CharacterTable(chars)\n",
        "\n",
        "questions = []\n",
        "expected = []\n",
        "seen = set()\n",
        "print(\"Generating data...\")\n",
        "while len(questions) < TRAINING_SIZE:\n",
        "    f = lambda: int(\n",
        "        \"\".join(\n",
        "            np.random.choice(list(\"0123456789\"))\n",
        "            for i in range(np.random.randint(1, DIGITS + 1))\n",
        "        )\n",
        "    )\n",
        "    a, b = f(), f()\n",
        "    # Skip any addition questions we've already seen\n",
        "    # Also skip any such that x+Y == Y+x (hence the sorting).\n",
        "    key = tuple(sorted((a, b)))\n",
        "    if key in seen:\n",
        "        continue\n",
        "    seen.add(key)\n",
        "    # Pad the data with spaces such that it is always MAXLEN.\n",
        "    q = \"{}+{}\".format(a, b)\n",
        "    query = q + \" \" * (MAXLEN - len(q))\n",
        "    ans = str(a + b)\n",
        "    # Answers can be of maximum size DIGITS + 1.\n",
        "    ans += \" \" * (DIGITS + 1 - len(ans))\n",
        "    if REVERSE:\n",
        "        # Reverse the query, e.g., '12+345  ' becomes '  543+21'. (Note the\n",
        "        # space used for padding.)\n",
        "        query = query[::-1]\n",
        "    questions.append(query)\n",
        "    expected.append(ans)\n",
        "print(\"Total questions:\", len(questions))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swvFnKfilGvM"
      },
      "source": [
        "## Vectorize the data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YAdQpmVmlGvM",
        "outputId": "6796a4ec-6257-4951-dbbb-e40f3e8a5d2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vectorization...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  \n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:3: DeprecationWarning: `np.bool` is a deprecated alias for the builtin `bool`. To silence this warning, use `bool` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.bool_` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Data:\n",
            "(45000, 7, 12)\n",
            "(45000, 4, 12)\n",
            "Validation Data:\n",
            "(5000, 7, 12)\n",
            "(5000, 4, 12)\n"
          ]
        }
      ],
      "source": [
        "print(\"Vectorization...\")\n",
        "x = np.zeros((len(questions), MAXLEN, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(questions), DIGITS + 1, len(chars)), dtype=np.bool)\n",
        "for i, sentence in enumerate(questions):\n",
        "    x[i] = ctable.encode(sentence, MAXLEN)\n",
        "for i, sentence in enumerate(expected):\n",
        "    y[i] = ctable.encode(sentence, DIGITS + 1)\n",
        "\n",
        "# Shuffle (x, y) in unison as the later parts of x will almost all be larger\n",
        "# digits.\n",
        "indices = np.arange(len(y))\n",
        "np.random.shuffle(indices)\n",
        "x = x[indices]\n",
        "y = y[indices]\n",
        "\n",
        "# Explicitly set apart 10% for validation data that we never train over.\n",
        "split_at = len(x) - len(x) // 10\n",
        "(x_train, x_val) = x[:split_at], x[split_at:]\n",
        "(y_train, y_val) = y[:split_at], y[split_at:]\n",
        "\n",
        "print(\"Training Data:\")\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(\"Validation Data:\")\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zm4vTC3olGvM"
      },
      "source": [
        "## Build the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ep_98FO2lGvN",
        "outputId": "db5c28b3-c04c-4dfc-d0de-232fd8c931c5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Build model...\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " lstm (LSTM)                 (None, 128)               72192     \n",
            "                                                                 \n",
            " repeat_vector (RepeatVector  (None, 4, 128)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 4, 128)            131584    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4, 12)             1548      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 205,324\n",
            "Trainable params: 205,324\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "print(\"Build model...\")\n",
        "num_layers = 1  # Try to add more LSTM layers!\n",
        "\n",
        "model = keras.Sequential()\n",
        "# \"Encode\" the input sequence using a LSTM, producing an output of size 128.\n",
        "# Note: In a situation where your input sequences have a variable length,\n",
        "# use input_shape=(None, num_feature).\n",
        "model.add(layers.LSTM(128, input_shape=(MAXLEN, len(chars))))\n",
        "# As the decoder RNN's input, repeatedly provide with the last output of\n",
        "# RNN for each time step. Repeat 'DIGITS + 1' times as that's the maximum\n",
        "# length of output, e.g., when DIGITS=3, max output is 999+999=1998.\n",
        "model.add(layers.RepeatVector(DIGITS + 1))\n",
        "# The decoder RNN could be multiple layers stacked or a single layer.\n",
        "for _ in range(num_layers):\n",
        "    # By setting return_sequences to True, return not only the last output but\n",
        "    # all the outputs so far in the form of (num_samples, timesteps,\n",
        "    # output_dim). This is necessary as TimeDistributed in the below expects\n",
        "    # the first dimension to be the timesteps.\n",
        "    model.add(layers.LSTM(128, return_sequences=True))\n",
        "\n",
        "# Apply a dense layer to the every temporal slice of an input. For each of step\n",
        "# of the output sequence, decide which character should be chosen.\n",
        "model.add(layers.Dense(len(chars), activation=\"softmax\"))\n",
        "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceYoo1EslGvN"
      },
      "source": [
        "## Train the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NyTP4Nx_lGvN",
        "outputId": "3c26ce08-84dc-4be8-d2a6-434d14a83885"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Iteration 1\n",
            "1407/1407 [==============================] - 27s 16ms/step - loss: 1.7642 - accuracy: 0.3565 - val_loss: 1.5701 - val_accuracy: 0.4081\n",
            "Q 680+54  T 734  ☒ 666 \n",
            "Q 392+293 T 685  ☒ 610 \n",
            "Q 46+89   T 135  ☒ 100 \n",
            "Q 975+299 T 1274 ☒ 1064\n",
            "Q 399+88  T 487  ☒ 996 \n",
            "Q 66+27   T 93   ☒ 10  \n",
            "Q 224+33  T 257  ☒ 366 \n",
            "Q 98+132  T 230  ☒ 316 \n",
            "Q 908+838 T 1746 ☒ 1799\n",
            "Q 11+412  T 423  ☒ 116 \n",
            "\n",
            "Iteration 2\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.3742 - accuracy: 0.4850 - val_loss: 1.1910 - val_accuracy: 0.5554\n",
            "Q 495+551 T 1046 ☒ 1001\n",
            "Q 99+206  T 305  ☒ 200 \n",
            "Q 549+40  T 589  ☒ 590 \n",
            "Q 731+398 T 1129 ☒ 1151\n",
            "Q 696+40  T 736  ☒ 730 \n",
            "Q 639+20  T 659  ☒ 665 \n",
            "Q 1+907   T 908  ☒ 905 \n",
            "Q 551+208 T 759  ☒ 800 \n",
            "Q 277+32  T 309  ☒ 305 \n",
            "Q 842+565 T 1407 ☒ 1365\n",
            "\n",
            "Iteration 3\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 1.0559 - accuracy: 0.6081 - val_loss: 0.9496 - val_accuracy: 0.6486\n",
            "Q 6+863   T 869  ☒ 873 \n",
            "Q 22+672  T 694  ☒ 797 \n",
            "Q 133+226 T 359  ☒ 374 \n",
            "Q 919+700 T 1619 ☒ 1649\n",
            "Q 984+78  T 1062 ☒ 1064\n",
            "Q 932+623 T 1555 ☒ 1554\n",
            "Q 104+6   T 110  ☒ 108 \n",
            "Q 676+494 T 1170 ☒ 1157\n",
            "Q 36+44   T 80   ☒ 87  \n",
            "Q 139+655 T 794  ☒ 799 \n",
            "\n",
            "Iteration 4\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.8803 - accuracy: 0.6759 - val_loss: 0.8270 - val_accuracy: 0.6973\n",
            "Q 151+861 T 1012 ☑ 1012\n",
            "Q 412+42  T 454  ☒ 457 \n",
            "Q 419+4   T 423  ☒ 420 \n",
            "Q 46+702  T 748  ☒ 745 \n",
            "Q 293+842 T 1135 ☒ 1122\n",
            "Q 149+111 T 260  ☒ 257 \n",
            "Q 938+82  T 1020 ☑ 1020\n",
            "Q 161+268 T 429  ☒ 427 \n",
            "Q 175+303 T 478  ☒ 477 \n",
            "Q 196+32  T 228  ☒ 226 \n",
            "\n",
            "Iteration 5\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7923 - accuracy: 0.7094 - val_loss: 0.7526 - val_accuracy: 0.7274\n",
            "Q 721+919 T 1640 ☒ 1632\n",
            "Q 342+4   T 346  ☑ 346 \n",
            "Q 726+58  T 784  ☒ 781 \n",
            "Q 86+444  T 530  ☒ 535 \n",
            "Q 890+66  T 956  ☒ 957 \n",
            "Q 608+378 T 986  ☒ 997 \n",
            "Q 517+0   T 517  ☒ 511 \n",
            "Q 34+8    T 42   ☒ 39  \n",
            "Q 664+46  T 710  ☒ 715 \n",
            "Q 411+353 T 764  ☒ 767 \n",
            "\n",
            "Iteration 6\n",
            "1407/1407 [==============================] - 23s 16ms/step - loss: 0.7289 - accuracy: 0.7344 - val_loss: 0.7225 - val_accuracy: 0.7325\n",
            "Q 253+188 T 441  ☒ 439 \n",
            "Q 548+4   T 552  ☒ 553 \n",
            "Q 863+101 T 964  ☒ 975 \n",
            "Q 500+909 T 1409 ☒ 1511\n",
            "Q 0+778   T 778  ☒ 780 \n",
            "Q 384+70  T 454  ☒ 451 \n",
            "Q 445+26  T 471  ☑ 471 \n",
            "Q 4+972   T 976  ☒ 971 \n",
            "Q 809+641 T 1450 ☒ 1451\n",
            "Q 43+990  T 1033 ☒ 1045\n",
            "\n",
            "Iteration 7\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.6464 - accuracy: 0.7648 - val_loss: 0.5662 - val_accuracy: 0.7908\n",
            "Q 2+462   T 464  ☒ 463 \n",
            "Q 38+633  T 671  ☑ 671 \n",
            "Q 413+646 T 1059 ☒ 1158\n",
            "Q 531+106 T 637  ☒ 638 \n",
            "Q 771+85  T 856  ☒ 852 \n",
            "Q 78+585  T 663  ☒ 662 \n",
            "Q 78+687  T 765  ☒ 767 \n",
            "Q 168+336 T 504  ☒ 512 \n",
            "Q 622+364 T 986  ☒ 988 \n",
            "Q 6+77    T 83   ☑ 83  \n",
            "\n",
            "Iteration 8\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.4256 - accuracy: 0.8487 - val_loss: 0.3261 - val_accuracy: 0.8814\n",
            "Q 862+49  T 911  ☑ 911 \n",
            "Q 530+902 T 1432 ☒ 1434\n",
            "Q 577+363 T 940  ☒ 931 \n",
            "Q 61+318  T 379  ☑ 379 \n",
            "Q 637+16  T 653  ☑ 653 \n",
            "Q 470+672 T 1142 ☑ 1142\n",
            "Q 133+226 T 359  ☒ 350 \n",
            "Q 11+272  T 283  ☒ 284 \n",
            "Q 309+462 T 771  ☑ 771 \n",
            "Q 400+140 T 540  ☒ 531 \n",
            "\n",
            "Iteration 9\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.2296 - accuracy: 0.9362 - val_loss: 0.1904 - val_accuracy: 0.9475\n",
            "Q 99+664  T 763  ☑ 763 \n",
            "Q 539+23  T 562  ☑ 562 \n",
            "Q 33+608  T 641  ☑ 641 \n",
            "Q 136+54  T 190  ☒ 180 \n",
            "Q 76+76   T 152  ☑ 152 \n",
            "Q 60+931  T 991  ☑ 991 \n",
            "Q 473+2   T 475  ☑ 475 \n",
            "Q 6+819   T 825  ☑ 825 \n",
            "Q 13+26   T 39   ☑ 39  \n",
            "Q 14+400  T 414  ☑ 414 \n",
            "\n",
            "Iteration 10\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.1429 - accuracy: 0.9654 - val_loss: 0.1933 - val_accuracy: 0.9376\n",
            "Q 18+200  T 218  ☑ 218 \n",
            "Q 403+63  T 466  ☑ 466 \n",
            "Q 32+392  T 424  ☑ 424 \n",
            "Q 66+540  T 606  ☑ 606 \n",
            "Q 21+78   T 99   ☑ 99  \n",
            "Q 90+933  T 1023 ☒ 1033\n",
            "Q 318+65  T 383  ☑ 383 \n",
            "Q 13+293  T 306  ☑ 306 \n",
            "Q 65+56   T 121  ☑ 121 \n",
            "Q 212+637 T 849  ☑ 849 \n",
            "\n",
            "Iteration 11\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0941 - accuracy: 0.9786 - val_loss: 0.0880 - val_accuracy: 0.9769\n",
            "Q 177+92  T 269  ☑ 269 \n",
            "Q 873+233 T 1106 ☑ 1106\n",
            "Q 721+8   T 729  ☑ 729 \n",
            "Q 32+466  T 498  ☑ 498 \n",
            "Q 579+122 T 701  ☑ 701 \n",
            "Q 206+52  T 258  ☑ 258 \n",
            "Q 599+827 T 1426 ☒ 1416\n",
            "Q 561+40  T 601  ☑ 601 \n",
            "Q 990+3   T 993  ☑ 993 \n",
            "Q 411+876 T 1287 ☑ 1287\n",
            "\n",
            "Iteration 12\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0713 - accuracy: 0.9830 - val_loss: 0.1104 - val_accuracy: 0.9643\n",
            "Q 608+378 T 986  ☑ 986 \n",
            "Q 68+936  T 1004 ☑ 1004\n",
            "Q 194+601 T 795  ☒ 895 \n",
            "Q 811+651 T 1462 ☒ 1362\n",
            "Q 576+11  T 587  ☑ 587 \n",
            "Q 994+50  T 1044 ☒ 1043\n",
            "Q 781+180 T 961  ☒ 971 \n",
            "Q 383+35  T 418  ☑ 418 \n",
            "Q 59+516  T 575  ☑ 575 \n",
            "Q 57+774  T 831  ☑ 831 \n",
            "\n",
            "Iteration 13\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0512 - accuracy: 0.9877 - val_loss: 0.0365 - val_accuracy: 0.9926\n",
            "Q 875+650 T 1525 ☑ 1525\n",
            "Q 543+62  T 605  ☑ 605 \n",
            "Q 408+17  T 425  ☑ 425 \n",
            "Q 390+2   T 392  ☑ 392 \n",
            "Q 729+303 T 1032 ☑ 1032\n",
            "Q 495+57  T 552  ☑ 552 \n",
            "Q 83+893  T 976  ☑ 976 \n",
            "Q 3+662   T 665  ☑ 665 \n",
            "Q 868+12  T 880  ☑ 880 \n",
            "Q 998+956 T 1954 ☑ 1954\n",
            "\n",
            "Iteration 14\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0573 - accuracy: 0.9845 - val_loss: 0.0361 - val_accuracy: 0.9912\n",
            "Q 292+2   T 294  ☑ 294 \n",
            "Q 952+532 T 1484 ☑ 1484\n",
            "Q 73+428  T 501  ☑ 501 \n",
            "Q 562+774 T 1336 ☑ 1336\n",
            "Q 540+78  T 618  ☑ 618 \n",
            "Q 467+21  T 488  ☑ 488 \n",
            "Q 433+336 T 769  ☑ 769 \n",
            "Q 78+965  T 1043 ☑ 1043\n",
            "Q 736+68  T 804  ☑ 804 \n",
            "Q 751+5   T 756  ☑ 756 \n",
            "\n",
            "Iteration 15\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0344 - accuracy: 0.9920 - val_loss: 0.0808 - val_accuracy: 0.9740\n",
            "Q 613+484 T 1097 ☑ 1097\n",
            "Q 352+7   T 359  ☑ 359 \n",
            "Q 541+6   T 547  ☑ 547 \n",
            "Q 530+46  T 576  ☑ 576 \n",
            "Q 55+54   T 109  ☑ 109 \n",
            "Q 17+827  T 844  ☑ 844 \n",
            "Q 11+664  T 675  ☑ 675 \n",
            "Q 975+697 T 1672 ☑ 1672\n",
            "Q 750+64  T 814  ☑ 814 \n",
            "Q 14+232  T 246  ☑ 246 \n",
            "\n",
            "Iteration 16\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0390 - accuracy: 0.9897 - val_loss: 0.0558 - val_accuracy: 0.9824\n",
            "Q 588+219 T 807  ☑ 807 \n",
            "Q 599+64  T 663  ☑ 663 \n",
            "Q 229+400 T 629  ☒ 639 \n",
            "Q 764+73  T 837  ☑ 837 \n",
            "Q 655+797 T 1452 ☑ 1452\n",
            "Q 19+85   T 104  ☑ 104 \n",
            "Q 508+34  T 542  ☑ 542 \n",
            "Q 550+7   T 557  ☑ 557 \n",
            "Q 42+210  T 252  ☒ 251 \n",
            "Q 399+65  T 464  ☑ 464 \n",
            "\n",
            "Iteration 17\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0349 - accuracy: 0.9912 - val_loss: 0.0165 - val_accuracy: 0.9967\n",
            "Q 149+700 T 849  ☑ 849 \n",
            "Q 345+74  T 419  ☑ 419 \n",
            "Q 256+74  T 330  ☑ 330 \n",
            "Q 795+795 T 1590 ☑ 1590\n",
            "Q 546+2   T 548  ☑ 548 \n",
            "Q 863+101 T 964  ☑ 964 \n",
            "Q 364+122 T 486  ☑ 486 \n",
            "Q 87+655  T 742  ☑ 742 \n",
            "Q 75+931  T 1006 ☑ 1006\n",
            "Q 68+43   T 111  ☑ 111 \n",
            "\n",
            "Iteration 18\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0404 - accuracy: 0.9885 - val_loss: 0.0268 - val_accuracy: 0.9924\n",
            "Q 660+7   T 667  ☑ 667 \n",
            "Q 16+485  T 501  ☑ 501 \n",
            "Q 322+411 T 733  ☑ 733 \n",
            "Q 3+522   T 525  ☑ 525 \n",
            "Q 554+9   T 563  ☑ 563 \n",
            "Q 5+913   T 918  ☑ 918 \n",
            "Q 339+178 T 517  ☑ 517 \n",
            "Q 18+87   T 105  ☑ 105 \n",
            "Q 46+57   T 103  ☑ 103 \n",
            "Q 248+291 T 539  ☑ 539 \n",
            "\n",
            "Iteration 19\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0305 - accuracy: 0.9914 - val_loss: 0.0263 - val_accuracy: 0.9926\n",
            "Q 121+35  T 156  ☑ 156 \n",
            "Q 26+466  T 492  ☑ 492 \n",
            "Q 936+748 T 1684 ☑ 1684\n",
            "Q 965+4   T 969  ☑ 969 \n",
            "Q 980+775 T 1755 ☑ 1755\n",
            "Q 51+992  T 1043 ☑ 1043\n",
            "Q 98+18   T 116  ☑ 116 \n",
            "Q 675+729 T 1404 ☑ 1404\n",
            "Q 599+98  T 697  ☑ 697 \n",
            "Q 402+81  T 483  ☑ 483 \n",
            "\n",
            "Iteration 20\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0268 - accuracy: 0.9931 - val_loss: 0.0557 - val_accuracy: 0.9811\n",
            "Q 44+46   T 90   ☑ 90  \n",
            "Q 54+240  T 294  ☑ 294 \n",
            "Q 12+568  T 580  ☑ 580 \n",
            "Q 97+954  T 1051 ☑ 1051\n",
            "Q 375+10  T 385  ☑ 385 \n",
            "Q 408+17  T 425  ☑ 425 \n",
            "Q 6+521   T 527  ☑ 527 \n",
            "Q 7+438   T 445  ☑ 445 \n",
            "Q 990+57  T 1047 ☑ 1047\n",
            "Q 41+122  T 163  ☑ 163 \n",
            "\n",
            "Iteration 21\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0316 - accuracy: 0.9913 - val_loss: 0.0077 - val_accuracy: 0.9987\n",
            "Q 69+204  T 273  ☑ 273 \n",
            "Q 117+946 T 1063 ☑ 1063\n",
            "Q 613+24  T 637  ☑ 637 \n",
            "Q 13+823  T 836  ☑ 836 \n",
            "Q 5+821   T 826  ☑ 826 \n",
            "Q 24+47   T 71   ☑ 71  \n",
            "Q 355+72  T 427  ☑ 427 \n",
            "Q 17+970  T 987  ☑ 987 \n",
            "Q 0+550   T 550  ☑ 550 \n",
            "Q 136+92  T 228  ☑ 228 \n",
            "\n",
            "Iteration 22\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0250 - accuracy: 0.9928 - val_loss: 0.0145 - val_accuracy: 0.9961\n",
            "Q 43+176  T 219  ☑ 219 \n",
            "Q 837+903 T 1740 ☑ 1740\n",
            "Q 536+62  T 598  ☑ 598 \n",
            "Q 37+577  T 614  ☑ 614 \n",
            "Q 886+440 T 1326 ☑ 1326\n",
            "Q 741+3   T 744  ☑ 744 \n",
            "Q 17+220  T 237  ☑ 237 \n",
            "Q 644+345 T 989  ☑ 989 \n",
            "Q 700+46  T 746  ☑ 746 \n",
            "Q 30+987  T 1017 ☑ 1017\n",
            "\n",
            "Iteration 23\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0264 - accuracy: 0.9926 - val_loss: 0.1301 - val_accuracy: 0.9610\n",
            "Q 3+137   T 140  ☑ 140 \n",
            "Q 161+1   T 162  ☑ 162 \n",
            "Q 879+143 T 1022 ☑ 1022\n",
            "Q 825+0   T 825  ☑ 825 \n",
            "Q 280+76  T 356  ☑ 356 \n",
            "Q 875+3   T 878  ☑ 878 \n",
            "Q 990+343 T 1333 ☑ 1333\n",
            "Q 42+561  T 603  ☑ 603 \n",
            "Q 80+541  T 621  ☑ 621 \n",
            "Q 715+84  T 799  ☑ 799 \n",
            "\n",
            "Iteration 24\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0123 - accuracy: 0.9973 - val_loss: 0.0134 - val_accuracy: 0.9963\n",
            "Q 999+6   T 1005 ☑ 1005\n",
            "Q 463+910 T 1373 ☑ 1373\n",
            "Q 99+57   T 156  ☑ 156 \n",
            "Q 97+3    T 100  ☑ 100 \n",
            "Q 270+9   T 279  ☑ 279 \n",
            "Q 588+5   T 593  ☑ 593 \n",
            "Q 107+88  T 195  ☑ 195 \n",
            "Q 789+636 T 1425 ☑ 1425\n",
            "Q 915+67  T 982  ☑ 982 \n",
            "Q 913+42  T 955  ☑ 955 \n",
            "\n",
            "Iteration 25\n",
            "1407/1407 [==============================] - 21s 15ms/step - loss: 0.0248 - accuracy: 0.9930 - val_loss: 0.0152 - val_accuracy: 0.9955\n",
            "Q 68+853  T 921  ☑ 921 \n",
            "Q 776+45  T 821  ☑ 821 \n",
            "Q 727+9   T 736  ☑ 736 \n",
            "Q 4+127   T 131  ☑ 131 \n",
            "Q 517+0   T 517  ☑ 517 \n",
            "Q 724+469 T 1193 ☑ 1193\n",
            "Q 99+41   T 140  ☑ 140 \n",
            "Q 5+486   T 491  ☑ 491 \n",
            "Q 36+438  T 474  ☑ 474 \n",
            "Q 962+14  T 976  ☑ 976 \n",
            "\n",
            "Iteration 26\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0240 - accuracy: 0.9940 - val_loss: 0.0110 - val_accuracy: 0.9974\n",
            "Q 121+785 T 906  ☑ 906 \n",
            "Q 969+418 T 1387 ☑ 1387\n",
            "Q 309+60  T 369  ☑ 369 \n",
            "Q 35+328  T 363  ☑ 363 \n",
            "Q 66+159  T 225  ☑ 225 \n",
            "Q 810+880 T 1690 ☑ 1690\n",
            "Q 73+399  T 472  ☑ 472 \n",
            "Q 51+576  T 627  ☑ 627 \n",
            "Q 636+53  T 689  ☑ 689 \n",
            "Q 775+406 T 1181 ☑ 1181\n",
            "\n",
            "Iteration 27\n",
            "1407/1407 [==============================] - 22s 15ms/step - loss: 0.0262 - accuracy: 0.9928 - val_loss: 0.0227 - val_accuracy: 0.9934\n",
            "Q 907+7   T 914  ☑ 914 \n",
            "Q 20+929  T 949  ☑ 949 \n",
            "Q 19+675  T 694  ☑ 694 \n",
            "Q 4+266   T 270  ☑ 270 \n",
            "Q 30+894  T 924  ☑ 924 \n",
            "Q 1+785   T 786  ☑ 786 \n",
            "Q 876+435 T 1311 ☑ 1311\n",
            "Q 735+21  T 756  ☑ 756 \n",
            "Q 551+3   T 554  ☑ 554 \n",
            "Q 21+82   T 103  ☑ 103 \n",
            "\n",
            "Iteration 28\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0129 - accuracy: 0.9967 - val_loss: 0.0119 - val_accuracy: 0.9965\n",
            "Q 55+12   T 67   ☑ 67  \n",
            "Q 889+180 T 1069 ☑ 1069\n",
            "Q 488+38  T 526  ☑ 526 \n",
            "Q 796+339 T 1135 ☑ 1135\n",
            "Q 808+526 T 1334 ☑ 1334\n",
            "Q 945+16  T 961  ☑ 961 \n",
            "Q 969+418 T 1387 ☑ 1387\n",
            "Q 12+279  T 291  ☑ 291 \n",
            "Q 994+921 T 1915 ☑ 1915\n",
            "Q 175+67  T 242  ☑ 242 \n",
            "\n",
            "Iteration 29\n",
            "1407/1407 [==============================] - 22s 16ms/step - loss: 0.0237 - accuracy: 0.9932 - val_loss: 0.0096 - val_accuracy: 0.9977\n",
            "Q 617+35  T 652  ☑ 652 \n",
            "Q 969+14  T 983  ☑ 983 \n",
            "Q 604+108 T 712  ☑ 712 \n",
            "Q 979+208 T 1187 ☑ 1187\n",
            "Q 510+55  T 565  ☑ 565 \n",
            "Q 0+986   T 986  ☑ 986 \n",
            "Q 833+691 T 1524 ☑ 1524\n",
            "Q 712+28  T 740  ☑ 740 \n",
            "Q 714+83  T 797  ☑ 797 \n",
            "Q 36+13   T 49   ☑ 49  \n"
          ]
        }
      ],
      "source": [
        "epochs = 30\n",
        "batch_size = 32\n",
        "\n",
        "\n",
        "# Train the model each generation and show predictions against the validation\n",
        "# dataset.\n",
        "for epoch in range(1, epochs):\n",
        "    print()\n",
        "    print(\"Iteration\", epoch)\n",
        "    model.fit(\n",
        "        x_train,\n",
        "        y_train,\n",
        "        batch_size=batch_size,\n",
        "        epochs=1,\n",
        "        validation_data=(x_val, y_val),\n",
        "    )\n",
        "    # Select 10 samples from the validation set at random so we can visualize\n",
        "    # errors.\n",
        "    for i in range(10):\n",
        "        ind = np.random.randint(0, len(x_val))\n",
        "        rowx, rowy = x_val[np.array([ind])], y_val[np.array([ind])]\n",
        "        preds = np.argmax(model.predict(rowx), axis=-1)\n",
        "        q = ctable.decode(rowx[0])\n",
        "        correct = ctable.decode(rowy[0])\n",
        "        guess = ctable.decode(preds[0], calc_argmax=False)\n",
        "        print(\"Q\", q[::-1] if REVERSE else q, end=\" \")\n",
        "        print(\"T\", correct, end=\" \")\n",
        "        if correct == guess:\n",
        "            print(\"☑ \" + guess)\n",
        "        else:\n",
        "            print(\"☒ \" + guess)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir1QpUQIlGvN"
      },
      "source": [
        "You'll get to 99+% validation accuracy after ~30 epochs.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}